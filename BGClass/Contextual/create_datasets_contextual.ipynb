{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCORD.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 accord_key.csv\n",
      "2 activitystatus.csv\n",
      "3 bloodpressure.csv\n",
      "4 concomitantmeds.csv\n",
      "5 cvdoutcomes.csv\n",
      "6 ecg.csv\n",
      "7 eye.csv\n",
      "8 f01_inclusionexclusionsummary.csv\n",
      "9 f02_bptrialscreening.csv\n",
      "10 f03_lipidtrialscreening.csv\n",
      "11 f07_baselinehistoryphysicalexam.csv\n",
      "12 f08_09_glycemiamanagement.csv\n",
      "13 f10_glycemiamedicationslog.csv\n",
      "14 f13_intensivebpmanagement.csv\n",
      "15 f14_standardbpmanagement.csv\n",
      "16 f15_bptrialmedicationslog.csv\n",
      "17 f16_lipidmedicationsmanagement.csv\n",
      "18 f19_healthutilitiesindex.csv\n",
      "19 f22_costsubstudy.csv\n",
      "20 f23_hrql.csv\n",
      "21 f26_dietquestionnaire.csv\n",
      "22 f29_champsphysicalactivity.csv\n",
      "23 f34_intervalhistoryfollowup.csv\n",
      "24 f36_annualfollowupphysicalexam.csv\n",
      "25 f49_standingbloodpressure.csv\n",
      "26 hba1c.csv\n",
      "27 hypoglycemiaevents.csv\n",
      "28 hypoglycemiatime1st.csv\n",
      "29 lipids.csv\n",
      "30 microvascularoutcomes.csv\n",
      "31 mind.csv\n",
      "32 mind_mri.csv\n",
      "33 otherlabs.csv\n",
      "34 sae.csv\n"
     ]
    }
   ],
   "source": [
    "# get the list of names of the csv files in the ../data folder\n",
    "csv_files = [f for f in os.listdir('../../../DataSets') if f.endswith('.csv')]\n",
    "csv_files.sort()\n",
    "for i in range(len(csv_files)):\n",
    "    print(i+1, csv_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(red_dict) =  13\n",
      "len(blue_dict) =  12\n",
      "red_features =  38\n",
      "blue_features =  24\n"
     ]
    }
   ],
   "source": [
    "# dfine the dict to select the columns from the csv files\n",
    "\n",
    "red_dict = dict()\n",
    "blue_dict = dict()\n",
    "\n",
    "# the accord_key.csv file contains the basic information about the patients, no per visit data +++++\n",
    "red_dict['accord_key.csv'] = ['MaskID', 'female', 'baseline_age','cvd_hx_baseline','raceclass']\n",
    "blue_dict['accord_key.csv'] = ['MaskID', 'female', 'baseline_age','cvd_hx_baseline','raceclass']\n",
    "\n",
    "\n",
    "# the following files contains the per visit data\n",
    "red_dict['activitystatus.csv'] = ['MaskID', 'Visit', 'glycemia','bp']\n",
    "blue_dict['activitystatus.csv'] = ['MaskID', 'Visit', 'glycemia','bp']\n",
    "\n",
    "red_dict['bloodpressure.csv'] = ['MaskID', 'Visit', 'sbp', 'dbp', 'hr']\n",
    "blue_dict['bloodpressure.csv'] = ['MaskID', 'Visit', 'sbp']\n",
    "\n",
    "# no 'Visit' column in the file +++++\n",
    "red_dict['cvdoutcomes.csv'] = ['MaskID', 'type_po']\n",
    "blue_dict['cvdoutcomes.csv'] = ['MaskID', 'type_po']\n",
    "\n",
    "red_dict['hba1c.csv'] = ['MaskID', 'Visit', 'hba1c']\n",
    "blue_dict['hba1c.csv'] = ['MaskID', 'Visit', 'hba1c']\n",
    "\n",
    "red_dict['lipids.csv'] = ['MaskID', 'Visit', 'chol', 'trig', 'vldl', 'ldl', 'hdl']\n",
    "blue_dict['lipids.csv'] = ['MaskID', 'Visit', 'chol', 'hdl']\n",
    "\n",
    "# no blue features +++++\n",
    "red_dict['otherlabs.csv'] = ['MaskID', 'Visit', 'fpg', 'alt', 'cpk', 'potassium', 'screat', 'gfr', 'ualb','ucreat', 'uacr']\n",
    "# blue_dict['otherlabs.csv'] = []\n",
    "\n",
    "# only baseline visit info +++++\n",
    "red_dict['f07_baselinehistoryphysicalexam.csv'] = ['MaskID', 'Visit', 'edu', 'yrsdiab', 'yrstens', 'cigarett', 'wt_kg', 'ht_cm']\n",
    "blue_dict['f07_baselinehistoryphysicalexam.csv'] = ['MaskID', 'Visit', 'edu', 'yrsdiab', 'yrstens', 'cigarett', 'wt_kg', 'ht_cm']\n",
    "\n",
    "# to calculate the BMI for every visit\n",
    "red_dict['f36_annualfollowupphysicalexam.csv'] = ['MaskID', 'Visit', 'wt_kg', 'ht_cm']\n",
    "blue_dict['f36_annualfollowupphysicalexam.csv'] = ['MaskID', 'Visit', 'wt_kg', 'ht_cm']\n",
    "\n",
    "# multiple rows for the same MaskID and Visit, each row is a different medication +++++\n",
    "red_dict['f10_glycemiamedicationslog.csv'] = ['MaskID', 'Visit', 'oral_gmed'] \n",
    "blue_dict['f10_glycemiamedicationslog.csv'] = ['MaskID', 'Visit', 'oral_gmed']\n",
    "\n",
    "red_dict['f13_intensivebpmanagement.csv'] = ['MaskID', 'Visit', 'medadd','medchg']\n",
    "blue_dict['f13_intensivebpmanagement.csv'] = ['MaskID', 'Visit', 'medadd','medchg']\n",
    "\n",
    "red_dict['f14_standardbpmanagement.csv'] = ['MaskID', 'Visit', 'medchg']\n",
    "blue_dict['f14_standardbpmanagement.csv'] = ['MaskID', 'Visit', 'medchg']\n",
    "\n",
    "# multiple rows for the same MaskID and Visit, each row is a different medication +++++\n",
    "red_dict['f15_bptrialmedicationslog.csv'] = ['MaskID', 'Visit','bp_med'] \n",
    "blue_dict['f15_bptrialmedicationslog.csv'] = ['MaskID', 'Visit','bp_med']\n",
    "\n",
    "print('len(red_dict) = ', len(red_dict))\n",
    "print('len(blue_dict) = ', len(blue_dict))\n",
    "\n",
    "# count total number of features in the red and blue dictionaries\n",
    "red_features_set = set()\n",
    "blue_features_set = set()\n",
    "for key in red_dict:\n",
    "    red_features_set.update(red_dict[key])\n",
    "for key in blue_dict:\n",
    "    blue_features_set.update(blue_dict[key])\n",
    "\n",
    "print('red_features = ', len(red_features_set)+1) # add 1 bc duplicate medchg\n",
    "print('blue_features = ', len(blue_features_set)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "collect_feature_columnns: red\n",
      "collect 0 accord_key.csv , row_number = 10251\n",
      "collect 1 activitystatus.csv , row_number = 388624\n",
      "collect 2 bloodpressure.csv , row_number = 181991\n",
      "collect 3 cvdoutcomes.csv , row_number = 10251\n",
      "collect 4 hba1c.csv , row_number = 136650\n",
      "collect 5 lipids.csv , row_number = 69062\n",
      "collect 6 otherlabs.csv , row_number = 118662\n",
      "collect 7 f07_baselinehistoryphysicalexam.csv , row_number = 10251\n",
      "collect 8 f36_annualfollowupphysicalexam.csv , row_number = 50701\n",
      "collect 9 f10_glycemiamedicationslog.csv , row_number = 727628\n",
      "collect 10 f13_intensivebpmanagement.csv , row_number = 68732\n",
      "collect 11 f14_standardbpmanagement.csv , row_number = 40026\n",
      "collect 12 f15_bptrialmedicationslog.csv , row_number = 307222\n",
      "done\n",
      "min_row_number = 10251\n"
     ]
    }
   ],
   "source": [
    "# use the red_dict and blue_dict to create the red and blue datasets\n",
    "# load the each csv file using the key, \n",
    "# and select the corresponding columns using the value\n",
    "# and save the resulting dataframe to a csv file\n",
    "\n",
    "def collect_feature_columnns(dict, flag):\n",
    "    print('\\ncollect_feature_columnns:', flag)\n",
    "\n",
    "    min_row_number = 1e6\n",
    "    for i, key in enumerate(dict):\n",
    "        \n",
    "        df = pd.read_csv('../../../DataSets/' + key)\n",
    "        print('collect', i, key, ', row_number =', df.shape[0])\n",
    "        if df.shape[0] < min_row_number:\n",
    "            min_row_number = df.shape[0]\n",
    "\n",
    "        # check if desired columns are in the dataframe\n",
    "        for col in dict[key]:\n",
    "            if col not in df.columns:\n",
    "                print('Error in dict:', col, 'not in', key)\n",
    "\n",
    "        df_fea = df[dict[key]]\n",
    "        out_file = 'data/features_'+ str(flag)+'/' + key\n",
    "        df_fea.to_csv(out_file, index=False)\n",
    "        # print('save to', out_file)\n",
    "\n",
    "    print('done')\n",
    "    print('min_row_number =', min_row_number)    \n",
    "\n",
    "collect_feature_columnns(red_dict, 'red')\n",
    "# collect_feature_columnns(blue_dict, 'blue')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total patients number: `10251`, as shown by the row number of `accord_key.csv` and `cvdoutcomes.csv` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect medication list per patient's visit\n",
    "\n",
    "Process the files with medication prescription information `f10_glycemiamedicationslog.csv`--> `oral_gmed`, and `f15_bptrialmedicationslog.csv` --> `bp_med`.\n",
    "Collect multiple rows with the same `MaskID` and `Visit` but different medications into the same row.\n",
    "The medicine is converted to lowercase and sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "collect_med: data/features_red/f10_glycemiamedicationslog.csv oral_gmed\n",
      "(727628, 3)\n",
      "(311310, 3)\n",
      "save to data/features_red/f10_glycemiamedicationslog_medlist.csv\n",
      "\n",
      "collect_med: data/features_red/f15_bptrialmedicationslog.csv bp_med\n",
      "(307222, 3)\n",
      "(104571, 3)\n",
      "save to data/features_red/f15_bptrialmedicationslog_medlist.csv\n"
     ]
    }
   ],
   "source": [
    "def collect_med(fn, col):\n",
    "    print('\\ncollect_med:', fn, col)\n",
    "\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "    # print(df.info())\n",
    "\n",
    "    # for all rows with missing `col` values, replace with 'NAN'\n",
    "    df[col] = df[col].fillna('none')\n",
    "\n",
    "    # cast the `col` column to string\n",
    "    # df[col] = df[col].astype('string')\n",
    "    # print(df.info())\n",
    "\n",
    "    # group by MaskID and Visit, and convert the `col` column to a list\n",
    "    df = df.groupby(['MaskID', 'Visit'])[col].apply(list).reset_index()\n",
    "\n",
    "    # convert to lowercase, then sort the list in the `col` column for each row\n",
    "    df[col] = df[col].apply(lambda x: sorted([y.lower() for y in x]))\n",
    "     \n",
    "    df[col] = df[col].apply(lambda x: '+'.join(sorted(x)))\n",
    "    # print(df.info())\n",
    "    print(df.shape)\n",
    "\n",
    "    # print(df.tail())\n",
    "    outfn = fn.replace('.csv', '_medlist.csv')\n",
    "    df.to_csv(outfn, index=False)\n",
    "    print('save to', outfn)\n",
    "\n",
    "collect_med('data/features_red/f10_glycemiamedicationslog.csv', 'oral_gmed')\n",
    "# collect_med('data/features_blue/f10_glycemiamedicationslog.csv', 'oral_gmed')\n",
    "\n",
    "collect_med('data/features_red/f15_bptrialmedicationslog.csv', 'bp_med')\n",
    "# collect_med('data/features_blue/f15_bptrialmedicationslog.csv', 'bp_med')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifiy duplicated column/feature names\n",
    "\n",
    "* `f13_intensivebpmanagement.csv` and `f14_standardbpmanagement.csv` has the same column name `medchg`, we need to change it to `medchg_intbp` and `medchg_stdbp`\n",
    "* `f07_baselinehistoryphysicalexam.csv`: `wt_kg` --> `wt_kg_baseline`, `ht_cm` --> `ht_cm_baseline`. Also add '_baseline' to other features in this file.\n",
    "* `f36_annualfollowupphysicalexam.csv`: `wt_kg` --> `wt_kg_visit`, `ht_cm` --> `ht_cm_visit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change ['medchg'] to ['medchg_intbp'] in data/features_red/f13_intensivebpmanagement.csv\n",
      "save to data/features_red/f13_intensivebpmanagement.csv\n",
      "change ['medchg'] to ['medchg_stdbp'] in data/features_red/f14_standardbpmanagement.csv\n",
      "save to data/features_red/f14_standardbpmanagement.csv\n",
      "change ['edu', 'yrsdiab', 'yrstens', 'cigarett', 'wt_kg', 'ht_cm'] to ['edu_baseline', 'yrsdiab_baseline', 'yrstens_baseline', 'cigarett_baseline', 'wt_kg_baseline', 'ht_cm_baseline'] in data/features_red/f07_baselinehistoryphysicalexam.csv\n",
      "save to data/features_red/f07_baselinehistoryphysicalexam.csv\n",
      "change ['wt_kg', 'ht_cm'] to ['wt_kg_visit', 'ht_cm_visit'] in data/features_red/f36_annualfollowupphysicalexam.csv\n",
      "save to data/features_red/f36_annualfollowupphysicalexam.csv\n"
     ]
    }
   ],
   "source": [
    "def modify_dup_name(fn, old_col_name_list, new_col_name_list, do_blue=False):\n",
    "    fn1 = 'data/features_red/' + fn\n",
    "    \n",
    "\n",
    "    # build a dictionary to rename the columns\n",
    "    name_pairs_dict = {}\n",
    "    for i in range(len(old_col_name_list)):\n",
    "        name_pairs_dict[old_col_name_list[i]] = new_col_name_list[i]\n",
    "\n",
    "    df1 = pd.read_csv(fn1)\n",
    "    df1.rename(columns=name_pairs_dict, inplace=True)\n",
    "    df1.to_csv(fn1, index=False)\n",
    "    print('change', old_col_name_list, 'to', new_col_name_list, 'in', fn1)\n",
    "    print('save to', fn1)\n",
    "\n",
    "    if do_blue:\n",
    "        fn2 = 'data/features_blue/' + fn\n",
    "        df2 = pd.read_csv(fn2)\n",
    "        df2.rename(columns=name_pairs_dict, inplace=True)\n",
    "        df2.to_csv(fn2, index=False)\n",
    "        print('change', old_col_name_list, 'to', new_col_name_list, 'in', fn2)\n",
    "        print('save to', fn2)\n",
    "        print()\n",
    "\n",
    "modify_dup_name('f13_intensivebpmanagement.csv', ['medchg'], ['medchg_intbp'])\n",
    "modify_dup_name('f14_standardbpmanagement.csv', ['medchg'], ['medchg_stdbp'])\n",
    "modify_dup_name('f07_baselinehistoryphysicalexam.csv', ['edu', 'yrsdiab', 'yrstens', 'cigarett','wt_kg','ht_cm'], \n",
    "                                                       ['edu_baseline','yrsdiab_baseline','yrstens_baseline','cigarett_baseline','wt_kg_baseline','ht_cm_baseline'])\n",
    "modify_dup_name('f36_annualfollowupphysicalexam.csv', ['wt_kg','ht_cm'], ['wt_kg_visit','ht_cm_visit'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tables\n",
    "\n",
    "1. The row numbers of each csv files are shown above. If we just naively merge them using `MaskID` and `Visit` column values, to keep the matching rows only, the resulting table would only contains `1725` rows, which looses too many datapoints.\n",
    "2. So, I use `how='outer'` when merging. The resulting table would have `at least 388624` rows (since the `activitystatus.csv` has the most number of rows, 388624 rows), with many missing entries. The table would contain all visits for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "combine_features: red\n",
      "df_res.shape = (388771, 35)\n"
     ]
    }
   ],
   "source": [
    "# merge a list of dataframes into a single dataframe, using the common column 'MaskID' and 'Visit'\n",
    "\n",
    "def merge_dfs(dfs, common_col):\n",
    "    df = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        # df = df.merge(dfs[i], on=common_col) # default is 'inner' join\n",
    "        df = df.merge(dfs[i], on=common_col, how='outer')\n",
    "    return df\n",
    "\n",
    "# merge the red/blue features\n",
    "def combine_features(dict, flag):\n",
    "    print('\\ncombine_features:', flag)\n",
    "\n",
    "    dfs = []\n",
    "    for fn in dict:\n",
    "\n",
    "        if fn == 'accord_key.csv' or fn == 'cvdoutcomes.csv': # this two files have no 'Visit' column, will add later on\n",
    "            continue\n",
    "\n",
    "        # update feature file names, use the medication list files\n",
    "        if fn == 'f10_glycemiamedicationslog.csv':\n",
    "            fn = 'f10_glycemiamedicationslog_medlist.csv'\n",
    "        if fn == 'f15_bptrialmedicationslog.csv':\n",
    "            fn = 'f15_bptrialmedicationslog_medlist.csv'\n",
    "\n",
    "        folder = 'data/features_' + str(flag) + '/'\n",
    "        df= pd.read_csv(folder + fn)\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_res = merge_dfs(dfs, ['MaskID', 'Visit'])\n",
    "    print('df_res.shape =', df_res.shape)\n",
    "\n",
    "    # set the order for the columns\n",
    "\n",
    "    # sort the rows by MaskID first then by Visit to ensure the visit are in order and complete for a patient\n",
    "    # change the Visit column with 'EXIT' value to 'X-EXIT'\n",
    "    df_res['Visit'] = df_res['Visit'].apply(lambda x: 'X-EXIT' if x == 'EXIT' else x)\n",
    "    df_res.sort_values(by=['MaskID', 'Visit'], inplace=True)\n",
    "\n",
    "\n",
    "    # save the merged dataframe to a csv file\n",
    "    df_res.to_csv('data/temp/features_' + str(flag) + '_merge.csv', index=False)\n",
    "\n",
    "combine_features(red_dict, 'red')\n",
    "# combine_features(blue_dict, 'blue')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red and blue datasets have different row number (388771 vs. 388679) because the blue dataset does not select features from the `otherlabs.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_red.shape = (388771, 35)\n",
      "df_red.shape = (388771, 35)\n"
     ]
    }
   ],
   "source": [
    "# check if have duplicated rows with same MaskID and Visit\n",
    "df_red = pd.read_csv('data/temp/features_red_merge.csv')\n",
    "print('df_red.shape =', df_red.shape)\n",
    "df_red = df_red.drop_duplicates(subset=['MaskID', 'Visit'])\n",
    "print('df_red.shape =', df_red.shape)\n",
    "\n",
    "# df_blue = pd.read_csv('data/temp/features_blue_merge.csv')\n",
    "# print('df_blue.shape =', df_blue.shape)\n",
    "# df_blue = df_blue.drop_duplicates(subset=['MaskID', 'Visit'])\n",
    "# print('df_blue.shape =', df_blue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As shown above, the row numbers does not change, thus no duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 388771 entries, 0 to 388770\n",
      "Data columns (total 35 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   MaskID             388771 non-null  int64  \n",
      " 1   Visit              388771 non-null  object \n",
      " 2   glycemia           375659 non-null  float64\n",
      " 3   bp                 123919 non-null  float64\n",
      " 4   sbp                181991 non-null  float64\n",
      " 5   dbp                181969 non-null  float64\n",
      " 6   hr                 181752 non-null  float64\n",
      " 7   hba1c              136650 non-null  float64\n",
      " 8   chol               69061 non-null   float64\n",
      " 9   trig               69061 non-null   float64\n",
      " 10  vldl               69051 non-null   float64\n",
      " 11  ldl                69051 non-null   float64\n",
      " 12  hdl                69053 non-null   float64\n",
      " 13  fpg                79017 non-null   float64\n",
      " 14  alt                87037 non-null   float64\n",
      " 15  cpk                58217 non-null   float64\n",
      " 16  potassium          62905 non-null   float64\n",
      " 17  screat             109689 non-null  float64\n",
      " 18  gfr                109687 non-null  float64\n",
      " 19  ualb               35647 non-null   float64\n",
      " 20  ucreat             35648 non-null   float64\n",
      " 21  uacr               34216 non-null   float64\n",
      " 22  edu_baseline       10244 non-null   float64\n",
      " 23  yrsdiab_baseline   10159 non-null   float64\n",
      " 24  yrstens_baseline   7726 non-null    float64\n",
      " 25  cigarett_baseline  10251 non-null   float64\n",
      " 26  wt_kg_baseline     10249 non-null   float64\n",
      " 27  ht_cm_baseline     10247 non-null   float64\n",
      " 28  wt_kg_visit        49048 non-null   float64\n",
      " 29  ht_cm_visit        48793 non-null   float64\n",
      " 30  oral_gmed          311310 non-null  object \n",
      " 31  medadd             7328 non-null    float64\n",
      " 32  medchg_intbp       21308 non-null   float64\n",
      " 33  medchg_stdbp       21667 non-null   float64\n",
      " 34  bp_med             104571 non-null  object \n",
      "dtypes: float64(31), int64(1), object(3)\n",
      "memory usage: 106.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# show the resulting table\n",
    "print(df_red.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_blue.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out inactive patients in both BP and BG trials\n",
    "\n",
    "Now the datasets have no duplicated patient-visit rows, let's do further processing\n",
    "\n",
    "1. Filtering out rows with inactive status in both glycemia and bp status\n",
    "\n",
    "Notice that, from observation of the data, a patient may: \n",
    "* quit early in BP/BG trials\n",
    "* quit in the middle of visit, and join back in later visit, e.g. MaskID 102990\n",
    "* But if they have ever been active, their baseline visit (BLR) must be active\n",
    "\n",
    "Thus, I use BLR visit to filter out patients who neither participate in BP nor BG trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/temp/features_red_merge.csv\n",
      "original df.shape = (388771, 35)\n",
      "select only BLR rows, df_blr.shape = (10251, 35)\n",
      "select only EXIT rows, df_exit.shape = (9146, 35)\n",
      "active glycemia, df_bg.shape = (10251, 35)\n",
      "actve bp, df_bp.shape = (4733, 35)\n",
      "candidates number with either active BP or BG = 10251\n"
     ]
    }
   ],
   "source": [
    "# use the glycemia and bp at BLR visit (baseline) †o select the candidates\n",
    "def select_active_blr(fn):\n",
    "\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print('original df.shape =', df.shape)\n",
    "\n",
    "    # select the rows with visit = BLR, confirmed every patient has only one row with visit = BLR, total 10251 patients\n",
    "    df_blr = df[df['Visit'] == 'BLR']\n",
    "    print('select only BLR rows, df_blr.shape =', df_blr.shape)\n",
    "\n",
    "    df_exit = df[df['Visit'] == 'X-EXIT']\n",
    "    print('select only EXIT rows, df_exit.shape =', df_exit.shape) # only 9146 rows with visit = EXIT, some have missing EXIT visit\n",
    "\n",
    "    # select the rows with glycemia = 1\n",
    "    df_bg = df_blr[df_blr['glycemia'] == 1]\n",
    "    print('active glycemia, df_bg.shape =', df_bg.shape)\n",
    "\n",
    "    # select the rows with bp = 1\n",
    "    df_bp = df_blr[df_blr['bp'] == 1]\n",
    "    print('actve bp, df_bp.shape =', df_bp.shape) # remaining 4733 patients with glycemia = 1 and bp = 1\n",
    "    \n",
    "    # collect the MaskID of the selected patients into a set\n",
    "    candidates_bg = set(df_bg['MaskID'])\n",
    "    candidates_bp = set(df_bp['MaskID'])\n",
    "    candidates = candidates_bg.union(candidates_bp)\n",
    "    print('candidates number with either active BP or BG =', len(candidates))\n",
    "\n",
    "    # save the candidates_bg and candidates_bp to a csv file\n",
    "    candidates_bg_lst = list(candidates_bg)\n",
    "    candidates_bp_lst = list(candidates_bp)\n",
    "\n",
    "    # write the candidates_bg_lst to a file\n",
    "    with open('data/temp/candidates_bg.csv', 'w') as f:\n",
    "        for item in candidates_bg_lst:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    \n",
    "    # write the candidates_bp_lst to a file\n",
    "    with open('data/temp/candidates_bp.csv', 'w') as f:\n",
    "        for item in candidates_bp_lst:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "    #------- select the rows in the original table with MaskID in the set\n",
    "    # df1 = pd.read_csv(fn)\n",
    "    # print('original df1.shape =', df1.shape)\n",
    "    # df1 = df1[df1['MaskID'].isin(candidates)]\n",
    "    # print('select candidates using BLR, df1.shape =', df1.shape)\n",
    "\n",
    "    #------- save the selected rows to a csv file\n",
    "    # df1.to_csv('data/temp/features_' + str(flag) + '_merge_blr.csv', index=False)  \n",
    "\n",
    "select_active_blr('data/temp/features_red_merge.csv')\n",
    "# select_active_blr('data/temp/features_blue_merge.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results above shows that all 10251 patients in record have active BG status, and 4733 of them have active BP. Thus we keep all of the patient-visit rows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate BMI per visit\n",
    "\n",
    "1. put the value of columns 'wt_kg_baseline' and 'ht_cm_baseline' to the columns 'ht_cm_visit' and 'wt_kg_visit'\n",
    "2. fill in the missing values in the columns 'ht_cm_visit' and 'wt_kg_visit' with -1, DONOT take the average of the previous and next valid values!\n",
    "3. calculate the BMI per visit, for missing wt or ht, mark as -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt_kg_mean = 94.64666678052369\n",
      "ht_cm_mean = 169.87821139400054\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 388771 entries, 0 to 388770\n",
      "Data columns (total 36 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   MaskID             388771 non-null  int64  \n",
      " 1   Visit              388771 non-null  object \n",
      " 2   glycemia           375659 non-null  float64\n",
      " 3   bp                 123919 non-null  float64\n",
      " 4   sbp                181991 non-null  float64\n",
      " 5   dbp                181969 non-null  float64\n",
      " 6   hr                 181752 non-null  float64\n",
      " 7   hba1c              136650 non-null  float64\n",
      " 8   chol               69061 non-null   float64\n",
      " 9   trig               69061 non-null   float64\n",
      " 10  vldl               69051 non-null   float64\n",
      " 11  ldl                69051 non-null   float64\n",
      " 12  hdl                69053 non-null   float64\n",
      " 13  fpg                79017 non-null   float64\n",
      " 14  alt                87037 non-null   float64\n",
      " 15  cpk                58217 non-null   float64\n",
      " 16  potassium          62905 non-null   float64\n",
      " 17  screat             109689 non-null  float64\n",
      " 18  gfr                109687 non-null  float64\n",
      " 19  ualb               35647 non-null   float64\n",
      " 20  ucreat             35648 non-null   float64\n",
      " 21  uacr               34216 non-null   float64\n",
      " 22  edu_baseline       10244 non-null   float64\n",
      " 23  yrsdiab_baseline   10159 non-null   float64\n",
      " 24  yrstens_baseline   7726 non-null    float64\n",
      " 25  cigarett_baseline  10251 non-null   float64\n",
      " 26  wt_kg_baseline     10249 non-null   float64\n",
      " 27  ht_cm_baseline     10247 non-null   float64\n",
      " 28  wt_kg_visit        388771 non-null  float64\n",
      " 29  ht_cm_visit        388771 non-null  float64\n",
      " 30  oral_gmed          311310 non-null  object \n",
      " 31  medadd             7328 non-null    float64\n",
      " 32  medchg_intbp       21308 non-null   float64\n",
      " 33  medchg_stdbp       21667 non-null   float64\n",
      " 34  bp_med             104571 non-null  object \n",
      " 35  BMI                388771 non-null  float64\n",
      "dtypes: float64(32), int64(1), object(3)\n",
      "memory usage: 106.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def fill_with_adjacent_avg_list(old_list, avg_value):\n",
    "  \n",
    "    new_list = old_list.copy()\n",
    "\n",
    "    # build a dictionary to store the index, value pairs in old_list\n",
    "    old_dict = {}\n",
    "    for i in range(len(old_list)):        \n",
    "        if old_list[i] == -1: # skip the missing values, +++++ notice here, the missing values are marked with -1\n",
    "            continue\n",
    "        else:\n",
    "            old_dict[i] = old_list[i] \n",
    "        \n",
    "    old_dict_keys = list(old_dict.keys())\n",
    "    # print('old_dict_keys =', old_dict_keys)\n",
    "    # print('old_dict =', old_dict)\n",
    "\n",
    "    if (len(old_dict_keys) == len(old_list)): # no missing values\n",
    "        return new_list\n",
    "\n",
    "    # if all values are missing, fill with the average value\n",
    "    if len(old_dict) == 0:\n",
    "        new_list = [avg_value] * len(old_list)\n",
    "\n",
    "    # if there is only one value, fill the entire list with the value\n",
    "    elif len(old_dict) == 1:\n",
    "        first_key = old_dict_keys[0]\n",
    "        new_list = [old_dict[first_key]] * len(old_list)\n",
    "    \n",
    "    # if there are more than one values, fill the missing values with the average value of the previous and next values\n",
    "    else: #len(old_dict) > 1:\n",
    "        \n",
    "        # fill in all missing values before the first valid value using the first valid value\n",
    "        first_key = old_dict_keys[0]\n",
    "        first_value = old_dict[first_key]\n",
    "        first_index = first_key\n",
    "        for i in range(first_index):\n",
    "            new_list[i] = first_value\n",
    "        \n",
    "        # fill in all missing values after the last valid value using the last valid value\n",
    "        last_key = old_dict_keys[-1]\n",
    "        last_value = old_dict[last_key]\n",
    "        last_index = last_key\n",
    "        for i in range(last_index+1, len(old_list)):\n",
    "            new_list[i] = last_value\n",
    "        \n",
    "        # for the remaining index missing values, fill with the average value of the its previous and next values\n",
    "        prev_value = first_value\n",
    "        old_dict_keys_idx = 0 #\n",
    "        i = first_index+1\n",
    "        while i < last_index:\n",
    "\n",
    "            if i in old_dict: # valid value, update the prev_value\n",
    "                prev_value = old_dict[i]\n",
    "                old_dict_keys_idx += 1 # update the index of the old_dict_keys\n",
    "                i += 1\n",
    "                continue\n",
    "            else:\n",
    "                # find the next_value by moving to the next index in old_dict_keys\n",
    "                next_index = old_dict_keys[old_dict_keys_idx+1]\n",
    "                next_value = old_dict[next_index]\n",
    "\n",
    "                for j in range(i, next_index):\n",
    "                    new_list[j] = float((prev_value + next_value) / 2)\n",
    "                \n",
    "                # move the i to the next_index+1\n",
    "                old_dict_keys_idx += 1 # update the index of the old_dict_keys\n",
    "                i = next_index+1\n",
    "                prev_value = next_value\n",
    "\n",
    "    # print('old_list =', old_list)\n",
    "    # print('new_list =', new_list)\n",
    "\n",
    "    return new_list\n",
    "\n",
    "def fill_with_adjacent_avg(df, col_name, avg_value):\n",
    "\n",
    "    new_col = []\n",
    "    # select each patient's rows by MaskID\n",
    "    # for maskid in tqdm(range(100001, 110252)):\n",
    "    for maskid in range(100001, 110252):\n",
    "        # print('maskid =', maskid)\n",
    "        df_patient = df[df['MaskID'] == maskid]\n",
    "        patient_col = df_patient[col_name].tolist()\n",
    "        # print('patient_col =', patient_col)\n",
    "\n",
    "        # fill the missing values with the average value of the previous and next visits\n",
    "        new_patient_col = fill_with_adjacent_avg_list(patient_col, avg_value)\n",
    "        \n",
    "        new_col.extend(new_patient_col)\n",
    "  \n",
    "    assert(len(new_col) == df.shape[0])\n",
    "    df[col_name] = new_col\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_BMI(fn):\n",
    "    df = pd.read_csv(fn)\n",
    "    \n",
    "    # for rows with 'Visit'=BLR, put the value of columns 'wt_kg_baseline' and 'ht_cm_baseline' \n",
    "    # to the columns 'ht_cm_visit' and 'wt_kg_visit'\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.loc[i, 'Visit'] == 'BLR':\n",
    "            df.loc[i, 'wt_kg_visit'] = df.loc[i, 'wt_kg_baseline']\n",
    "            df.loc[i, 'ht_cm_visit'] = df.loc[i, 'ht_cm_baseline']\n",
    "    \n",
    "    # fill in the missing values of 'wt_kg_visit' and 'ht_cm_visit' with the average value of the previous and next visits\n",
    "    # if the patient have no wt_kg_visit or ht_cm_visit value, use the average value of the whole population\n",
    "\n",
    "    # calculate the average value of the whole population, donot account for missing values\n",
    "    wt_kg_mean = df['wt_kg_visit'].mean()\n",
    "    ht_cm_mean = df['ht_cm_visit'].mean()\n",
    "    print('wt_kg_mean =', wt_kg_mean)\n",
    "    print('ht_cm_mean =', ht_cm_mean)\n",
    "\n",
    "    # fill in the missing values of 'wt_kg_visit' and 'ht_cm_visit' with -1\n",
    "    df['wt_kg_visit'] = df['wt_kg_visit'].fillna(-1)\n",
    "    df['ht_cm_visit'] = df['ht_cm_visit'].fillna(-1)\n",
    "\n",
    "    # loop through all rows\n",
    "    # df = fill_with_adjacent_avg(df, 'wt_kg_visit', wt_kg_mean)\n",
    "    # df = fill_with_adjacent_avg(df, 'ht_cm_visit', ht_cm_mean)\n",
    "\n",
    "    # calculate the BMI per visit\n",
    "    BMI = []\n",
    "    for i in range(df.shape[0]):\n",
    "        row = df.loc[i]\n",
    "        if row['wt_kg_visit'] == -1 or row['ht_cm_visit'] == -1:\n",
    "            BMI.append(-1)\n",
    "        else:\n",
    "            BMI.append(df.loc[i, 'wt_kg_visit'] / (df.loc[i, 'ht_cm_visit']/100)**2)\n",
    "            \n",
    "    df['BMI'] = BMI # the BMI is per visit\n",
    "\n",
    "    print(df.info())\n",
    "\n",
    "    # save the dataframe to a csv file\n",
    "    df.to_csv(fn.split('.')[0]+'_BMI.csv', index=False)\n",
    "\n",
    "add_BMI('data/temp/features_red_merge.csv')\n",
    "# add_BMI('data/temp/features_blue_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58871\n"
     ]
    }
   ],
   "source": [
    "# count how many rows have -1 for BMI\n",
    "df = pd.read_csv('data/temp/features_red_merge_BMI.csv')\n",
    "print(df[df['BMI'] != -1].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the patient's info\n",
    "\n",
    "1. Add the patient's information on from the following files to each row, using the `MaskID`\n",
    "  * `accord_key.csv` \n",
    "  * `cvdoutcomes.csv` , only `1046` patients have valid `type_po` entries\n",
    "  * `f07_baselinehistoryphysicalexam.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "build_dict: data/features_red/accord_key.csv data/features_red/cvdoutcomes.csv data/features_red/f07_baselinehistoryphysicalexam.csv\n",
      "df1.shape = (10251, 5)\n",
      "df2.shape = (10251, 2)\n",
      "df3.shape = (10251, 8)\n",
      "dict size = 10251\n",
      "dict[100001] = {'MaskID': 100001, 'female': 0, 'baseline_age': 60.8, 'cvd_hx_baseline': 0, 'raceclass': 'White', 'type_po': nan, 'Visit': 'BLR', 'edu_baseline': 4.0, 'yrsdiab_baseline': 26.0, 'yrstens_baseline': 6.0, 'cigarett_baseline': 2, 'wt_kg_baseline': 101.599998474121, 'ht_cm_baseline': 168.199996948242}\n",
      "dict[110251] = {'MaskID': 110251, 'female': 0, 'baseline_age': 61.3, 'cvd_hx_baseline': 0, 'raceclass': 'Black', 'type_po': nan, 'Visit': 'BLR', 'edu_baseline': 4.0, 'yrsdiab_baseline': 10.0, 'yrstens_baseline': 2.0, 'cigarett_baseline': 2, 'wt_kg_baseline': 108.099998474121, 'ht_cm_baseline': 177.800003051758}\n"
     ]
    }
   ],
   "source": [
    "# read in accord_key.csv and build a dict of dict\n",
    "# the first dict is keyed by MaskID, the second dict is keyed by column names\n",
    "def build_dict(fn1, fn2, fn3):\n",
    "    print('\\nbuild_dict:', fn1, fn2, fn3)\n",
    "    \n",
    "    df1 = pd.read_csv(fn1)\n",
    "    df2 = pd.read_csv(fn2)\n",
    "    df3 = pd.read_csv(fn3)\n",
    "    print('df1.shape =', df1.shape)\n",
    "    print('df2.shape =', df2.shape)\n",
    "    print('df3.shape =', df3.shape)\n",
    "    \n",
    "    dict = {}\n",
    "    # accord_key.csv\n",
    "    for i in range(df1.shape[0]):\n",
    "        row = df1.iloc[i]\n",
    "        MaskID = row['MaskID']\n",
    "        if MaskID not in dict:\n",
    "            dict[MaskID] = {}\n",
    "        else:\n",
    "            print('error: duplicated MaskID =', MaskID)\n",
    "            exit()\n",
    "\n",
    "        for col in df1.columns:\n",
    "            dict[MaskID][col] = row[col]\n",
    "    \n",
    "    # cvdoutcomes.csv\n",
    "    for i in range(df2.shape[0]):\n",
    "        row = df2.iloc[i]\n",
    "        MaskID = row['MaskID']\n",
    "        if MaskID not in dict:\n",
    "            dict[MaskID] = {}\n",
    "\n",
    "        for col in df2.columns:\n",
    "            dict[MaskID][col] = row[col]\n",
    "\n",
    "    # f07_baselinehistoryphysicalexam.csv\n",
    "    for i in range(df3.shape[0]):\n",
    "        row = df3.iloc[i]\n",
    "        MaskID = row['MaskID']\n",
    "        if MaskID not in dict:\n",
    "            dict[MaskID] = {}\n",
    "\n",
    "        for col in df3.columns:\n",
    "            dict[MaskID][col] = row[col]    \n",
    "\n",
    "    print('dict size =', len(dict))\n",
    "    print('dict[100001] =', dict[100001])\n",
    "    print('dict[110251] =', dict[110251])\n",
    "\n",
    "    return dict\n",
    "\n",
    "col_dict = build_dict('data/features_red/accord_key.csv', \n",
    "                      'data/features_red/cvdoutcomes.csv',\n",
    "                      'data/features_red/f07_baselinehistoryphysicalexam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "add_fea_cols: data/temp/features_red_merge_BMI.csv\n",
      "feature_names = ['MaskID', 'female', 'baseline_age', 'cvd_hx_baseline', 'raceclass', 'type_po', 'Visit', 'edu_baseline', 'yrsdiab_baseline', 'yrstens_baseline', 'cigarett_baseline', 'wt_kg_baseline', 'ht_cm_baseline']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 388771 entries, 0 to 388770\n",
      "Data columns (total 41 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   MaskID             388771 non-null  int64  \n",
      " 1   Visit              388771 non-null  object \n",
      " 2   glycemia           375659 non-null  float64\n",
      " 3   bp                 123919 non-null  float64\n",
      " 4   sbp                181991 non-null  float64\n",
      " 5   dbp                181969 non-null  float64\n",
      " 6   hr                 181752 non-null  float64\n",
      " 7   hba1c              136650 non-null  float64\n",
      " 8   chol               69061 non-null   float64\n",
      " 9   trig               69061 non-null   float64\n",
      " 10  vldl               69051 non-null   float64\n",
      " 11  ldl                69051 non-null   float64\n",
      " 12  hdl                69053 non-null   float64\n",
      " 13  fpg                79017 non-null   float64\n",
      " 14  alt                87037 non-null   float64\n",
      " 15  cpk                58217 non-null   float64\n",
      " 16  potassium          62905 non-null   float64\n",
      " 17  screat             109689 non-null  float64\n",
      " 18  gfr                109687 non-null  float64\n",
      " 19  ualb               35647 non-null   float64\n",
      " 20  ucreat             35648 non-null   float64\n",
      " 21  uacr               34216 non-null   float64\n",
      " 22  edu_baseline       388531 non-null  float64\n",
      " 23  yrsdiab_baseline   385470 non-null  float64\n",
      " 24  yrstens_baseline   295705 non-null  float64\n",
      " 25  cigarett_baseline  388771 non-null  int64  \n",
      " 26  wt_kg_baseline     388671 non-null  float64\n",
      " 27  ht_cm_baseline     388661 non-null  float64\n",
      " 28  wt_kg_visit        388771 non-null  float64\n",
      " 29  ht_cm_visit        388771 non-null  float64\n",
      " 30  oral_gmed          311310 non-null  object \n",
      " 31  medadd             7328 non-null    float64\n",
      " 32  medchg_intbp       21308 non-null   float64\n",
      " 33  medchg_stdbp       21667 non-null   float64\n",
      " 34  bp_med             104571 non-null  object \n",
      " 35  BMI                388771 non-null  float64\n",
      " 36  female             388771 non-null  int64  \n",
      " 37  baseline_age       388771 non-null  float64\n",
      " 38  cvd_hx_baseline    388771 non-null  int64  \n",
      " 39  raceclass          388771 non-null  object \n",
      " 40  type_po            36418 non-null   object \n",
      "dtypes: float64(32), int64(4), object(5)\n",
      "memory usage: 121.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# add the features in accord_key.csv and cvdoutcomes.csv to the table\n",
    "def add_fea_cols(fn, dict):\n",
    "    \n",
    "    print('\\nadd_fea_cols:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "\n",
    "    # get feature names in dict\n",
    "    first_key = list(dict.keys())[0]\n",
    "    feature_names = list(dict[first_key].keys())\n",
    "    print('feature_names =', feature_names)\n",
    "\n",
    "    fea_dict = {}\n",
    "    for fea in feature_names:\n",
    "        fea_dict[fea] = []\n",
    "\n",
    "    # add the values from the dict to the table row by row using matching MaskID\n",
    "    for i in range(df.shape[0]):\n",
    "        row = df.iloc[i]\n",
    "        MaskID = row['MaskID']\n",
    "        if MaskID in dict:\n",
    "            for fea in feature_names:\n",
    "                fea_dict[fea].append(dict[MaskID][fea])\n",
    "        else:\n",
    "            print('error: MaskID =', MaskID, 'not found')\n",
    "            exit()\n",
    "    \n",
    "    # add the new columns to the table\n",
    "    for fea in feature_names:\n",
    "        if fea == 'MaskID' or fea == 'Visit': # donot add MaskID, sicne it is already in the table\n",
    "            continue\n",
    "        df[fea] = fea_dict[fea]\n",
    "\n",
    "    print(df.info())\n",
    "    \n",
    "    df.to_csv(fn.split('.')[0]+'_addfea.csv', index=False)\n",
    "\n",
    "add_fea_cols('data/temp/features_red_merge_BMI.csv', col_dict)\n",
    "# add_fea_cols('data/temp/features_blue_merge_BMI.csv', col_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values\n",
    " \n",
    "1. `type_po`: 0 means nothing, 1 means have a valid entry of CVD death, MI, Stroke\n",
    "2. `medchg_intbp`, `medchg_stdbp`, `medadd`: 0 means No, 1 means Yes\n",
    "3. `oral_gmed`, `bp_med`: fill in missing values with 'none'\n",
    "4. yrstens_baseline, yrsdiab_baseline, edu_baseline: fill in missing values with -1\n",
    "5. Other numeric entires, fille with average of adjacent values. For patients missing entire visit records, marked as -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "handle_missing_values: data/temp/features_red_merge_BMI_addfea.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 38.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 388771 entries, 0 to 388770\n",
      "Data columns (total 41 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   MaskID             388771 non-null  int64  \n",
      " 1   Visit              388771 non-null  object \n",
      " 2   glycemia           375659 non-null  float64\n",
      " 3   bp                 123919 non-null  float64\n",
      " 4   sbp                388771 non-null  float64\n",
      " 5   dbp                388771 non-null  float64\n",
      " 6   hr                 388771 non-null  float64\n",
      " 7   hba1c              388771 non-null  float64\n",
      " 8   TC                 388771 non-null  float64\n",
      " 9   trig               388771 non-null  float64\n",
      " 10  vldl               388771 non-null  float64\n",
      " 11  ldl                388771 non-null  float64\n",
      " 12  hdl                388771 non-null  float64\n",
      " 13  fpg                388771 non-null  float64\n",
      " 14  alt                388771 non-null  float64\n",
      " 15  cpk                388771 non-null  float64\n",
      " 16  potassium          388771 non-null  float64\n",
      " 17  screat             388771 non-null  float64\n",
      " 18  gfr                388771 non-null  float64\n",
      " 19  ualb               388771 non-null  float64\n",
      " 20  ucreat             388771 non-null  float64\n",
      " 21  uacr               388771 non-null  float64\n",
      " 22  edu_baseline       388771 non-null  float64\n",
      " 23  yrsdiab_baseline   388771 non-null  float64\n",
      " 24  yrstens_baseline   388771 non-null  float64\n",
      " 25  cigarett_baseline  388771 non-null  int64  \n",
      " 26  wt_kg_baseline     388771 non-null  float64\n",
      " 27  ht_cm_baseline     388771 non-null  float64\n",
      " 28  wt_kg_visit        388771 non-null  float64\n",
      " 29  ht_cm_visit        388771 non-null  float64\n",
      " 30  oral_gmed          388771 non-null  object \n",
      " 31  medadd             388771 non-null  float64\n",
      " 32  medchg_intbp       388771 non-null  float64\n",
      " 33  medchg_stdbp       388771 non-null  float64\n",
      " 34  bp_med             388771 non-null  object \n",
      " 35  BMI                388771 non-null  float64\n",
      " 36  female             388771 non-null  int64  \n",
      " 37  baseline_age       388771 non-null  float64\n",
      " 38  cvd_hx_baseline    388771 non-null  int64  \n",
      " 39  raceclass          388771 non-null  object \n",
      " 40  type_po            388771 non-null  int64  \n",
      "dtypes: float64(32), int64(5), object(4)\n",
      "memory usage: 121.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(fn, flag):\n",
    "    print('\\nhandle_missing_values:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    # print(df.info())\n",
    "\n",
    "    # fill in the missing values in 'type_po' with 0, and convert the valid values to 1\n",
    "    df['type_po'] = df['type_po'].fillna('None')\n",
    "    new_type_po = []   \n",
    "    for i in range(df.shape[0]):\n",
    "        if df.loc[i, 'type_po'] == 'None':\n",
    "            new_type_po.append(0)\n",
    "        else:\n",
    "            new_type_po.append(1)\n",
    "    df['type_po'] = new_type_po\n",
    "    \n",
    "    # 'medchg_intbp', 'medchg_stdbp', 'medadd'\n",
    "    # fill in the missing values with 0\n",
    "    df['medchg_intbp'] = df['medchg_intbp'].fillna(0)\n",
    "    df['medchg_stdbp'] = df['medchg_stdbp'].fillna(0)\n",
    "    df['medadd'] = df['medadd'].fillna(0)\n",
    "     \n",
    "    # bpmed, oral_gmed\n",
    "    df['bp_med'] = df['bp_med'].fillna('none')\n",
    "    df['oral_gmed'] = df['oral_gmed'].fillna('none')\n",
    "\n",
    "    # wt_kg_baseline, ht_cm_baseline fill in missing values with -1 to show it is missing\n",
    "    df['wt_kg_baseline'] = df['wt_kg_baseline'].fillna(-1)\n",
    "    df['ht_cm_baseline'] = df['ht_cm_baseline'].fillna(-1)\n",
    "\n",
    "    # yrstens_baseline, yrsdiab_baseline, edu_baseline\n",
    "    # fill in missing values with -1 to show it is missing\n",
    "    df['yrstens_baseline'] = df['yrstens_baseline'].fillna(-1)\n",
    "    df['yrsdiab_baseline'] = df['yrsdiab_baseline'].fillna(-1)\n",
    "    df['edu_baseline'] = df['edu_baseline'].fillna(-1)\n",
    "    \n",
    "    # change the column name 'chol' to 'TC'\n",
    "    df.rename(columns={'chol':'TC'}, inplace=True)\n",
    "\n",
    "    # other features based on flag\n",
    "    if flag == 'red':\n",
    "        col_names = ['sbp','dbp','hr', 'hba1c', 'TC', 'trig', 'vldl', 'ldl', 'hdl', \n",
    "                     'fpg', 'alt', 'cpk', 'potassium','screat', 'gfr', 'ualb', 'ucreat','uacr']\n",
    "\n",
    "    elif flag == 'blue':\n",
    "        col_names = ['sbp', 'hba1c', 'TC', 'hdl']\n",
    "    else:\n",
    "        print('error: invalid flag =', flag)\n",
    "        exit()\n",
    "    # print(df.columns)\n",
    "    \n",
    "    for col in tqdm(col_names):\n",
    "        df[col] = df[col].fillna(-1) # fill in missing values with -1 to mark it is missing, then fill in with average of adjacent values\n",
    "        # df = fill_with_adjacent_avg(df, col, -1) # note here, for a patient with no visit record, we fill in -1 marking as missing\n",
    "    \n",
    "    print(df.info())\n",
    "\n",
    "    df.to_csv(fn.split('.')[0]+'_handlemissing.csv', index=False)\n",
    "\n",
    "handle_missing_values('data/temp/features_red_merge_BMI_addfea.csv','red')\n",
    "# handle_missing_values('data/temp/features_blue_merge_BMI_addfea.csv', 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "count_missing_values: data/temp/features_red_merge_BMI_addfea_handlemissing.csv\n",
      "columnname missing_row_count missing_MaskID_count\n",
      "MaskID 0 0\n",
      "Visit 0 0\n",
      "glycemia 0 0\n",
      "bp 0 0\n",
      "sbp 206780 8960\n",
      "dbp 206802 8960\n",
      "hr 207019 8963\n",
      "hba1c 252121 10236\n",
      "TC 319710 10240\n",
      "trig 319710 10240\n",
      "vldl 319720 10240\n",
      "ldl 319720 10240\n",
      "hdl 319718 10240\n",
      "fpg 309754 10240\n",
      "alt 301734 10201\n",
      "cpk 330554 10214\n",
      "potassium 325866 10240\n",
      "screat 279082 10240\n",
      "gfr 279084 10240\n",
      "ualb 353124 10240\n",
      "ucreat 353123 10240\n",
      "uacr 354555 10241\n",
      "edu_baseline 240 7\n",
      "yrsdiab_baseline 3301 92\n",
      "yrstens_baseline 93066 2525\n",
      "cigarett_baseline 0 0\n",
      "wt_kg_baseline 100 2\n",
      "ht_cm_baseline 110 4\n",
      "wt_kg_visit 329474 10239\n",
      "ht_cm_visit 329731 10239\n",
      "oral_gmed 0 0\n",
      "medadd 0 0\n",
      "medchg_intbp 0 0\n",
      "medchg_stdbp 0 0\n",
      "bp_med 0 0\n",
      "BMI 329900 10239\n",
      "female 0 0\n",
      "baseline_age 0 0\n",
      "cvd_hx_baseline 0 0\n",
      "raceclass 0 0\n",
      "type_po 0 0\n",
      "\n",
      "MaskID_to_remove = {100001, 100002, 100003, 100004, 100005, 100006, 100007, 100008, 100009, 100010, 100011, 100012, 100013, 100014, 100015, 100016, 100017, 100018, 100019, 100020, 100021, 100022, 100023, 100024, 100025, 100026, 100027, 100028, 100029, 100030, 100031, 100032, 100033, 100034, 100035, 100036, 100037, 100038, 100039, 100040, 100041, 100042, 100043, 100044, 100045, 100046, 100047, 100048, 100049, 100050, 100051, 100052, 100053, 100054, 100055, 100056, 100057, 100058, 100059, 100060, 100061, 100062, 100063, 100064, 100065, 100066, 100067, 100068, 100069, 100070, 100071, 100072, 100073, 100074, 100075, 100076, 100077, 100078, 100079, 100080, 100081, 100082, 100083, 100084, 100085, 100086, 100087, 100088, 100089, 100090, 100091, 100092, 100093, 100094, 100095, 100096, 100097, 100098, 100099, 100100, 100101, 100102, 100103, 100104, 100105, 100106, 100107, 100108, 100109, 100110, 100111, 100112, 100113, 100114, 100115, 100116, 100117, 100118, 100119, 100120, 100121, 100122, 100123, 100124, 100125, 100126, 100127, 100128, 100129, 100130, 100131, 100132, 100133, 100134, 100135, 100136, 100137, 100138, 100139, 100140, 100141, 100142, 100143, 100144, 100145, 100146, 100147, 100148, 100149, 100150, 100151, 100152, 100153, 100154, 100155, 100156, 100157, 100158, 100159, 100160, 100161, 100162, 100163, 100164, 100165, 100166, 100167, 100168, 100169, 100170, 100171, 100172, 100173, 100174, 100175, 100176, 100177, 100178, 100179, 100180, 100181, 100182, 100183, 100184, 100185, 100186, 100187, 100188, 100189, 100190, 100191, 100192, 100193, 100194, 100195, 100196, 100197, 100198, 100199, 100200, 100201, 100202, 100203, 100204, 100205, 100206, 100207, 100208, 100209, 100210, 100211, 100212, 100213, 100214, 100215, 100216, 100217, 100218, 100219, 100220, 100221, 100222, 100223, 100224, 100225, 100226, 100227, 100228, 100229, 100230, 100231, 100232, 100233, 100234, 100235, 100236, 100237, 100238, 100239, 100240, 100241, 100242, 100243, 100244, 100245, 100246, 100247, 100248, 100249, 100250, 100251, 100252, 100253, 100254, 100255, 100256, 100257, 100258, 100259, 100260, 100261, 100262, 100263, 100264, 100265, 100266, 100267, 100268, 100269, 100270, 100271, 100272, 100273, 100274, 100275, 100276, 100277, 100278, 100279, 100280, 100281, 100282, 100283, 100284, 100285, 100286, 100287, 100288, 100289, 100290, 100291, 100292, 100293, 100294, 100295, 100296, 100297, 100298, 100299, 100300, 100301, 100302, 100303, 100304, 100305, 100306, 100307, 100308, 100309, 100310, 100311, 100312, 100313, 100314, 100315, 100316, 100317, 100318, 100319, 100320, 100321, 100322, 100323, 100324, 100325, 100326, 100327, 100328, 100329, 100330, 100331, 100332, 100333, 100334, 100335, 100336, 100337, 100338, 100339, 100340, 100341, 100342, 100343, 100344, 100345, 100346, 100347, 100348, 100349, 100350, 100351, 100352, 100353, 100354, 100355, 100356, 100357, 100358, 100359, 100360, 100361, 100362, 100363, 100364, 100365, 100366, 100367, 100368, 100369, 100370, 100371, 100372, 100373, 100374, 100375, 100376, 100377, 100378, 100379, 100380, 100381, 100382, 100383, 100384, 100385, 100386, 100387, 100388, 100389, 100390, 100391, 100392, 100393, 100394, 100395, 100396, 100397, 100398, 100399, 100400, 100401, 100402, 100403, 100404, 100405, 100406, 100407, 100408, 100409, 100410, 100411, 100412, 100413, 100414, 100415, 100416, 100417, 100418, 100419, 100420, 100421, 100422, 100423, 100424, 100425, 100426, 100427, 100428, 100429, 100430, 100431, 100432, 100433, 100434, 100435, 100436, 100437, 100438, 100439, 100440, 100441, 100442, 100443, 100444, 100445, 100446, 100447, 100448, 100449, 100450, 100451, 100452, 100453, 100454, 100455, 100456, 100457, 100458, 100459, 100460, 100461, 100462, 100463, 100464, 100465, 100466, 100467, 100468, 100469, 100470, 100471, 100472, 100473, 100474, 100475, 100476, 100477, 100478, 100479, 100480, 100481, 100482, 100483, 100484, 100485, 100486, 100487, 100488, 100489, 100490, 100491, 100492, 100493, 100494, 100495, 100496, 100497, 100498, 100499, 100500, 100501, 100502, 100503, 100504, 100505, 100506, 100507, 100508, 100509, 100510, 100511, 100512, 100513, 100514, 100515, 100516, 100517, 100518, 100519, 100520, 100521, 100522, 100523, 100524, 100525, 100526, 100527, 100528, 100529, 100530, 100531, 100532, 100533, 100534, 100535, 100536, 100537, 100538, 100539, 100540, 100541, 100542, 100543, 100544, 100545, 100546, 100547, 100548, 100549, 100550, 100551, 100552, 100553, 100554, 100555, 100556, 100557, 100558, 100559, 100560, 100561, 100562, 100563, 100564, 100565, 100566, 100567, 100568, 100569, 100570, 100571, 100572, 100573, 100574, 100575, 100576, 100577, 100578, 100579, 100580, 100581, 100582, 100583, 100584, 100585, 100586, 100587, 100588, 100589, 100590, 100591, 100592, 100593, 100594, 100595, 100596, 100597, 100598, 100599, 100600, 100601, 100602, 100603, 100604, 100605, 100606, 100607, 100608, 100609, 100610, 100611, 100612, 100613, 100614, 100615, 100616, 100617, 100618, 100619, 100620, 100621, 100622, 100623, 100624, 100625, 100626, 100627, 100628, 100629, 100630, 100631, 100632, 100633, 100634, 100635, 100636, 100637, 100638, 100639, 100640, 100641, 100642, 100643, 100644, 100645, 100646, 100647, 100648, 100649, 100650, 100651, 100652, 100653, 100654, 100655, 100656, 100657, 100658, 100659, 100660, 100661, 100662, 100663, 100664, 100665, 100666, 100667, 100668, 100669, 100670, 100671, 100672, 100673, 100674, 100675, 100676, 100677, 100678, 100679, 100680, 100681, 100682, 100683, 100684, 100685, 100686, 100687, 100688, 100689, 100690, 100691, 100692, 100693, 100694, 100695, 100696, 100697, 100698, 100699, 100700, 100701, 100702, 100703, 100704, 100705, 100706, 100707, 100708, 100709, 100710, 100711, 100712, 100713, 100714, 100715, 100716, 100717, 100718, 100719, 100720, 100721, 100722, 100723, 100724, 100725, 100726, 100727, 100728, 100729, 100730, 100731, 100732, 100733, 100734, 100735, 100736, 100737, 100738, 100739, 100740, 100741, 100742, 100743, 100744, 100745, 100746, 100747, 100748, 100749, 100750, 100751, 100752, 100753, 100754, 100755, 100756, 100757, 100758, 100759, 100760, 100761, 100762, 100763, 100764, 100765, 100766, 100767, 100768, 100769, 100770, 100771, 100772, 100773, 100774, 100775, 100776, 100777, 100778, 100779, 100780, 100781, 100782, 100783, 100784, 100785, 100786, 100787, 100788, 100789, 100790, 100791, 100792, 100793, 100794, 100795, 100796, 100797, 100798, 100799, 100800, 100801, 100802, 100803, 100804, 100805, 100806, 100807, 100808, 100809, 100810, 100811, 100812, 100813, 100814, 100815, 100816, 100817, 100818, 100819, 100820, 100821, 100822, 100823, 100824, 100825, 100826, 100827, 100828, 100829, 100830, 100831, 100832, 100833, 100834, 100835, 100836, 100837, 100838, 100839, 100840, 100841, 100842, 100843, 100844, 100845, 100846, 100847, 100848, 100849, 100850, 100851, 100852, 100853, 100854, 100855, 100856, 100857, 100858, 100859, 100860, 100861, 100862, 100863, 100864, 100865, 100866, 100867, 100868, 100869, 100870, 100871, 100872, 100873, 100874, 100875, 100876, 100877, 100878, 100879, 100880, 100881, 100882, 100883, 100884, 100885, 100886, 100887, 100888, 100889, 100890, 100891, 100892, 100893, 100894, 100895, 100896, 100897, 100898, 100899, 100900, 100901, 100902, 100903, 100904, 100905, 100906, 100907, 100908, 100909, 100910, 100911, 100912, 100913, 100914, 100915, 100916, 100917, 100918, 100919, 100920, 100921, 100922, 100923, 100924, 100925, 100926, 100927, 100928, 100929, 100930, 100931, 100932, 100933, 100934, 100935, 100936, 100937, 100938, 100939, 100940, 100941, 100942, 100943, 100944, 100945, 100946, 100947, 100948, 100949, 100950, 100951, 100952, 100953, 100954, 100955, 100956, 100957, 100958, 100959, 100960, 100961, 100962, 100963, 100964, 100966, 100967, 100968, 100969, 100970, 100971, 100972, 100973, 100974, 100975, 100976, 100977, 100978, 100979, 100980, 100981, 100982, 100983, 100984, 100985, 100986, 100987, 100988, 100989, 100990, 100991, 100992, 100993, 100994, 100995, 100996, 100997, 100998, 100999, 101000, 101001, 101002, 101003, 101004, 101005, 101006, 101007, 101008, 101009, 101010, 101011, 101012, 101013, 101014, 101015, 101016, 101017, 101018, 101019, 101020, 101021, 101022, 101023, 101024, 101025, 101026, 101027, 101028, 101029, 101030, 101031, 101032, 101033, 101034, 101035, 101036, 101037, 101038, 101039, 101040, 101041, 101042, 101043, 101044, 101045, 101046, 101047, 101048, 101049, 101050, 101051, 101052, 101053, 101054, 101055, 101056, 101057, 101058, 101059, 101060, 101061, 101062, 101063, 101064, 101065, 101066, 101067, 101068, 101069, 101070, 101071, 101072, 101073, 101074, 101075, 101076, 101077, 101078, 101079, 101080, 101081, 101082, 101083, 101084, 101085, 101086, 101087, 101088, 101089, 101090, 101091, 101092, 101093, 101094, 101095, 101096, 101097, 101098, 101099, 101100, 101101, 101102, 101103, 101104, 101105, 101106, 101107, 101108, 101109, 101110, 101111, 101112, 101113, 101114, 101115, 101116, 101117, 101118, 101119, 101120, 101121, 101122, 101123, 101124, 101125, 101126, 101127, 101128, 101129, 101130, 101131, 101132, 101133, 101134, 101135, 101136, 101137, 101138, 101139, 101140, 101141, 101142, 101143, 101144, 101145, 101146, 101147, 101148, 101149, 101150, 101151, 101152, 101153, 101154, 101155, 101156, 101157, 101158, 101159, 101160, 101161, 101162, 101163, 101164, 101165, 101166, 101167, 101168, 101169, 101170, 101171, 101172, 101173, 101174, 101175, 101176, 101177, 101178, 101179, 101180, 101181, 101182, 101183, 101184, 101185, 101186, 101187, 101188, 101189, 101190, 101191, 101192, 101193, 101194, 101195, 101196, 101197, 101198, 101199, 101200, 101201, 101202, 101203, 101204, 101205, 101206, 101207, 101208, 101209, 101210, 101211, 101212, 101213, 101214, 101215, 101216, 101217, 101218, 101219, 101220, 101221, 101222, 101223, 101224, 101225, 101226, 101227, 101228, 101229, 101230, 101231, 101232, 101233, 101234, 101235, 101236, 101237, 101238, 101239, 101240, 101241, 101242, 101243, 101244, 101245, 101246, 101247, 101248, 101249, 101250, 101251, 101252, 101253, 101254, 101255, 101256, 101257, 101258, 101259, 101260, 101261, 101262, 101263, 101264, 101265, 101266, 101267, 101268, 101269, 101270, 101271, 101272, 101273, 101274, 101275, 101276, 101277, 101278, 101279, 101280, 101281, 101282, 101283, 101284, 101285, 101286, 101287, 101288, 101289, 101290, 101291, 101292, 101293, 101294, 101295, 101296, 101297, 101298, 101299, 101300, 101301, 101302, 101303, 101304, 101305, 101306, 101307, 101308, 101309, 101310, 101311, 101312, 101313, 101314, 101315, 101316, 101317, 101318, 101319, 101320, 101321, 101322, 101323, 101324, 101325, 101326, 101327, 101328, 101329, 101330, 101331, 101332, 101333, 101334, 101335, 101336, 101337, 101338, 101339, 101340, 101341, 101342, 101343, 101344, 101345, 101346, 101347, 101348, 101349, 101350, 101351, 101352, 101353, 101354, 101355, 101356, 101357, 101358, 101359, 101360, 101361, 101362, 101363, 101364, 101365, 101366, 101367, 101368, 101369, 101370, 101371, 101372, 101373, 101374, 101375, 101376, 101377, 101378, 101379, 101380, 101381, 101382, 101383, 101384, 101385, 101386, 101387, 101388, 101389, 101390, 101391, 101392, 101393, 101394, 101395, 101396, 101397, 101398, 101399, 101400, 101401, 101402, 101403, 101404, 101405, 101406, 101407, 101408, 101409, 101410, 101411, 101412, 101413, 101414, 101415, 101416, 101417, 101418, 101419, 101420, 101421, 101422, 101423, 101424, 101425, 101426, 101427, 101428, 101429, 101430, 101431, 101432, 101433, 101434, 101435, 101436, 101437, 101438, 101439, 101440, 101441, 101442, 101443, 101444, 101445, 101446, 101447, 101448, 101449, 101450, 101451, 101452, 101453, 101454, 101455, 101456, 101457, 101458, 101459, 101460, 101461, 101462, 101463, 101464, 101465, 101466, 101467, 101468, 101469, 101470, 101471, 101472, 101473, 101474, 101475, 101476, 101477, 101478, 101479, 101480, 101481, 101482, 101483, 101484, 101485, 101486, 101487, 101488, 101489, 101490, 101491, 101492, 101493, 101494, 101495, 101496, 101497, 101498, 101499, 101500, 101501, 101502, 101503, 101504, 101505, 101506, 101507, 101508, 101509, 101510, 101511, 101512, 101513, 101514, 101515, 101516, 101517, 101518, 101519, 101520, 101521, 101522, 101523, 101524, 101525, 101526, 101527, 101528, 101529, 101530, 101531, 101532, 101533, 101534, 101535, 101536, 101537, 101538, 101539, 101540, 101541, 101542, 101543, 101544, 101545, 101546, 101547, 101548, 101549, 101550, 101551, 101552, 101553, 101554, 101555, 101556, 101557, 101558, 101559, 101560, 101561, 101562, 101563, 101564, 101565, 101566, 101567, 101568, 101569, 101570, 101571, 101572, 101573, 101574, 101575, 101576, 101577, 101578, 101579, 101580, 101581, 101582, 101583, 101584, 101585, 101586, 101587, 101588, 101589, 101590, 101591, 101592, 101593, 101594, 101595, 101596, 101597, 101598, 101599, 101600, 101601, 101602, 101603, 101604, 101605, 101606, 101607, 101608, 101609, 101610, 101611, 101612, 101613, 101614, 101615, 101616, 101617, 101618, 101619, 101620, 101621, 101622, 101623, 101624, 101625, 101626, 101627, 101628, 101629, 101630, 101631, 101632, 101633, 101634, 101635, 101636, 101637, 101638, 101639, 101640, 101641, 101642, 101643, 101644, 101645, 101646, 101647, 101648, 101649, 101650, 101651, 101652, 101653, 101654, 101655, 101656, 101657, 101658, 101659, 101660, 101661, 101662, 101663, 101664, 101665, 101666, 101667, 101668, 101669, 101670, 101671, 101672, 101673, 101674, 101675, 101676, 101677, 101678, 101679, 101680, 101681, 101682, 101683, 101684, 101685, 101686, 101687, 101688, 101689, 101690, 101691, 101692, 101693, 101694, 101695, 101696, 101697, 101698, 101699, 101700, 101701, 101702, 101703, 101704, 101705, 101706, 101707, 101708, 101709, 101710, 101711, 101712, 101713, 101714, 101715, 101716, 101717, 101718, 101719, 101720, 101721, 101722, 101723, 101724, 101725, 101726, 101727, 101728, 101729, 101730, 101731, 101732, 101733, 101734, 101735, 101736, 101737, 101738, 101739, 101740, 101741, 101742, 101743, 101744, 101745, 101746, 101747, 101748, 101749, 101750, 101751, 101752, 101753, 101754, 101755, 101756, 101757, 101758, 101759, 101760, 101761, 101762, 101763, 101764, 101765, 101766, 101767, 101768, 101769, 101770, 101771, 101772, 101773, 101774, 101775, 101776, 101777, 101778, 101779, 101780, 101781, 101782, 101783, 101784, 101785, 101786, 101787, 101788, 101789, 101790, 101791, 101792, 101793, 101794, 101795, 101796, 101797, 101798, 101799, 101800, 101801, 101802, 101803, 101804, 101805, 101806, 101807, 101808, 101809, 101810, 101811, 101812, 101813, 101814, 101815, 101816, 101817, 101818, 101819, 101820, 101821, 101822, 101823, 101824, 101825, 101826, 101827, 101828, 101829, 101830, 101831, 101832, 101833, 101834, 101835, 101836, 101837, 101838, 101839, 101840, 101841, 101842, 101843, 101844, 101845, 101846, 101847, 101848, 101849, 101850, 101851, 101852, 101853, 101854, 101855, 101856, 101857, 101858, 101859, 101860, 101861, 101862, 101863, 101864, 101865, 101866, 101867, 101868, 101869, 101870, 101871, 101872, 101873, 101874, 101875, 101876, 101877, 101878, 101879, 101880, 101881, 101882, 101883, 101884, 101885, 101886, 101887, 101888, 101889, 101890, 101891, 101892, 101893, 101894, 101895, 101896, 101897, 101898, 101899, 101900, 101901, 101902, 101903, 101904, 101905, 101906, 101907, 101908, 101909, 101910, 101911, 101912, 101913, 101914, 101915, 101916, 101917, 101918, 101919, 101920, 101921, 101922, 101923, 101924, 101925, 101926, 101927, 101928, 101929, 101930, 101931, 101932, 101933, 101934, 101935, 101936, 101937, 101938, 101939, 101940, 101941, 101942, 101943, 101944, 101945, 101946, 101947, 101948, 101949, 101950, 101951, 101952, 101953, 101954, 101955, 101956, 101957, 101958, 101959, 101960, 101961, 101962, 101963, 101964, 101965, 101966, 101967, 101968, 101969, 101970, 101971, 101972, 101973, 101974, 101975, 101976, 101977, 101978, 101979, 101980, 101981, 101982, 101983, 101984, 101985, 101986, 101987, 101988, 101989, 101990, 101991, 101992, 101993, 101994, 101995, 101996, 101997, 101998, 101999, 102000, 102001, 102002, 102003, 102004, 102005, 102006, 102007, 102008, 102009, 102010, 102011, 102012, 102013, 102014, 102015, 102016, 102017, 102018, 102019, 102020, 102021, 102022, 102023, 102024, 102025, 102026, 102027, 102028, 102029, 102030, 102031, 102032, 102033, 102034, 102035, 102036, 102037, 102038, 102039, 102040, 102041, 102042, 102043, 102044, 102045, 102046, 102047, 102048, 102049, 102050, 102051, 102052, 102053, 102054, 102055, 102056, 102057, 102058, 102059, 102060, 102061, 102062, 102063, 102064, 102065, 102066, 102067, 102068, 102069, 102070, 102071, 102072, 102073, 102074, 102075, 102076, 102077, 102078, 102079, 102080, 102081, 102082, 102083, 102084, 102085, 102086, 102087, 102088, 102089, 102090, 102091, 102092, 102093, 102094, 102095, 102096, 102097, 102098, 102099, 102100, 102101, 102102, 102103, 102104, 102105, 102106, 102107, 102108, 102109, 102110, 102111, 102112, 102113, 102114, 102115, 102116, 102117, 102118, 102119, 102120, 102121, 102122, 102123, 102124, 102125, 102126, 102127, 102128, 102129, 102130, 102131, 102132, 102133, 102134, 102135, 102136, 102137, 102138, 102139, 102140, 102141, 102142, 102143, 102144, 102145, 102146, 102147, 102148, 102149, 102150, 102151, 102152, 102153, 102154, 102155, 102156, 102157, 102158, 102159, 102160, 102161, 102162, 102163, 102164, 102165, 102166, 102167, 102168, 102169, 102170, 102171, 102172, 102173, 102174, 102175, 102176, 102177, 102178, 102179, 102180, 102181, 102182, 102183, 102184, 102185, 102186, 102187, 102188, 102189, 102190, 102191, 102192, 102193, 102194, 102195, 102196, 102197, 102198, 102199, 102200, 102201, 102202, 102203, 102204, 102205, 102206, 102207, 102208, 102209, 102210, 102211, 102212, 102213, 102214, 102215, 102216, 102217, 102218, 102219, 102220, 102221, 102222, 102223, 102224, 102225, 102226, 102227, 102228, 102229, 102230, 102231, 102232, 102233, 102234, 102235, 102236, 102237, 102238, 102239, 102240, 102241, 102242, 102243, 102244, 102245, 102246, 102247, 102248, 102249, 102250, 102251, 102252, 102253, 102254, 102255, 102256, 102257, 102258, 102259, 102260, 102261, 102262, 102263, 102264, 102265, 102266, 102267, 102268, 102269, 102270, 102271, 102272, 102273, 102274, 102275, 102276, 102277, 102278, 102279, 102280, 102281, 102282, 102283, 102284, 102285, 102287, 102288, 102289, 102290, 102291, 102292, 102293, 102294, 102295, 102296, 102297, 102298, 102299, 102300, 102301, 102302, 102303, 102304, 102305, 102306, 102307, 102308, 102309, 102310, 102311, 102312, 102313, 102314, 102315, 102316, 102317, 102318, 102319, 102320, 102321, 102322, 102323, 102324, 102325, 102326, 102327, 102328, 102329, 102330, 102331, 102332, 102333, 102334, 102335, 102336, 102337, 102338, 102339, 102340, 102341, 102342, 102343, 102344, 102345, 102346, 102347, 102348, 102349, 102350, 102351, 102352, 102353, 102354, 102355, 102356, 102357, 102358, 102359, 102360, 102361, 102362, 102363, 102364, 102365, 102366, 102367, 102368, 102369, 102370, 102371, 102372, 102373, 102374, 102375, 102376, 102377, 102378, 102379, 102380, 102381, 102382, 102383, 102384, 102385, 102386, 102387, 102388, 102389, 102390, 102391, 102392, 102393, 102394, 102395, 102396, 102397, 102398, 102399, 102400, 102401, 102402, 102403, 102404, 102405, 102406, 102407, 102408, 102409, 102410, 102411, 102412, 102413, 102414, 102415, 102416, 102417, 102418, 102419, 102420, 102421, 102422, 102423, 102424, 102425, 102426, 102427, 102428, 102429, 102430, 102431, 102432, 102433, 102434, 102435, 102436, 102437, 102438, 102439, 102440, 102441, 102442, 102443, 102444, 102445, 102446, 102447, 102448, 102449, 102450, 102451, 102452, 102453, 102454, 102455, 102456, 102457, 102458, 102459, 102460, 102461, 102462, 102463, 102464, 102465, 102466, 102467, 102468, 102469, 102470, 102471, 102472, 102473, 102474, 102475, 102476, 102477, 102478, 102479, 102480, 102481, 102482, 102483, 102484, 102485, 102486, 102487, 102488, 102489, 102490, 102491, 102492, 102493, 102494, 102495, 102496, 102497, 102498, 102499, 102500, 102501, 102502, 102503, 102504, 102505, 102506, 102507, 102508, 102509, 102510, 102511, 102512, 102513, 102514, 102515, 102516, 102517, 102518, 102519, 102520, 102521, 102522, 102523, 102524, 102525, 102526, 102527, 102528, 102529, 102530, 102531, 102532, 102533, 102534, 102535, 102536, 102537, 102538, 102539, 102540, 102541, 102542, 102543, 102544, 102545, 102546, 102547, 102548, 102549, 102550, 102551, 102552, 102553, 102554, 102555, 102556, 102557, 102558, 102559, 102560, 102561, 102562, 102563, 102564, 102565, 102566, 102567, 102568, 102569, 102570, 102571, 102572, 102573, 102574, 102575, 102576, 102577, 102578, 102579, 102580, 102581, 102582, 102583, 102584, 102585, 102586, 102587, 102588, 102589, 102590, 102591, 102592, 102593, 102594, 102595, 102596, 102597, 102598, 102599, 102600, 102601, 102602, 102603, 102604, 102605, 102606, 102607, 102608, 102609, 102610, 102611, 102612, 102613, 102614, 102615, 102616, 102617, 102618, 102619, 102620, 102621, 102622, 102623, 102624, 102625, 102626, 102627, 102628, 102629, 102630, 102631, 102632, 102633, 102634, 102635, 102636, 102637, 102638, 102639, 102640, 102641, 102642, 102643, 102644, 102645, 102646, 102647, 102648, 102649, 102650, 102651, 102652, 102653, 102654, 102655, 102656, 102657, 102658, 102659, 102660, 102661, 102662, 102663, 102664, 102665, 102666, 102667, 102668, 102669, 102670, 102671, 102672, 102673, 102674, 102675, 102676, 102677, 102678, 102679, 102680, 102681, 102682, 102683, 102684, 102685, 102686, 102687, 102688, 102689, 102690, 102691, 102692, 102693, 102694, 102695, 102696, 102697, 102698, 102699, 102700, 102701, 102702, 102703, 102704, 102705, 102706, 102707, 102708, 102709, 102710, 102711, 102712, 102713, 102714, 102715, 102716, 102717, 102718, 102719, 102720, 102721, 102722, 102723, 102724, 102725, 102726, 102727, 102728, 102729, 102730, 102731, 102732, 102733, 102734, 102735, 102736, 102737, 102738, 102739, 102740, 102741, 102742, 102743, 102744, 102745, 102746, 102747, 102748, 102749, 102750, 102751, 102752, 102753, 102754, 102755, 102756, 102757, 102758, 102759, 102760, 102761, 102762, 102763, 102764, 102765, 102766, 102767, 102768, 102769, 102770, 102771, 102772, 102773, 102774, 102775, 102776, 102777, 102778, 102779, 102780, 102781, 102782, 102783, 102784, 102785, 102786, 102787, 102788, 102789, 102790, 102791, 102792, 102793, 102794, 102795, 102796, 102797, 102798, 102799, 102800, 102801, 102802, 102803, 102804, 102805, 102806, 102807, 102808, 102809, 102810, 102811, 102812, 102813, 102814, 102815, 102816, 102817, 102818, 102819, 102820, 102821, 102822, 102823, 102824, 102825, 102826, 102827, 102828, 102829, 102830, 102831, 102832, 102833, 102834, 102835, 102836, 102837, 102838, 102839, 102840, 102841, 102842, 102843, 102844, 102845, 102846, 102847, 102848, 102849, 102850, 102851, 102852, 102853, 102854, 102855, 102856, 102857, 102858, 102859, 102860, 102861, 102862, 102863, 102864, 102865, 102866, 102867, 102868, 102869, 102870, 102871, 102872, 102873, 102874, 102875, 102876, 102877, 102878, 102879, 102880, 102881, 102882, 102883, 102884, 102885, 102886, 102887, 102888, 102889, 102890, 102891, 102892, 102893, 102894, 102895, 102896, 102897, 102898, 102899, 102900, 102901, 102902, 102903, 102904, 102905, 102906, 102907, 102908, 102909, 102910, 102911, 102912, 102913, 102914, 102915, 102916, 102917, 102918, 102919, 102920, 102921, 102922, 102923, 102924, 102925, 102926, 102927, 102928, 102929, 102930, 102931, 102932, 102933, 102934, 102935, 102936, 102937, 102938, 102939, 102940, 102941, 102942, 102943, 102944, 102945, 102946, 102947, 102948, 102949, 102950, 102951, 102952, 102953, 102954, 102955, 102956, 102957, 102958, 102959, 102960, 102961, 102962, 102963, 102964, 102965, 102966, 102967, 102968, 102969, 102970, 102971, 102972, 102973, 102974, 102975, 102976, 102977, 102978, 102979, 102980, 102981, 102982, 102983, 102984, 102985, 102986, 102987, 102988, 102989, 102990, 102991, 102992, 102993, 102994, 102995, 102996, 102997, 102998, 102999, 103000, 103001, 103002, 103003, 103004, 103005, 103006, 103007, 103008, 103009, 103010, 103011, 103012, 103013, 103014, 103015, 103016, 103017, 103018, 103019, 103020, 103021, 103022, 103023, 103024, 103025, 103026, 103027, 103028, 103029, 103030, 103031, 103032, 103033, 103034, 103035, 103036, 103037, 103038, 103039, 103040, 103041, 103042, 103043, 103044, 103045, 103046, 103047, 103048, 103049, 103050, 103051, 103052, 103053, 103054, 103055, 103056, 103057, 103058, 103059, 103060, 103061, 103062, 103063, 103064, 103065, 103066, 103067, 103068, 103069, 103070, 103071, 103072, 103073, 103074, 103075, 103076, 103077, 103078, 103079, 103080, 103081, 103082, 103083, 103084, 103085, 103086, 103087, 103088, 103089, 103090, 103091, 103092, 103093, 103094, 103095, 103096, 103097, 103098, 103099, 103100, 103101, 103102, 103103, 103104, 103105, 103106, 103107, 103108, 103109, 103110, 103111, 103112, 103113, 103114, 103115, 103116, 103117, 103118, 103119, 103120, 103121, 103122, 103123, 103124, 103125, 103126, 103127, 103128, 103129, 103130, 103131, 103132, 103133, 103134, 103135, 103136, 103137, 103138, 103139, 103140, 103141, 103142, 103143, 103144, 103145, 103146, 103147, 103148, 103149, 103150, 103151, 103152, 103153, 103154, 103155, 103156, 103157, 103158, 103159, 103160, 103161, 103162, 103163, 103164, 103165, 103166, 103167, 103168, 103169, 103170, 103171, 103172, 103173, 103174, 103175, 103176, 103177, 103178, 103179, 103180, 103181, 103182, 103183, 103184, 103185, 103186, 103187, 103188, 103189, 103190, 103191, 103192, 103193, 103194, 103195, 103196, 103197, 103198, 103199, 103200, 103201, 103202, 103203, 103204, 103205, 103206, 103207, 103208, 103209, 103210, 103211, 103212, 103213, 103214, 103215, 103216, 103217, 103218, 103219, 103220, 103221, 103222, 103223, 103224, 103225, 103226, 103227, 103228, 103229, 103230, 103231, 103232, 103233, 103234, 103235, 103236, 103237, 103238, 103239, 103240, 103241, 103242, 103243, 103244, 103245, 103246, 103247, 103248, 103249, 103250, 103251, 103252, 103253, 103254, 103255, 103256, 103257, 103258, 103259, 103260, 103261, 103262, 103263, 103264, 103265, 103266, 103267, 103268, 103269, 103270, 103271, 103272, 103273, 103274, 103275, 103276, 103277, 103278, 103279, 103280, 103281, 103282, 103283, 103284, 103285, 103286, 103287, 103288, 103289, 103290, 103291, 103292, 103293, 103294, 103295, 103296, 103297, 103298, 103299, 103300, 103301, 103302, 103303, 103304, 103305, 103306, 103307, 103308, 103309, 103310, 103311, 103312, 103313, 103314, 103315, 103316, 103317, 103318, 103319, 103320, 103321, 103322, 103323, 103324, 103325, 103326, 103327, 103328, 103329, 103330, 103331, 103332, 103333, 103334, 103335, 103336, 103337, 103338, 103339, 103340, 103341, 103342, 103343, 103344, 103345, 103346, 103347, 103348, 103349, 103350, 103351, 103352, 103353, 103354, 103355, 103356, 103357, 103358, 103359, 103360, 103361, 103362, 103363, 103364, 103365, 103366, 103367, 103368, 103369, 103370, 103371, 103372, 103373, 103374, 103375, 103376, 103377, 103378, 103379, 103380, 103381, 103382, 103383, 103384, 103385, 103386, 103387, 103388, 103389, 103390, 103391, 103392, 103393, 103394, 103395, 103396, 103397, 103398, 103399, 103400, 103401, 103402, 103403, 103404, 103405, 103406, 103407, 103408, 103409, 103410, 103411, 103412, 103413, 103414, 103415, 103416, 103417, 103418, 103419, 103420, 103421, 103422, 103423, 103424, 103425, 103426, 103427, 103428, 103429, 103430, 103431, 103432, 103433, 103434, 103435, 103436, 103437, 103438, 103439, 103440, 103441, 103442, 103443, 103444, 103445, 103446, 103447, 103448, 103449, 103450, 103451, 103452, 103453, 103454, 103455, 103456, 103457, 103458, 103459, 103460, 103461, 103462, 103463, 103464, 103465, 103466, 103467, 103468, 103469, 103470, 103471, 103472, 103473, 103474, 103475, 103476, 103477, 103478, 103479, 103480, 103481, 103482, 103483, 103484, 103485, 103486, 103487, 103488, 103489, 103490, 103491, 103492, 103493, 103494, 103495, 103496, 103497, 103498, 103499, 103500, 103501, 103502, 103503, 103504, 103505, 103506, 103507, 103508, 103509, 103510, 103511, 103512, 103513, 103514, 103515, 103516, 103517, 103518, 103519, 103520, 103521, 103522, 103523, 103524, 103525, 103526, 103527, 103528, 103529, 103530, 103531, 103532, 103533, 103534, 103535, 103536, 103537, 103538, 103539, 103540, 103541, 103542, 103543, 103544, 103545, 103546, 103547, 103548, 103549, 103550, 103551, 103552, 103553, 103554, 103555, 103556, 103557, 103558, 103559, 103560, 103561, 103562, 103563, 103564, 103565, 103566, 103567, 103568, 103569, 103570, 103571, 103572, 103573, 103574, 103575, 103576, 103577, 103578, 103579, 103580, 103581, 103582, 103583, 103584, 103585, 103586, 103587, 103588, 103589, 103590, 103591, 103592, 103593, 103594, 103595, 103596, 103597, 103598, 103599, 103600, 103601, 103602, 103603, 103604, 103605, 103606, 103607, 103608, 103609, 103610, 103611, 103612, 103613, 103614, 103615, 103616, 103617, 103618, 103619, 103620, 103621, 103622, 103623, 103624, 103625, 103626, 103627, 103628, 103629, 103630, 103631, 103632, 103633, 103634, 103635, 103636, 103637, 103638, 103639, 103640, 103641, 103642, 103643, 103644, 103645, 103646, 103647, 103648, 103649, 103650, 103651, 103652, 103653, 103654, 103655, 103656, 103657, 103658, 103659, 103660, 103661, 103662, 103663, 103664, 103665, 103666, 103667, 103668, 103669, 103670, 103671, 103672, 103673, 103674, 103675, 103676, 103677, 103678, 103679, 103680, 103681, 103682, 103683, 103684, 103685, 103686, 103687, 103688, 103689, 103690, 103691, 103692, 103693, 103694, 103695, 103696, 103697, 103698, 103699, 103700, 103701, 103702, 103703, 103704, 103705, 103706, 103707, 103708, 103709, 103710, 103711, 103712, 103713, 103714, 103715, 103716, 103717, 103718, 103719, 103720, 103721, 103722, 103723, 103724, 103725, 103726, 103727, 103728, 103729, 103730, 103731, 103732, 103733, 103734, 103735, 103736, 103737, 103738, 103739, 103740, 103741, 103742, 103743, 103744, 103745, 103746, 103747, 103748, 103749, 103750, 103751, 103752, 103753, 103754, 103755, 103756, 103757, 103758, 103759, 103760, 103761, 103762, 103763, 103764, 103765, 103766, 103767, 103768, 103769, 103770, 103771, 103772, 103773, 103774, 103775, 103776, 103777, 103778, 103779, 103780, 103781, 103782, 103783, 103784, 103785, 103786, 103787, 103788, 103789, 103790, 103791, 103792, 103793, 103794, 103795, 103796, 103797, 103798, 103799, 103800, 103801, 103802, 103803, 103804, 103805, 103806, 103807, 103808, 103809, 103810, 103811, 103812, 103813, 103814, 103815, 103816, 103817, 103818, 103819, 103820, 103821, 103822, 103823, 103824, 103825, 103826, 103827, 103828, 103829, 103830, 103831, 103832, 103833, 103834, 103835, 103836, 103837, 103838, 103839, 103840, 103841, 103842, 103843, 103844, 103845, 103846, 103847, 103848, 103849, 103850, 103851, 103852, 103853, 103854, 103855, 103856, 103857, 103858, 103859, 103860, 103861, 103862, 103863, 103864, 103865, 103866, 103867, 103868, 103869, 103870, 103871, 103872, 103873, 103874, 103875, 103876, 103877, 103878, 103879, 103880, 103881, 103882, 103883, 103884, 103885, 103886, 103887, 103888, 103889, 103890, 103891, 103892, 103893, 103894, 103895, 103896, 103897, 103898, 103899, 103900, 103901, 103902, 103903, 103904, 103905, 103906, 103907, 103908, 103909, 103910, 103911, 103912, 103913, 103914, 103915, 103916, 103917, 103918, 103919, 103920, 103921, 103922, 103923, 103924, 103925, 103926, 103927, 103928, 103929, 103930, 103931, 103932, 103933, 103934, 103935, 103936, 103937, 103938, 103939, 103940, 103941, 103942, 103943, 103944, 103945, 103946, 103947, 103948, 103949, 103950, 103951, 103952, 103953, 103954, 103955, 103956, 103957, 103958, 103959, 103960, 103961, 103962, 103963, 103964, 103965, 103966, 103967, 103968, 103969, 103970, 103971, 103972, 103973, 103974, 103975, 103976, 103977, 103978, 103979, 103980, 103981, 103982, 103983, 103984, 103985, 103986, 103987, 103988, 103989, 103990, 103991, 103992, 103993, 103994, 103995, 103996, 103997, 103998, 103999, 104000, 104001, 104002, 104003, 104004, 104005, 104006, 104007, 104008, 104009, 104010, 104011, 104012, 104013, 104014, 104015, 104016, 104017, 104018, 104019, 104020, 104021, 104022, 104023, 104024, 104025, 104026, 104027, 104028, 104029, 104030, 104031, 104032, 104033, 104034, 104035, 104036, 104037, 104038, 104039, 104040, 104041, 104042, 104043, 104044, 104045, 104046, 104047, 104048, 104049, 104050, 104051, 104052, 104053, 104054, 104055, 104056, 104057, 104058, 104059, 104060, 104061, 104062, 104063, 104064, 104065, 104066, 104067, 104068, 104069, 104070, 104071, 104072, 104073, 104074, 104075, 104076, 104077, 104078, 104079, 104080, 104081, 104082, 104083, 104084, 104085, 104086, 104087, 104088, 104089, 104090, 104091, 104092, 104093, 104094, 104095, 104096, 104097, 104098, 104099, 104100, 104101, 104102, 104103, 104104, 104105, 104106, 104107, 104108, 104109, 104110, 104111, 104112, 104113, 104114, 104115, 104116, 104117, 104118, 104119, 104120, 104121, 104122, 104123, 104124, 104125, 104126, 104127, 104128, 104129, 104130, 104131, 104132, 104133, 104134, 104135, 104136, 104137, 104138, 104139, 104140, 104141, 104142, 104143, 104144, 104145, 104146, 104147, 104148, 104149, 104150, 104151, 104152, 104153, 104154, 104155, 104156, 104157, 104158, 104159, 104160, 104161, 104162, 104163, 104164, 104165, 104166, 104167, 104168, 104169, 104170, 104171, 104172, 104173, 104174, 104175, 104176, 104177, 104178, 104179, 104180, 104181, 104182, 104183, 104184, 104185, 104186, 104187, 104188, 104189, 104190, 104191, 104192, 104193, 104194, 104195, 104196, 104197, 104198, 104199, 104200, 104201, 104202, 104203, 104204, 104205, 104206, 104207, 104208, 104209, 104210, 104211, 104212, 104213, 104214, 104215, 104216, 104217, 104218, 104219, 104220, 104221, 104222, 104223, 104224, 104225, 104226, 104227, 104228, 104229, 104230, 104231, 104232, 104233, 104234, 104235, 104236, 104237, 104238, 104239, 104240, 104241, 104242, 104243, 104244, 104245, 104246, 104247, 104248, 104249, 104250, 104251, 104252, 104253, 104254, 104255, 104256, 104257, 104258, 104259, 104260, 104261, 104262, 104263, 104264, 104265, 104266, 104267, 104268, 104269, 104270, 104271, 104272, 104273, 104274, 104275, 104276, 104277, 104278, 104279, 104280, 104281, 104282, 104283, 104284, 104285, 104286, 104287, 104288, 104289, 104290, 104291, 104292, 104293, 104294, 104295, 104296, 104297, 104298, 104299, 104300, 104301, 104302, 104303, 104304, 104305, 104306, 104307, 104308, 104309, 104310, 104311, 104312, 104313, 104314, 104315, 104316, 104317, 104318, 104319, 104320, 104321, 104322, 104323, 104324, 104325, 104326, 104327, 104328, 104329, 104330, 104331, 104332, 104333, 104334, 104335, 104336, 104337, 104338, 104339, 104340, 104341, 104342, 104343, 104344, 104345, 104346, 104347, 104348, 104349, 104350, 104351, 104352, 104353, 104354, 104355, 104356, 104357, 104358, 104359, 104360, 104361, 104362, 104363, 104364, 104365, 104366, 104367, 104368, 104369, 104370, 104371, 104372, 104373, 104374, 104375, 104376, 104377, 104378, 104379, 104380, 104381, 104382, 104383, 104384, 104385, 104386, 104387, 104388, 104389, 104390, 104391, 104392, 104393, 104394, 104395, 104396, 104397, 104398, 104399, 104400, 104401, 104402, 104403, 104404, 104405, 104406, 104407, 104408, 104409, 104410, 104411, 104412, 104413, 104414, 104415, 104416, 104417, 104418, 104419, 104420, 104421, 104422, 104423, 104424, 104425, 104426, 104427, 104428, 104429, 104430, 104431, 104432, 104433, 104434, 104435, 104436, 104437, 104438, 104439, 104440, 104441, 104442, 104443, 104444, 104445, 104446, 104447, 104448, 104449, 104450, 104451, 104452, 104453, 104454, 104455, 104456, 104457, 104458, 104459, 104460, 104461, 104462, 104463, 104464, 104465, 104466, 104467, 104468, 104469, 104470, 104471, 104472, 104473, 104474, 104475, 104476, 104477, 104478, 104479, 104480, 104481, 104482, 104483, 104484, 104485, 104486, 104487, 104488, 104489, 104490, 104491, 104492, 104493, 104494, 104495, 104496, 104497, 104498, 104499, 104500, 104501, 104502, 104503, 104504, 104505, 104506, 104507, 104508, 104509, 104510, 104511, 104512, 104513, 104514, 104515, 104516, 104517, 104518, 104519, 104520, 104521, 104522, 104523, 104524, 104525, 104526, 104527, 104528, 104529, 104530, 104531, 104532, 104533, 104534, 104535, 104536, 104537, 104538, 104539, 104540, 104541, 104542, 104543, 104544, 104545, 104546, 104547, 104548, 104549, 104550, 104551, 104552, 104553, 104554, 104555, 104556, 104557, 104558, 104559, 104560, 104561, 104562, 104563, 104564, 104565, 104566, 104567, 104568, 104569, 104570, 104571, 104572, 104573, 104574, 104575, 104576, 104577, 104578, 104579, 104580, 104581, 104582, 104583, 104584, 104585, 104586, 104587, 104588, 104589, 104590, 104591, 104592, 104593, 104594, 104595, 104596, 104597, 104598, 104599, 104600, 104601, 104602, 104603, 104604, 104605, 104606, 104607, 104608, 104609, 104610, 104611, 104612, 104613, 104614, 104615, 104616, 104617, 104618, 104619, 104620, 104621, 104622, 104623, 104624, 104625, 104626, 104627, 104628, 104629, 104630, 104631, 104632, 104633, 104634, 104635, 104636, 104637, 104638, 104639, 104640, 104641, 104642, 104643, 104644, 104645, 104646, 104647, 104648, 104649, 104650, 104651, 104652, 104653, 104654, 104655, 104656, 104657, 104658, 104659, 104660, 104661, 104662, 104663, 104664, 104665, 104666, 104667, 104668, 104669, 104670, 104671, 104672, 104673, 104674, 104675, 104676, 104677, 104678, 104679, 104680, 104681, 104682, 104683, 104684, 104685, 104686, 104687, 104688, 104689, 104690, 104691, 104692, 104693, 104694, 104695, 104696, 104697, 104698, 104699, 104700, 104701, 104702, 104703, 104704, 104705, 104706, 104707, 104708, 104709, 104710, 104711, 104712, 104713, 104714, 104715, 104716, 104717, 104718, 104719, 104720, 104721, 104722, 104723, 104724, 104725, 104726, 104727, 104728, 104729, 104730, 104731, 104732, 104733, 104734, 104735, 104736, 104737, 104738, 104739, 104740, 104741, 104742, 104743, 104744, 104745, 104746, 104747, 104748, 104749, 104750, 104751, 104752, 104753, 104754, 104755, 104756, 104757, 104758, 104759, 104760, 104761, 104762, 104763, 104764, 104765, 104766, 104767, 104768, 104769, 104770, 104771, 104772, 104773, 104774, 104775, 104776, 104777, 104778, 104779, 104780, 104781, 104782, 104783, 104784, 104785, 104786, 104787, 104788, 104789, 104790, 104791, 104792, 104793, 104794, 104795, 104796, 104797, 104798, 104799, 104800, 104801, 104802, 104803, 104804, 104805, 104806, 104807, 104808, 104809, 104810, 104811, 104812, 104813, 104814, 104815, 104816, 104817, 104818, 104819, 104820, 104821, 104822, 104823, 104824, 104825, 104826, 104827, 104828, 104829, 104830, 104831, 104832, 104833, 104834, 104835, 104836, 104837, 104838, 104839, 104840, 104841, 104842, 104843, 104844, 104845, 104846, 104847, 104848, 104849, 104850, 104851, 104852, 104853, 104854, 104855, 104856, 104857, 104858, 104859, 104860, 104861, 104862, 104863, 104864, 104865, 104867, 104868, 104869, 104870, 104871, 104872, 104873, 104874, 104875, 104876, 104877, 104878, 104879, 104880, 104881, 104882, 104883, 104884, 104885, 104886, 104887, 104888, 104889, 104890, 104891, 104892, 104893, 104894, 104895, 104896, 104897, 104898, 104899, 104900, 104901, 104902, 104903, 104904, 104905, 104906, 104907, 104908, 104909, 104910, 104911, 104912, 104913, 104914, 104915, 104916, 104917, 104918, 104919, 104920, 104921, 104922, 104923, 104924, 104925, 104926, 104927, 104928, 104929, 104930, 104931, 104932, 104933, 104934, 104935, 104936, 104937, 104938, 104939, 104940, 104941, 104942, 104943, 104944, 104945, 104946, 104947, 104948, 104949, 104950, 104951, 104952, 104953, 104954, 104955, 104956, 104957, 104958, 104959, 104960, 104961, 104962, 104963, 104964, 104965, 104966, 104967, 104968, 104969, 104970, 104971, 104972, 104973, 104974, 104975, 104976, 104977, 104978, 104979, 104980, 104981, 104982, 104983, 104984, 104985, 104986, 104987, 104988, 104989, 104990, 104991, 104992, 104993, 104994, 104995, 104996, 104997, 104998, 104999, 105000, 105001, 105002, 105003, 105004, 105005, 105006, 105007, 105008, 105009, 105010, 105011, 105012, 105013, 105014, 105015, 105016, 105017, 105018, 105019, 105020, 105021, 105022, 105023, 105024, 105025, 105026, 105027, 105028, 105029, 105030, 105031, 105032, 105033, 105034, 105035, 105036, 105037, 105038, 105039, 105040, 105041, 105042, 105043, 105044, 105045, 105046, 105047, 105048, 105049, 105050, 105051, 105052, 105053, 105054, 105055, 105056, 105057, 105058, 105059, 105060, 105061, 105062, 105063, 105064, 105065, 105066, 105067, 105068, 105069, 105070, 105071, 105072, 105073, 105074, 105075, 105076, 105077, 105078, 105079, 105080, 105081, 105082, 105083, 105084, 105085, 105086, 105087, 105088, 105089, 105090, 105091, 105092, 105093, 105094, 105095, 105096, 105097, 105098, 105099, 105100, 105101, 105102, 105103, 105104, 105105, 105106, 105107, 105108, 105109, 105110, 105111, 105112, 105113, 105114, 105115, 105116, 105117, 105118, 105119, 105120, 105121, 105122, 105123, 105124, 105125, 105126, 105127, 105128, 105129, 105130, 105131, 105132, 105133, 105134, 105135, 105136, 105137, 105138, 105139, 105140, 105141, 105142, 105143, 105144, 105145, 105146, 105147, 105148, 105149, 105150, 105151, 105152, 105153, 105154, 105155, 105156, 105157, 105158, 105159, 105160, 105161, 105162, 105163, 105164, 105165, 105166, 105167, 105168, 105169, 105170, 105171, 105172, 105173, 105174, 105175, 105176, 105177, 105178, 105179, 105180, 105181, 105182, 105183, 105184, 105185, 105186, 105187, 105188, 105189, 105190, 105191, 105192, 105193, 105194, 105195, 105196, 105197, 105198, 105199, 105200, 105201, 105202, 105203, 105204, 105205, 105206, 105207, 105208, 105209, 105210, 105211, 105212, 105213, 105214, 105215, 105216, 105217, 105218, 105219, 105220, 105221, 105222, 105223, 105224, 105225, 105226, 105227, 105228, 105229, 105230, 105231, 105232, 105233, 105234, 105235, 105236, 105237, 105238, 105239, 105240, 105241, 105242, 105243, 105244, 105245, 105246, 105247, 105248, 105249, 105250, 105251, 105252, 105253, 105254, 105255, 105256, 105257, 105258, 105259, 105260, 105261, 105262, 105263, 105264, 105265, 105266, 105267, 105268, 105269, 105270, 105271, 105272, 105273, 105274, 105275, 105276, 105277, 105278, 105279, 105280, 105281, 105282, 105283, 105284, 105285, 105286, 105287, 105288, 105289, 105290, 105291, 105292, 105293, 105294, 105295, 105296, 105297, 105298, 105299, 105300, 105301, 105302, 105303, 105304, 105305, 105306, 105307, 105308, 105309, 105310, 105311, 105312, 105313, 105314, 105315, 105316, 105317, 105318, 105319, 105320, 105321, 105322, 105323, 105324, 105325, 105326, 105327, 105328, 105329, 105330, 105331, 105332, 105333, 105334, 105335, 105336, 105337, 105338, 105339, 105340, 105341, 105342, 105343, 105344, 105345, 105346, 105347, 105348, 105349, 105350, 105351, 105352, 105353, 105354, 105355, 105356, 105357, 105358, 105359, 105360, 105361, 105362, 105363, 105364, 105365, 105366, 105367, 105368, 105369, 105370, 105371, 105372, 105373, 105374, 105375, 105376, 105377, 105378, 105379, 105380, 105381, 105382, 105383, 105384, 105385, 105386, 105387, 105388, 105389, 105390, 105391, 105392, 105393, 105394, 105395, 105396, 105397, 105398, 105399, 105400, 105401, 105402, 105403, 105404, 105405, 105406, 105407, 105408, 105409, 105410, 105411, 105412, 105413, 105414, 105415, 105416, 105417, 105418, 105419, 105420, 105421, 105422, 105423, 105424, 105425, 105426, 105427, 105428, 105429, 105430, 105431, 105432, 105433, 105434, 105435, 105436, 105437, 105438, 105439, 105440, 105441, 105442, 105443, 105444, 105445, 105446, 105447, 105448, 105449, 105450, 105451, 105452, 105453, 105454, 105455, 105456, 105457, 105458, 105459, 105460, 105461, 105462, 105463, 105464, 105465, 105466, 105467, 105468, 105469, 105470, 105471, 105472, 105473, 105474, 105475, 105476, 105477, 105478, 105479, 105480, 105481, 105482, 105483, 105484, 105485, 105486, 105487, 105488, 105489, 105490, 105491, 105492, 105493, 105494, 105495, 105496, 105497, 105498, 105499, 105500, 105501, 105502, 105503, 105504, 105505, 105506, 105507, 105508, 105509, 105510, 105511, 105512, 105513, 105514, 105515, 105516, 105517, 105518, 105519, 105520, 105521, 105522, 105523, 105524, 105525, 105526, 105527, 105528, 105529, 105530, 105531, 105532, 105533, 105534, 105535, 105536, 105537, 105538, 105539, 105540, 105541, 105542, 105543, 105544, 105545, 105546, 105547, 105548, 105549, 105550, 105551, 105552, 105553, 105554, 105555, 105556, 105557, 105558, 105559, 105560, 105561, 105562, 105563, 105564, 105565, 105566, 105567, 105568, 105569, 105570, 105571, 105572, 105573, 105574, 105575, 105576, 105577, 105578, 105579, 105580, 105581, 105582, 105583, 105584, 105585, 105586, 105587, 105588, 105589, 105590, 105591, 105592, 105593, 105594, 105595, 105596, 105597, 105598, 105599, 105600, 105601, 105602, 105603, 105604, 105605, 105606, 105607, 105608, 105609, 105610, 105611, 105612, 105613, 105614, 105615, 105616, 105617, 105618, 105619, 105620, 105621, 105622, 105623, 105624, 105625, 105626, 105627, 105628, 105629, 105630, 105631, 105632, 105633, 105634, 105635, 105636, 105637, 105638, 105639, 105640, 105641, 105642, 105643, 105644, 105645, 105646, 105647, 105648, 105649, 105650, 105651, 105652, 105653, 105654, 105655, 105656, 105657, 105658, 105659, 105660, 105661, 105662, 105663, 105664, 105665, 105666, 105667, 105668, 105669, 105670, 105671, 105672, 105673, 105674, 105675, 105676, 105677, 105678, 105680, 105681, 105682, 105683, 105684, 105685, 105686, 105687, 105688, 105689, 105690, 105691, 105692, 105693, 105694, 105695, 105696, 105697, 105698, 105699, 105700, 105701, 105702, 105703, 105704, 105705, 105706, 105707, 105708, 105709, 105710, 105711, 105712, 105713, 105714, 105715, 105716, 105717, 105718, 105719, 105720, 105721, 105722, 105723, 105724, 105725, 105726, 105727, 105728, 105729, 105730, 105731, 105732, 105733, 105734, 105735, 105736, 105737, 105738, 105739, 105740, 105741, 105742, 105743, 105744, 105745, 105746, 105747, 105748, 105749, 105750, 105751, 105752, 105753, 105754, 105755, 105756, 105757, 105758, 105759, 105760, 105761, 105762, 105763, 105764, 105765, 105766, 105767, 105768, 105769, 105770, 105771, 105772, 105773, 105774, 105775, 105776, 105777, 105778, 105779, 105780, 105781, 105782, 105783, 105784, 105785, 105786, 105787, 105788, 105789, 105790, 105791, 105792, 105793, 105794, 105795, 105796, 105797, 105798, 105799, 105800, 105801, 105802, 105803, 105804, 105805, 105806, 105807, 105808, 105809, 105810, 105811, 105812, 105813, 105814, 105815, 105816, 105817, 105818, 105819, 105820, 105821, 105822, 105823, 105824, 105825, 105826, 105827, 105828, 105829, 105830, 105831, 105832, 105833, 105834, 105835, 105836, 105837, 105838, 105839, 105840, 105841, 105842, 105843, 105844, 105845, 105846, 105847, 105848, 105849, 105850, 105851, 105852, 105853, 105854, 105855, 105856, 105857, 105858, 105859, 105860, 105861, 105862, 105863, 105864, 105865, 105866, 105867, 105868, 105869, 105870, 105871, 105872, 105873, 105874, 105875, 105876, 105877, 105878, 105879, 105880, 105881, 105882, 105883, 105884, 105885, 105886, 105887, 105888, 105889, 105890, 105891, 105892, 105893, 105894, 105895, 105896, 105897, 105898, 105899, 105900, 105901, 105902, 105903, 105904, 105905, 105906, 105907, 105908, 105909, 105910, 105911, 105912, 105913, 105914, 105915, 105916, 105917, 105918, 105919, 105920, 105921, 105922, 105923, 105924, 105925, 105926, 105927, 105928, 105929, 105930, 105931, 105932, 105933, 105934, 105935, 105936, 105937, 105938, 105939, 105940, 105941, 105942, 105943, 105944, 105945, 105946, 105947, 105948, 105949, 105950, 105951, 105952, 105953, 105954, 105955, 105956, 105957, 105958, 105959, 105960, 105961, 105962, 105963, 105964, 105965, 105966, 105967, 105968, 105969, 105970, 105971, 105972, 105973, 105974, 105975, 105976, 105977, 105978, 105979, 105980, 105981, 105982, 105983, 105984, 105985, 105986, 105987, 105988, 105989, 105990, 105991, 105992, 105993, 105994, 105995, 105996, 105997, 105998, 105999, 106000, 106001, 106002, 106003, 106004, 106005, 106006, 106007, 106008, 106009, 106010, 106011, 106012, 106013, 106014, 106015, 106016, 106017, 106018, 106019, 106020, 106021, 106022, 106023, 106024, 106025, 106026, 106027, 106028, 106029, 106030, 106031, 106032, 106033, 106034, 106035, 106036, 106037, 106038, 106039, 106040, 106041, 106042, 106043, 106044, 106045, 106046, 106047, 106048, 106049, 106050, 106051, 106052, 106053, 106054, 106055, 106056, 106057, 106058, 106059, 106060, 106061, 106062, 106063, 106064, 106065, 106066, 106067, 106068, 106069, 106070, 106071, 106072, 106073, 106074, 106075, 106076, 106077, 106078, 106079, 106080, 106081, 106082, 106083, 106084, 106085, 106086, 106087, 106088, 106089, 106090, 106091, 106092, 106093, 106094, 106095, 106096, 106097, 106098, 106099, 106100, 106101, 106102, 106103, 106104, 106105, 106106, 106107, 106108, 106109, 106110, 106111, 106112, 106113, 106114, 106115, 106116, 106117, 106118, 106119, 106120, 106121, 106122, 106123, 106124, 106125, 106126, 106127, 106128, 106129, 106130, 106131, 106132, 106133, 106134, 106135, 106136, 106137, 106138, 106139, 106140, 106141, 106142, 106143, 106144, 106145, 106146, 106147, 106148, 106149, 106150, 106151, 106152, 106153, 106154, 106155, 106156, 106157, 106158, 106159, 106160, 106161, 106162, 106163, 106164, 106165, 106166, 106167, 106168, 106169, 106170, 106171, 106172, 106173, 106174, 106175, 106176, 106177, 106178, 106179, 106180, 106181, 106182, 106183, 106184, 106185, 106186, 106187, 106188, 106189, 106190, 106191, 106192, 106193, 106194, 106195, 106196, 106197, 106198, 106199, 106200, 106201, 106202, 106203, 106204, 106205, 106206, 106207, 106208, 106209, 106210, 106211, 106212, 106213, 106214, 106215, 106216, 106217, 106218, 106219, 106220, 106221, 106222, 106223, 106224, 106225, 106226, 106227, 106228, 106229, 106230, 106231, 106232, 106233, 106234, 106235, 106236, 106237, 106238, 106240, 106241, 106242, 106243, 106244, 106245, 106246, 106247, 106248, 106249, 106250, 106251, 106252, 106253, 106254, 106255, 106256, 106257, 106258, 106259, 106260, 106261, 106262, 106263, 106264, 106265, 106266, 106267, 106268, 106269, 106270, 106271, 106272, 106273, 106274, 106275, 106276, 106277, 106278, 106279, 106280, 106281, 106282, 106283, 106284, 106285, 106286, 106287, 106288, 106289, 106290, 106291, 106292, 106293, 106294, 106295, 106296, 106297, 106298, 106299, 106300, 106301, 106302, 106303, 106304, 106305, 106306, 106307, 106308, 106309, 106310, 106311, 106312, 106313, 106314, 106315, 106316, 106317, 106318, 106319, 106320, 106321, 106322, 106323, 106324, 106325, 106326, 106327, 106328, 106329, 106330, 106331, 106332, 106333, 106334, 106335, 106336, 106337, 106338, 106339, 106340, 106341, 106342, 106343, 106344, 106345, 106346, 106347, 106348, 106349, 106350, 106351, 106352, 106353, 106354, 106355, 106356, 106357, 106358, 106359, 106360, 106361, 106362, 106363, 106364, 106365, 106366, 106367, 106368, 106369, 106370, 106371, 106372, 106373, 106374, 106375, 106376, 106377, 106378, 106379, 106380, 106381, 106382, 106383, 106384, 106385, 106386, 106387, 106388, 106389, 106390, 106391, 106392, 106393, 106394, 106395, 106396, 106397, 106398, 106399, 106400, 106401, 106402, 106403, 106404, 106405, 106406, 106407, 106408, 106409, 106410, 106411, 106412, 106413, 106414, 106415, 106416, 106417, 106418, 106419, 106420, 106421, 106422, 106423, 106424, 106425, 106426, 106427, 106428, 106429, 106430, 106431, 106432, 106433, 106434, 106435, 106436, 106437, 106438, 106439, 106440, 106441, 106442, 106443, 106444, 106445, 106446, 106447, 106448, 106449, 106450, 106451, 106452, 106453, 106454, 106455, 106456, 106457, 106458, 106459, 106460, 106461, 106462, 106463, 106464, 106465, 106466, 106467, 106468, 106469, 106470, 106471, 106472, 106473, 106474, 106475, 106476, 106477, 106478, 106479, 106480, 106481, 106482, 106483, 106484, 106485, 106486, 106487, 106488, 106489, 106490, 106491, 106492, 106493, 106494, 106495, 106496, 106497, 106498, 106499, 106500, 106501, 106502, 106503, 106504, 106505, 106506, 106507, 106508, 106509, 106510, 106511, 106512, 106513, 106514, 106515, 106516, 106517, 106518, 106519, 106520, 106521, 106522, 106523, 106524, 106525, 106526, 106527, 106528, 106529, 106530, 106531, 106532, 106533, 106534, 106535, 106536, 106537, 106538, 106539, 106540, 106541, 106542, 106543, 106544, 106545, 106546, 106547, 106548, 106549, 106550, 106551, 106552, 106553, 106554, 106555, 106556, 106557, 106558, 106559, 106560, 106561, 106562, 106563, 106564, 106565, 106566, 106567, 106568, 106569, 106570, 106571, 106572, 106573, 106574, 106575, 106576, 106577, 106578, 106579, 106580, 106581, 106582, 106583, 106584, 106585, 106586, 106587, 106588, 106589, 106590, 106591, 106592, 106593, 106594, 106595, 106596, 106597, 106598, 106599, 106600, 106601, 106602, 106603, 106604, 106605, 106606, 106607, 106608, 106609, 106610, 106611, 106612, 106613, 106614, 106615, 106616, 106617, 106618, 106619, 106620, 106621, 106622, 106623, 106624, 106625, 106626, 106627, 106628, 106629, 106630, 106631, 106632, 106633, 106634, 106635, 106636, 106637, 106638, 106639, 106640, 106641, 106642, 106643, 106644, 106645, 106646, 106647, 106648, 106649, 106650, 106651, 106652, 106653, 106654, 106655, 106656, 106657, 106658, 106659, 106660, 106661, 106662, 106663, 106664, 106665, 106666, 106667, 106668, 106669, 106670, 106671, 106672, 106673, 106674, 106675, 106676, 106677, 106678, 106679, 106680, 106681, 106682, 106683, 106684, 106685, 106686, 106687, 106688, 106689, 106690, 106691, 106692, 106693, 106694, 106695, 106696, 106697, 106698, 106699, 106700, 106701, 106702, 106703, 106704, 106705, 106706, 106707, 106708, 106709, 106710, 106711, 106712, 106713, 106714, 106715, 106716, 106717, 106718, 106719, 106720, 106721, 106722, 106723, 106724, 106725, 106726, 106727, 106728, 106729, 106730, 106731, 106732, 106733, 106734, 106735, 106736, 106737, 106738, 106739, 106740, 106741, 106742, 106743, 106744, 106745, 106746, 106747, 106748, 106749, 106750, 106751, 106752, 106753, 106754, 106755, 106756, 106757, 106758, 106759, 106760, 106761, 106762, 106763, 106764, 106765, 106766, 106767, 106768, 106769, 106770, 106771, 106772, 106773, 106774, 106775, 106776, 106777, 106778, 106779, 106780, 106781, 106782, 106783, 106784, 106785, 106786, 106787, 106788, 106789, 106790, 106791, 106792, 106793, 106794, 106795, 106796, 106797, 106798, 106799, 106800, 106801, 106802, 106803, 106804, 106805, 106806, 106807, 106808, 106809, 106810, 106811, 106812, 106813, 106814, 106815, 106816, 106817, 106818, 106819, 106820, 106821, 106822, 106823, 106824, 106825, 106826, 106827, 106828, 106829, 106830, 106831, 106832, 106833, 106834, 106835, 106836, 106837, 106838, 106839, 106840, 106841, 106842, 106843, 106844, 106845, 106846, 106847, 106848, 106849, 106850, 106851, 106852, 106853, 106854, 106855, 106856, 106857, 106858, 106859, 106860, 106861, 106862, 106863, 106864, 106865, 106866, 106867, 106868, 106869, 106870, 106871, 106872, 106873, 106874, 106875, 106876, 106877, 106878, 106879, 106880, 106881, 106882, 106883, 106884, 106885, 106886, 106887, 106888, 106889, 106890, 106891, 106892, 106893, 106894, 106895, 106896, 106897, 106898, 106899, 106900, 106901, 106902, 106903, 106904, 106905, 106906, 106907, 106908, 106909, 106910, 106911, 106912, 106913, 106914, 106915, 106916, 106917, 106918, 106919, 106920, 106921, 106922, 106923, 106924, 106925, 106926, 106927, 106928, 106929, 106930, 106931, 106932, 106933, 106934, 106935, 106936, 106937, 106938, 106939, 106940, 106941, 106942, 106943, 106944, 106945, 106946, 106948, 106949, 106950, 106951, 106952, 106953, 106954, 106955, 106956, 106957, 106958, 106959, 106960, 106961, 106962, 106963, 106964, 106965, 106966, 106967, 106968, 106969, 106970, 106971, 106972, 106973, 106974, 106975, 106976, 106977, 106978, 106979, 106980, 106981, 106982, 106983, 106984, 106985, 106986, 106987, 106988, 106989, 106990, 106991, 106992, 106993, 106994, 106995, 106996, 106997, 106998, 106999, 107000, 107001, 107002, 107003, 107004, 107005, 107006, 107007, 107008, 107009, 107010, 107011, 107012, 107013, 107014, 107015, 107016, 107017, 107018, 107019, 107020, 107021, 107022, 107023, 107024, 107025, 107026, 107027, 107028, 107029, 107030, 107031, 107032, 107033, 107034, 107035, 107036, 107037, 107038, 107039, 107040, 107041, 107042, 107043, 107044, 107045, 107046, 107047, 107048, 107049, 107050, 107051, 107052, 107053, 107054, 107055, 107056, 107057, 107058, 107059, 107060, 107061, 107062, 107063, 107064, 107065, 107066, 107067, 107068, 107069, 107070, 107071, 107072, 107073, 107074, 107075, 107076, 107077, 107078, 107079, 107080, 107081, 107082, 107083, 107084, 107085, 107086, 107087, 107088, 107089, 107090, 107091, 107092, 107093, 107094, 107095, 107096, 107097, 107098, 107099, 107100, 107101, 107102, 107103, 107104, 107105, 107106, 107107, 107108, 107109, 107110, 107111, 107112, 107113, 107114, 107115, 107116, 107117, 107118, 107119, 107120, 107121, 107122, 107123, 107124, 107125, 107126, 107127, 107128, 107129, 107130, 107131, 107132, 107133, 107134, 107135, 107136, 107137, 107138, 107139, 107140, 107141, 107142, 107143, 107144, 107145, 107146, 107147, 107148, 107149, 107150, 107151, 107152, 107153, 107154, 107155, 107156, 107157, 107158, 107159, 107160, 107161, 107162, 107163, 107164, 107165, 107166, 107167, 107168, 107169, 107170, 107171, 107172, 107173, 107174, 107175, 107176, 107177, 107178, 107179, 107180, 107181, 107182, 107183, 107184, 107185, 107186, 107187, 107188, 107189, 107190, 107191, 107192, 107193, 107194, 107195, 107196, 107197, 107198, 107199, 107200, 107201, 107202, 107203, 107204, 107205, 107206, 107207, 107208, 107209, 107210, 107211, 107212, 107213, 107214, 107215, 107216, 107217, 107218, 107219, 107220, 107221, 107222, 107223, 107224, 107225, 107226, 107227, 107228, 107229, 107230, 107231, 107232, 107233, 107234, 107235, 107236, 107237, 107238, 107239, 107240, 107241, 107242, 107243, 107244, 107245, 107246, 107247, 107248, 107249, 107250, 107251, 107252, 107253, 107254, 107255, 107256, 107257, 107258, 107259, 107260, 107261, 107262, 107263, 107264, 107265, 107266, 107267, 107268, 107269, 107270, 107271, 107272, 107273, 107274, 107275, 107276, 107277, 107278, 107279, 107280, 107281, 107282, 107283, 107284, 107285, 107286, 107287, 107288, 107289, 107290, 107291, 107292, 107293, 107294, 107295, 107296, 107297, 107298, 107299, 107300, 107301, 107302, 107303, 107304, 107305, 107306, 107307, 107308, 107309, 107310, 107311, 107312, 107313, 107314, 107315, 107316, 107317, 107318, 107319, 107320, 107321, 107322, 107323, 107324, 107325, 107326, 107327, 107328, 107329, 107330, 107331, 107332, 107333, 107334, 107335, 107336, 107337, 107338, 107339, 107340, 107341, 107342, 107343, 107344, 107345, 107346, 107347, 107348, 107349, 107350, 107351, 107352, 107353, 107354, 107355, 107356, 107357, 107358, 107359, 107360, 107361, 107362, 107363, 107364, 107365, 107366, 107367, 107368, 107369, 107370, 107371, 107372, 107373, 107374, 107375, 107376, 107377, 107378, 107379, 107380, 107381, 107382, 107383, 107384, 107385, 107386, 107387, 107388, 107389, 107390, 107391, 107392, 107393, 107394, 107395, 107396, 107397, 107398, 107399, 107400, 107401, 107402, 107403, 107404, 107405, 107406, 107407, 107408, 107409, 107410, 107411, 107412, 107413, 107414, 107415, 107416, 107417, 107418, 107419, 107420, 107421, 107422, 107423, 107424, 107425, 107426, 107427, 107428, 107429, 107430, 107431, 107432, 107433, 107434, 107435, 107436, 107437, 107438, 107439, 107440, 107441, 107442, 107443, 107444, 107445, 107446, 107447, 107448, 107449, 107450, 107451, 107452, 107453, 107454, 107455, 107456, 107457, 107458, 107459, 107460, 107461, 107462, 107463, 107464, 107465, 107466, 107467, 107468, 107469, 107470, 107471, 107472, 107473, 107474, 107475, 107476, 107477, 107478, 107479, 107480, 107481, 107482, 107483, 107484, 107485, 107486, 107487, 107488, 107489, 107490, 107491, 107492, 107493, 107494, 107495, 107496, 107497, 107498, 107499, 107500, 107501, 107502, 107503, 107504, 107505, 107506, 107507, 107508, 107509, 107510, 107511, 107512, 107513, 107514, 107515, 107516, 107517, 107518, 107519, 107520, 107521, 107522, 107523, 107524, 107525, 107526, 107527, 107528, 107529, 107530, 107531, 107532, 107533, 107534, 107535, 107536, 107537, 107538, 107539, 107540, 107541, 107542, 107543, 107544, 107545, 107546, 107547, 107548, 107549, 107550, 107551, 107552, 107553, 107554, 107555, 107556, 107557, 107558, 107559, 107560, 107561, 107562, 107563, 107564, 107565, 107566, 107567, 107568, 107569, 107570, 107571, 107572, 107573, 107574, 107575, 107576, 107577, 107578, 107579, 107580, 107581, 107582, 107583, 107584, 107586, 107587, 107588, 107589, 107590, 107591, 107592, 107593, 107594, 107595, 107596, 107597, 107598, 107599, 107600, 107601, 107602, 107603, 107604, 107605, 107606, 107607, 107608, 107609, 107610, 107611, 107612, 107613, 107614, 107615, 107616, 107617, 107618, 107619, 107620, 107621, 107622, 107623, 107624, 107625, 107626, 107627, 107628, 107629, 107630, 107631, 107632, 107633, 107634, 107635, 107636, 107637, 107638, 107639, 107640, 107641, 107642, 107643, 107644, 107645, 107646, 107647, 107648, 107649, 107650, 107651, 107652, 107653, 107654, 107655, 107656, 107657, 107658, 107659, 107660, 107661, 107662, 107663, 107664, 107665, 107666, 107667, 107668, 107669, 107670, 107671, 107672, 107673, 107674, 107675, 107676, 107677, 107678, 107679, 107680, 107681, 107682, 107683, 107684, 107685, 107686, 107687, 107688, 107689, 107690, 107691, 107692, 107693, 107694, 107695, 107696, 107697, 107698, 107699, 107700, 107701, 107702, 107703, 107704, 107705, 107706, 107707, 107708, 107709, 107710, 107711, 107712, 107713, 107714, 107715, 107716, 107717, 107718, 107719, 107720, 107721, 107722, 107723, 107724, 107725, 107726, 107727, 107728, 107729, 107730, 107731, 107732, 107733, 107734, 107735, 107736, 107737, 107738, 107739, 107740, 107741, 107742, 107743, 107744, 107745, 107746, 107747, 107748, 107749, 107750, 107751, 107752, 107753, 107754, 107755, 107756, 107757, 107758, 107759, 107760, 107761, 107762, 107763, 107764, 107765, 107766, 107767, 107768, 107769, 107770, 107771, 107772, 107773, 107774, 107775, 107776, 107777, 107778, 107779, 107780, 107781, 107782, 107783, 107784, 107785, 107786, 107787, 107788, 107789, 107790, 107791, 107792, 107793, 107794, 107795, 107796, 107797, 107798, 107799, 107800, 107801, 107802, 107803, 107804, 107805, 107806, 107807, 107808, 107809, 107810, 107811, 107812, 107813, 107814, 107815, 107816, 107817, 107818, 107819, 107820, 107821, 107822, 107823, 107824, 107825, 107826, 107827, 107828, 107829, 107830, 107831, 107832, 107833, 107834, 107835, 107836, 107837, 107838, 107839, 107840, 107841, 107842, 107843, 107844, 107845, 107846, 107847, 107848, 107849, 107850, 107851, 107852, 107853, 107854, 107855, 107856, 107857, 107858, 107859, 107860, 107861, 107862, 107863, 107864, 107865, 107866, 107867, 107868, 107869, 107870, 107871, 107872, 107873, 107874, 107875, 107876, 107877, 107878, 107879, 107880, 107881, 107882, 107883, 107884, 107885, 107886, 107887, 107888, 107889, 107890, 107891, 107892, 107893, 107894, 107895, 107896, 107897, 107898, 107899, 107900, 107901, 107902, 107903, 107904, 107905, 107906, 107907, 107908, 107909, 107910, 107911, 107912, 107913, 107914, 107915, 107916, 107917, 107918, 107919, 107920, 107921, 107922, 107923, 107924, 107925, 107926, 107927, 107928, 107929, 107930, 107931, 107932, 107933, 107934, 107935, 107936, 107937, 107938, 107939, 107940, 107941, 107942, 107943, 107944, 107945, 107946, 107947, 107948, 107949, 107950, 107951, 107952, 107953, 107954, 107955, 107956, 107957, 107958, 107959, 107960, 107961, 107962, 107963, 107964, 107965, 107966, 107967, 107968, 107969, 107970, 107971, 107972, 107973, 107974, 107975, 107976, 107977, 107978, 107979, 107980, 107981, 107982, 107983, 107984, 107985, 107986, 107987, 107988, 107989, 107990, 107991, 107992, 107993, 107994, 107995, 107996, 107997, 107998, 107999, 108000, 108001, 108002, 108003, 108004, 108005, 108006, 108007, 108008, 108009, 108010, 108011, 108012, 108013, 108014, 108015, 108016, 108017, 108018, 108019, 108020, 108021, 108022, 108023, 108024, 108025, 108026, 108027, 108028, 108029, 108030, 108031, 108032, 108033, 108034, 108035, 108036, 108037, 108038, 108039, 108040, 108041, 108042, 108043, 108044, 108045, 108046, 108047, 108048, 108049, 108050, 108051, 108052, 108053, 108054, 108055, 108056, 108057, 108058, 108059, 108060, 108061, 108062, 108063, 108064, 108065, 108066, 108067, 108068, 108069, 108070, 108071, 108072, 108073, 108074, 108075, 108076, 108077, 108078, 108079, 108080, 108081, 108082, 108083, 108084, 108085, 108086, 108087, 108088, 108089, 108090, 108091, 108092, 108093, 108094, 108095, 108096, 108097, 108098, 108099, 108100, 108101, 108102, 108103, 108104, 108105, 108106, 108107, 108108, 108109, 108110, 108111, 108112, 108113, 108114, 108115, 108116, 108117, 108118, 108119, 108120, 108121, 108122, 108123, 108124, 108125, 108126, 108127, 108128, 108129, 108130, 108131, 108132, 108133, 108134, 108135, 108136, 108137, 108138, 108139, 108140, 108141, 108142, 108143, 108144, 108145, 108146, 108147, 108148, 108149, 108150, 108151, 108152, 108153, 108154, 108155, 108156, 108157, 108158, 108159, 108160, 108161, 108162, 108163, 108164, 108165, 108166, 108167, 108168, 108169, 108170, 108171, 108172, 108173, 108174, 108175, 108176, 108177, 108178, 108179, 108180, 108181, 108182, 108183, 108184, 108185, 108186, 108187, 108188, 108189, 108190, 108191, 108192, 108193, 108194, 108195, 108196, 108197, 108198, 108199, 108200, 108201, 108202, 108203, 108204, 108205, 108207, 108208, 108209, 108210, 108211, 108212, 108213, 108214, 108215, 108216, 108217, 108218, 108219, 108220, 108221, 108222, 108223, 108224, 108225, 108226, 108227, 108228, 108229, 108230, 108231, 108232, 108233, 108234, 108235, 108236, 108237, 108238, 108239, 108240, 108241, 108242, 108243, 108244, 108245, 108246, 108247, 108248, 108249, 108250, 108251, 108252, 108253, 108254, 108255, 108256, 108257, 108258, 108259, 108260, 108261, 108262, 108263, 108264, 108265, 108266, 108267, 108268, 108269, 108270, 108271, 108272, 108273, 108274, 108275, 108276, 108277, 108278, 108279, 108280, 108281, 108282, 108283, 108284, 108285, 108286, 108287, 108288, 108289, 108290, 108291, 108292, 108293, 108294, 108295, 108296, 108297, 108298, 108299, 108300, 108301, 108302, 108303, 108304, 108305, 108306, 108307, 108308, 108309, 108310, 108311, 108312, 108313, 108314, 108315, 108316, 108317, 108318, 108319, 108320, 108321, 108322, 108323, 108324, 108325, 108326, 108327, 108328, 108329, 108330, 108331, 108332, 108333, 108334, 108335, 108336, 108337, 108338, 108339, 108340, 108341, 108342, 108343, 108344, 108345, 108346, 108347, 108348, 108349, 108350, 108351, 108352, 108353, 108354, 108355, 108356, 108357, 108358, 108359, 108360, 108361, 108362, 108363, 108364, 108365, 108366, 108367, 108368, 108369, 108370, 108371, 108372, 108373, 108374, 108375, 108376, 108377, 108378, 108379, 108380, 108381, 108382, 108383, 108384, 108385, 108386, 108387, 108388, 108389, 108390, 108391, 108392, 108393, 108394, 108395, 108396, 108397, 108398, 108399, 108400, 108401, 108402, 108403, 108404, 108405, 108406, 108407, 108408, 108409, 108410, 108411, 108412, 108413, 108414, 108415, 108416, 108417, 108418, 108419, 108420, 108421, 108422, 108423, 108424, 108425, 108426, 108427, 108428, 108429, 108430, 108431, 108432, 108433, 108434, 108435, 108436, 108437, 108438, 108439, 108440, 108441, 108442, 108443, 108444, 108445, 108446, 108447, 108448, 108449, 108450, 108451, 108452, 108453, 108454, 108455, 108456, 108457, 108458, 108459, 108460, 108461, 108462, 108463, 108464, 108465, 108466, 108467, 108468, 108469, 108470, 108471, 108472, 108473, 108474, 108475, 108476, 108477, 108478, 108479, 108480, 108481, 108482, 108483, 108484, 108485, 108486, 108487, 108488, 108489, 108490, 108491, 108492, 108493, 108494, 108495, 108496, 108497, 108498, 108499, 108500, 108501, 108502, 108503, 108504, 108505, 108506, 108507, 108508, 108509, 108510, 108511, 108512, 108513, 108514, 108515, 108516, 108517, 108518, 108519, 108520, 108521, 108522, 108523, 108524, 108525, 108526, 108527, 108528, 108529, 108530, 108531, 108532, 108533, 108534, 108535, 108536, 108537, 108538, 108539, 108540, 108541, 108542, 108543, 108544, 108545, 108546, 108547, 108548, 108549, 108550, 108551, 108552, 108553, 108554, 108555, 108556, 108557, 108558, 108559, 108560, 108561, 108562, 108563, 108564, 108565, 108566, 108567, 108568, 108569, 108570, 108571, 108572, 108573, 108574, 108575, 108576, 108577, 108578, 108579, 108580, 108581, 108582, 108583, 108584, 108585, 108586, 108587, 108588, 108589, 108590, 108591, 108592, 108593, 108594, 108595, 108596, 108597, 108598, 108599, 108600, 108601, 108602, 108603, 108604, 108605, 108606, 108607, 108608, 108609, 108610, 108611, 108612, 108613, 108614, 108615, 108616, 108617, 108618, 108619, 108620, 108621, 108622, 108623, 108624, 108625, 108626, 108627, 108628, 108629, 108630, 108631, 108632, 108633, 108634, 108635, 108636, 108637, 108638, 108639, 108640, 108641, 108642, 108643, 108644, 108645, 108646, 108647, 108648, 108649, 108650, 108651, 108652, 108653, 108654, 108655, 108656, 108657, 108658, 108659, 108660, 108661, 108662, 108663, 108664, 108665, 108666, 108667, 108668, 108669, 108670, 108671, 108672, 108673, 108674, 108675, 108676, 108677, 108678, 108679, 108680, 108681, 108682, 108683, 108684, 108685, 108686, 108687, 108688, 108689, 108690, 108691, 108692, 108693, 108694, 108695, 108696, 108697, 108698, 108699, 108700, 108701, 108702, 108703, 108704, 108705, 108706, 108707, 108708, 108709, 108710, 108711, 108712, 108713, 108714, 108715, 108716, 108717, 108718, 108719, 108720, 108721, 108722, 108723, 108724, 108725, 108726, 108727, 108728, 108729, 108730, 108731, 108732, 108733, 108734, 108735, 108736, 108737, 108738, 108739, 108740, 108741, 108742, 108743, 108744, 108745, 108746, 108747, 108748, 108749, 108750, 108751, 108752, 108753, 108754, 108755, 108756, 108757, 108758, 108759, 108760, 108761, 108762, 108763, 108764, 108765, 108766, 108767, 108768, 108769, 108770, 108771, 108772, 108773, 108774, 108775, 108776, 108777, 108778, 108779, 108780, 108781, 108782, 108783, 108784, 108785, 108786, 108787, 108788, 108789, 108790, 108791, 108792, 108793, 108794, 108795, 108796, 108797, 108798, 108799, 108800, 108801, 108802, 108803, 108804, 108805, 108806, 108807, 108808, 108809, 108810, 108811, 108812, 108813, 108814, 108815, 108816, 108817, 108818, 108819, 108820, 108821, 108822, 108823, 108824, 108825, 108826, 108827, 108828, 108829, 108830, 108831, 108832, 108833, 108834, 108835, 108836, 108837, 108838, 108839, 108840, 108841, 108842, 108843, 108844, 108845, 108846, 108847, 108848, 108849, 108850, 108851, 108852, 108853, 108854, 108855, 108856, 108857, 108858, 108859, 108860, 108861, 108862, 108863, 108864, 108865, 108866, 108867, 108868, 108869, 108870, 108871, 108872, 108873, 108874, 108875, 108876, 108877, 108878, 108879, 108880, 108881, 108882, 108883, 108884, 108885, 108886, 108887, 108888, 108889, 108890, 108891, 108892, 108893, 108894, 108895, 108896, 108897, 108898, 108899, 108900, 108901, 108902, 108903, 108904, 108905, 108906, 108907, 108908, 108909, 108910, 108911, 108912, 108913, 108914, 108915, 108916, 108917, 108918, 108919, 108920, 108921, 108922, 108923, 108924, 108925, 108926, 108927, 108928, 108929, 108930, 108931, 108932, 108933, 108934, 108935, 108936, 108937, 108938, 108939, 108940, 108941, 108942, 108943, 108944, 108945, 108946, 108947, 108948, 108949, 108950, 108951, 108952, 108953, 108954, 108955, 108956, 108957, 108958, 108959, 108960, 108961, 108962, 108963, 108964, 108965, 108966, 108967, 108968, 108969, 108970, 108971, 108972, 108973, 108974, 108975, 108976, 108977, 108978, 108979, 108980, 108981, 108982, 108983, 108984, 108985, 108986, 108987, 108988, 108989, 108990, 108991, 108992, 108993, 108994, 108995, 108996, 108997, 108998, 108999, 109000, 109001, 109002, 109003, 109004, 109005, 109006, 109007, 109008, 109009, 109010, 109011, 109012, 109013, 109014, 109015, 109016, 109017, 109018, 109019, 109020, 109021, 109022, 109023, 109024, 109025, 109026, 109027, 109028, 109029, 109030, 109031, 109032, 109033, 109034, 109035, 109036, 109037, 109038, 109039, 109041, 109042, 109043, 109044, 109045, 109046, 109047, 109048, 109049, 109050, 109051, 109052, 109053, 109054, 109055, 109056, 109057, 109058, 109059, 109060, 109061, 109062, 109063, 109064, 109065, 109066, 109067, 109068, 109069, 109070, 109071, 109072, 109073, 109074, 109075, 109076, 109077, 109078, 109079, 109080, 109081, 109082, 109083, 109084, 109085, 109086, 109087, 109088, 109089, 109090, 109091, 109092, 109093, 109094, 109095, 109096, 109097, 109098, 109099, 109100, 109101, 109102, 109103, 109104, 109105, 109106, 109107, 109108, 109109, 109110, 109111, 109112, 109113, 109114, 109115, 109116, 109117, 109118, 109119, 109120, 109121, 109122, 109123, 109124, 109125, 109126, 109127, 109128, 109129, 109130, 109131, 109132, 109133, 109134, 109135, 109136, 109137, 109138, 109139, 109140, 109141, 109142, 109143, 109144, 109145, 109146, 109147, 109148, 109149, 109150, 109151, 109152, 109153, 109154, 109155, 109156, 109157, 109158, 109159, 109160, 109161, 109162, 109163, 109164, 109165, 109166, 109167, 109168, 109169, 109170, 109171, 109172, 109173, 109174, 109175, 109176, 109177, 109178, 109179, 109180, 109181, 109182, 109183, 109184, 109185, 109186, 109187, 109188, 109189, 109190, 109191, 109192, 109193, 109194, 109195, 109196, 109197, 109198, 109199, 109200, 109201, 109202, 109203, 109204, 109205, 109206, 109207, 109208, 109209, 109210, 109211, 109212, 109213, 109214, 109215, 109216, 109217, 109218, 109219, 109220, 109221, 109222, 109223, 109224, 109225, 109226, 109227, 109228, 109229, 109230, 109231, 109232, 109233, 109234, 109235, 109236, 109237, 109238, 109239, 109240, 109241, 109242, 109243, 109244, 109245, 109246, 109247, 109248, 109249, 109250, 109251, 109252, 109253, 109254, 109255, 109256, 109257, 109258, 109259, 109260, 109261, 109262, 109263, 109264, 109265, 109266, 109267, 109268, 109269, 109270, 109271, 109272, 109273, 109274, 109275, 109276, 109277, 109278, 109279, 109280, 109281, 109282, 109283, 109284, 109285, 109286, 109287, 109288, 109289, 109290, 109291, 109292, 109293, 109294, 109295, 109296, 109297, 109298, 109299, 109300, 109301, 109302, 109303, 109304, 109305, 109306, 109307, 109308, 109309, 109310, 109311, 109312, 109313, 109314, 109315, 109316, 109317, 109318, 109319, 109320, 109321, 109322, 109323, 109324, 109325, 109326, 109327, 109328, 109329, 109330, 109331, 109332, 109333, 109334, 109335, 109336, 109337, 109338, 109339, 109340, 109341, 109342, 109343, 109345, 109346, 109347, 109348, 109349, 109350, 109351, 109352, 109353, 109354, 109355, 109356, 109357, 109358, 109359, 109360, 109361, 109362, 109363, 109364, 109365, 109366, 109367, 109368, 109369, 109370, 109371, 109372, 109373, 109375, 109376, 109377, 109378, 109379, 109380, 109381, 109382, 109383, 109384, 109385, 109386, 109387, 109388, 109389, 109390, 109391, 109392, 109393, 109394, 109395, 109396, 109397, 109398, 109399, 109400, 109401, 109402, 109403, 109404, 109405, 109406, 109407, 109408, 109409, 109410, 109411, 109412, 109413, 109414, 109415, 109416, 109417, 109418, 109419, 109420, 109421, 109422, 109423, 109424, 109425, 109426, 109427, 109428, 109429, 109430, 109431, 109432, 109433, 109434, 109435, 109436, 109437, 109438, 109439, 109440, 109441, 109442, 109443, 109444, 109445, 109446, 109447, 109448, 109449, 109450, 109451, 109452, 109453, 109454, 109455, 109456, 109457, 109458, 109459, 109460, 109461, 109462, 109463, 109464, 109465, 109466, 109467, 109468, 109469, 109470, 109471, 109472, 109473, 109474, 109475, 109476, 109477, 109478, 109479, 109480, 109481, 109482, 109483, 109484, 109485, 109486, 109487, 109488, 109489, 109490, 109491, 109492, 109493, 109494, 109495, 109496, 109497, 109498, 109499, 109500, 109501, 109502, 109503, 109504, 109505, 109506, 109507, 109508, 109509, 109510, 109511, 109512, 109513, 109514, 109515, 109516, 109517, 109518, 109519, 109520, 109521, 109522, 109523, 109524, 109525, 109526, 109527, 109528, 109529, 109530, 109531, 109532, 109533, 109534, 109535, 109536, 109537, 109538, 109539, 109540, 109541, 109542, 109543, 109544, 109545, 109546, 109547, 109548, 109549, 109550, 109551, 109552, 109553, 109554, 109555, 109556, 109557, 109558, 109559, 109560, 109561, 109562, 109563, 109564, 109565, 109566, 109567, 109568, 109569, 109570, 109571, 109572, 109573, 109574, 109575, 109576, 109577, 109578, 109579, 109580, 109581, 109582, 109583, 109584, 109585, 109586, 109587, 109588, 109589, 109590, 109591, 109592, 109593, 109594, 109595, 109596, 109597, 109598, 109599, 109600, 109601, 109602, 109603, 109604, 109605, 109606, 109607, 109608, 109609, 109610, 109611, 109612, 109613, 109614, 109615, 109616, 109617, 109618, 109619, 109620, 109621, 109622, 109623, 109624, 109625, 109626, 109627, 109628, 109629, 109630, 109631, 109632, 109633, 109634, 109635, 109636, 109637, 109638, 109639, 109640, 109641, 109642, 109643, 109644, 109645, 109646, 109647, 109648, 109649, 109650, 109651, 109652, 109653, 109654, 109655, 109656, 109657, 109658, 109659, 109660, 109661, 109662, 109663, 109664, 109665, 109666, 109667, 109668, 109669, 109670, 109671, 109672, 109673, 109674, 109675, 109676, 109677, 109678, 109679, 109680, 109681, 109682, 109683, 109684, 109685, 109686, 109687, 109688, 109689, 109690, 109691, 109692, 109693, 109694, 109695, 109696, 109697, 109698, 109699, 109700, 109701, 109702, 109703, 109704, 109705, 109706, 109707, 109708, 109709, 109710, 109711, 109712, 109713, 109714, 109715, 109716, 109717, 109718, 109719, 109720, 109721, 109722, 109723, 109724, 109725, 109726, 109727, 109728, 109729, 109730, 109731, 109732, 109733, 109734, 109735, 109736, 109737, 109738, 109739, 109740, 109741, 109742, 109743, 109744, 109745, 109746, 109747, 109748, 109749, 109750, 109751, 109752, 109753, 109754, 109755, 109756, 109757, 109758, 109759, 109760, 109761, 109762, 109763, 109764, 109765, 109766, 109767, 109768, 109769, 109770, 109771, 109772, 109773, 109774, 109775, 109776, 109777, 109778, 109779, 109780, 109781, 109782, 109783, 109784, 109785, 109786, 109787, 109788, 109789, 109790, 109791, 109792, 109793, 109794, 109795, 109796, 109797, 109798, 109799, 109800, 109801, 109802, 109803, 109804, 109805, 109806, 109807, 109808, 109809, 109810, 109811, 109812, 109813, 109814, 109815, 109816, 109817, 109818, 109819, 109820, 109821, 109822, 109823, 109824, 109825, 109826, 109827, 109828, 109829, 109830, 109831, 109832, 109833, 109834, 109835, 109836, 109837, 109838, 109839, 109840, 109841, 109842, 109843, 109844, 109845, 109846, 109847, 109848, 109849, 109850, 109851, 109852, 109853, 109854, 109855, 109856, 109857, 109858, 109859, 109860, 109861, 109862, 109863, 109864, 109865, 109866, 109867, 109868, 109869, 109870, 109871, 109872, 109873, 109874, 109875, 109876, 109877, 109878, 109879, 109880, 109881, 109882, 109883, 109884, 109885, 109886, 109887, 109888, 109889, 109890, 109891, 109892, 109893, 109894, 109895, 109896, 109897, 109898, 109899, 109900, 109901, 109902, 109903, 109904, 109905, 109906, 109907, 109908, 109909, 109910, 109911, 109912, 109913, 109914, 109915, 109916, 109917, 109918, 109919, 109920, 109921, 109922, 109923, 109924, 109925, 109926, 109927, 109928, 109929, 109930, 109931, 109932, 109933, 109934, 109935, 109936, 109937, 109938, 109939, 109940, 109941, 109942, 109943, 109944, 109945, 109946, 109947, 109948, 109949, 109950, 109951, 109952, 109953, 109954, 109955, 109956, 109957, 109958, 109959, 109960, 109961, 109962, 109963, 109964, 109965, 109966, 109967, 109968, 109969, 109970, 109971, 109972, 109973, 109974, 109975, 109976, 109977, 109978, 109979, 109980, 109981, 109982, 109983, 109984, 109985, 109986, 109987, 109988, 109989, 109990, 109991, 109992, 109993, 109994, 109995, 109996, 109997, 109998, 109999, 110000, 110001, 110002, 110003, 110004, 110005, 110006, 110007, 110008, 110009, 110010, 110011, 110012, 110013, 110014, 110015, 110016, 110017, 110018, 110019, 110020, 110021, 110022, 110023, 110024, 110025, 110026, 110027, 110028, 110029, 110030, 110031, 110032, 110033, 110034, 110035, 110036, 110037, 110038, 110039, 110040, 110041, 110042, 110043, 110044, 110045, 110046, 110047, 110048, 110049, 110050, 110051, 110052, 110053, 110054, 110055, 110056, 110057, 110058, 110059, 110060, 110061, 110062, 110063, 110064, 110065, 110066, 110067, 110068, 110069, 110070, 110071, 110072, 110073, 110074, 110075, 110076, 110077, 110078, 110079, 110080, 110081, 110082, 110083, 110084, 110085, 110086, 110087, 110088, 110089, 110090, 110091, 110092, 110093, 110094, 110095, 110096, 110097, 110098, 110099, 110100, 110101, 110102, 110103, 110104, 110105, 110106, 110107, 110108, 110109, 110110, 110111, 110112, 110113, 110114, 110115, 110116, 110117, 110118, 110119, 110120, 110121, 110122, 110123, 110124, 110125, 110126, 110127, 110128, 110129, 110130, 110131, 110132, 110133, 110134, 110135, 110136, 110137, 110138, 110139, 110140, 110141, 110142, 110143, 110144, 110145, 110146, 110147, 110148, 110149, 110150, 110151, 110152, 110153, 110154, 110155, 110156, 110157, 110158, 110159, 110160, 110161, 110162, 110163, 110164, 110165, 110166, 110167, 110168, 110169, 110170, 110171, 110172, 110173, 110174, 110175, 110176, 110177, 110178, 110179, 110180, 110181, 110182, 110183, 110184, 110185, 110186, 110187, 110188, 110189, 110190, 110191, 110192, 110193, 110194, 110195, 110196, 110197, 110198, 110199, 110200, 110201, 110202, 110203, 110204, 110205, 110206, 110207, 110208, 110209, 110210, 110211, 110212, 110213, 110214, 110215, 110216, 110217, 110218, 110219, 110220, 110221, 110222, 110223, 110224, 110225, 110226, 110227, 110228, 110229, 110230, 110231, 110232, 110233, 110234, 110235, 110236, 110237, 110238, 110239, 110240, 110241, 110242, 110243, 110244, 110245, 110246, 110247, 110248, 110249, 110250, 110251}\n",
      "len(MaskID_to_remove) = 10240\n"
     ]
    }
   ],
   "source": [
    "# count how many rows have value -1 in each column\n",
    "def count_missing_values(fn):\n",
    "    print('\\ncount_missing_values:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    # print(df.info())\n",
    "    MaskID_to_remove = set()\n",
    "    target_col = {'sbp', 'hdl', 'TC', 'hba1c'}\n",
    "    print('columnname', 'missing_row_count', 'missing_MaskID_count')\n",
    "    for col in df.columns:\n",
    "        # count how many different MaskID for the rows with value -1 in the column\n",
    "        MaskID_unique = df[df[col] == -1]['MaskID'].unique()\n",
    "        print(col, df[df[col] == -1].shape[0], len(MaskID_unique))\n",
    "        # add the MaskID to the set\n",
    "        # print('col =', col, 'MaskID_unique =', MaskID_unique, 'MaskID_to_remove =', MaskID_to_remove)\n",
    "        if col in target_col:\n",
    "            for MaskID in MaskID_unique:\n",
    "                MaskID_to_remove.add(MaskID)\n",
    "    print()\n",
    "\n",
    "    return MaskID_to_remove\n",
    "\n",
    "MaskID_to_remove = count_missing_values('data/temp/features_red_merge_BMI_addfea_handlemissing.csv')\n",
    "print('MaskID_to_remove =', MaskID_to_remove)\n",
    "print('len(MaskID_to_remove) =', len(MaskID_to_remove))\n",
    "# count_missing_values('data/temp/features_blue_merge_BMI_addfea_handlemissing.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total 10251 patients:\n",
    "missing sbp: 8960 people\n",
    "missing edu_baseline: 7 people\n",
    "missing BMI: 10239 people (have partial visit record)\n",
    "\n",
    "sbp and other numeric values didnot fill in with average of adjacent values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate CVD_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "add_CVDrisk: data/temp/features_red_merge_BMI_addfea_handlemissing.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388771/388771 [01:04<00:00, 5997.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 388771 entries, 0 to 388770\n",
      "Data columns (total 42 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   MaskID             388771 non-null  int64  \n",
      " 1   Visit              388771 non-null  object \n",
      " 2   glycemia           375659 non-null  float64\n",
      " 3   bp                 123919 non-null  float64\n",
      " 4   sbp                388771 non-null  float64\n",
      " 5   dbp                388771 non-null  float64\n",
      " 6   hr                 388771 non-null  float64\n",
      " 7   hba1c              388771 non-null  float64\n",
      " 8   TC                 388771 non-null  float64\n",
      " 9   trig               388771 non-null  float64\n",
      " 10  vldl               388771 non-null  float64\n",
      " 11  ldl                388771 non-null  float64\n",
      " 12  hdl                388771 non-null  float64\n",
      " 13  fpg                388771 non-null  float64\n",
      " 14  alt                388771 non-null  float64\n",
      " 15  cpk                388771 non-null  float64\n",
      " 16  potassium          388771 non-null  float64\n",
      " 17  screat             388771 non-null  float64\n",
      " 18  gfr                388771 non-null  float64\n",
      " 19  ualb               388771 non-null  float64\n",
      " 20  ucreat             388771 non-null  float64\n",
      " 21  uacr               388771 non-null  float64\n",
      " 22  edu_baseline       388771 non-null  float64\n",
      " 23  yrsdiab_baseline   388771 non-null  float64\n",
      " 24  yrstens_baseline   388771 non-null  float64\n",
      " 25  cigarett_baseline  388771 non-null  int64  \n",
      " 26  wt_kg_baseline     388771 non-null  float64\n",
      " 27  ht_cm_baseline     388771 non-null  float64\n",
      " 28  wt_kg_visit        388771 non-null  float64\n",
      " 29  ht_cm_visit        388771 non-null  float64\n",
      " 30  oral_gmed          388771 non-null  object \n",
      " 31  medadd             388771 non-null  float64\n",
      " 32  medchg_intbp       388771 non-null  float64\n",
      " 33  medchg_stdbp       388771 non-null  float64\n",
      " 34  bp_med             388771 non-null  object \n",
      " 35  BMI                388771 non-null  float64\n",
      " 36  female             388771 non-null  int64  \n",
      " 37  baseline_age       388771 non-null  float64\n",
      " 38  cvd_hx_baseline    388771 non-null  int64  \n",
      " 39  raceclass          388771 non-null  object \n",
      " 40  type_po            388771 non-null  int64  \n",
      " 41  CVDRisk            388771 non-null  float64\n",
      "dtypes: float64(33), int64(5), object(4)\n",
      "memory usage: 124.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def add_CVDrisk(fn):\n",
    "\n",
    "    print('\\nadd_CVDrisk:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    CVD = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        # collect the features\n",
    "        \n",
    "        # following features have no missinng rows\n",
    "        race = 'Black' if row['raceclass']=='Black' else 'White/Other'\n",
    "        gender = 'Female' if row['female']==1 else 'Male'\n",
    "        age = row['baseline_age']\n",
    "        smoke = 1 if row['cigarett_baseline'] == 1 else 0 # 1 means yes, 2 means no\n",
    "\n",
    "        # patients with missing values in the following features are already removed\n",
    "        TC = 1 if row['TC']==-1 else row['TC'] # 96 rows have value -1, which means missing, take 1 when missing such that log(1) = 0\n",
    "        HDL = 1 if row['hdl']==-1 else row['hdl'] # 96 rows have value -1, which means missing\n",
    "        SBP = 1 if row['sbp']==-1 else row['sbp'] # 3 rows have value -1, which means missing\n",
    "\n",
    "        if race=='Black' and gender=='Female':\n",
    "            q = np.exp( 17.114*np.log(age) + 0.940*np.log(TC) - 18.920*np.log(HDL) \\\n",
    "                        + 4.475*np.log(age)*np.log(HDL) \\\n",
    "                        + 29.291*np.log(SBP) - 6.432*np.log(age)*np.log(SBP) \\\n",
    "                        + 0.691*smoke +0.874*(1) -86.61)\n",
    "            p_ascvd_10year = 1-np.power(0.9533, q)\n",
    "\n",
    "        elif race=='White/Other' and gender=='Female':\n",
    "            q = np.exp( -29.799*np.log(age) + 4.884*np.log(age)*np.log(age) +13.54*np.log(TC) \\\n",
    "               - 3.114*np.log(age)*np.log(TC) - 13.578*np.log(HDL) + 3.149*np.log(age)*np.log(HDL) \\\n",
    "               + 2.019*np.log(SBP) + 7.574*smoke - 1.665*np.log(age)*smoke +0.661*(1) + 29.18)\n",
    "\n",
    "            p_ascvd_10year = 1-np.power(0.9665, q)\n",
    "        \n",
    "        elif race=='White/Other' and gender=='Male':\n",
    "            q = np.exp( 12.344*np.log(age) +11.853*np.log(TC) \\\n",
    "               -2.664*np.log(age)*np.log(TC) -7.990*np.log(HDL) +1.769*np.log(age)*np.log(HDL) \\\n",
    "               +1.797*np.log(SBP)  \\\n",
    "               +7.837*smoke -1.795*np.log(age)*smoke +0.658*(1) -61.18)\n",
    "            \n",
    "            p_ascvd_10year = 1-np.power(0.9144, q)\n",
    "        \n",
    "        elif race=='Black' and gender=='Male':\n",
    "            q = np.exp(2.469*np.log(age) +0.302*np.log(TC) -0.307*np.log(HDL)  \\\n",
    "               +1.916*np.log(SBP)  \\\n",
    "               +0.549*smoke +0.645*(1) -19.54)\n",
    "            p_ascvd_10year = 1-np.power(0.8954, q)\n",
    "        \n",
    "        else:\n",
    "            print('unrecognized race and gender:', race, gender)\n",
    "            exit()\n",
    "        \n",
    "        CVD.append(p_ascvd_10year)\n",
    "   \n",
    "    df['CVDRisk'] = CVD\n",
    "    print(df.info())\n",
    "\n",
    "    df.to_csv(fn.split('.')[0]+'_addCVDrisk.csv', index=False)\n",
    "\n",
    "add_CVDrisk('data/temp/features_red_merge_BMI_addfea_handlemissing.csv')\n",
    "# add_CVDrisk('data/temp/features_blue_merge_BMI_addfea_handlemissing.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add BPClass.v2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we fixed the data in `ACCORD_BPClass_v2_merged_Contextual.csv` such that the average values will be corrected by the missing values represented by \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388771, 42)\n",
      "len(columns_to_replace) = 40\n",
      "columns_to_replace = ['glycemia', 'bp', 'sbp', 'dbp', 'hr', 'hba1c', 'TC', 'trig', 'vldl', 'ldl', 'hdl', 'fpg', 'alt', 'cpk', 'potassium', 'screat', 'gfr', 'ualb', 'ucreat', 'uacr', 'edu_baseline', 'yrsdiab_baseline', 'yrstens_baseline', 'cigarett_baseline', 'wt_kg_baseline', 'ht_cm_baseline', 'wt_kg_visit', 'ht_cm_visit', 'oral_gmed', 'medadd', 'medchg_intbp', 'medchg_stdbp', 'bp_med', 'BMI', 'female', 'baseline_age', 'cvd_hx_baseline', 'raceclass', 'type_po', 'CVDRisk']\n",
      "len(replace_data) = 388771\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/temp/features_red_merge_BMI_addfea_handlemissing_addCVDrisk.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# build the dict of each column in df using MaskID and Visit as key\n",
    "columns_to_replace = df.columns\n",
    "columns_to_replace = columns_to_replace.drop('MaskID')\n",
    "columns_to_replace = columns_to_replace.drop('Visit')\n",
    "# convert to list\n",
    "columns_to_replace = columns_to_replace.tolist()\n",
    "print('len(columns_to_replace) =', len(columns_to_replace))\n",
    "print('columns_to_replace =', columns_to_replace)\n",
    "\n",
    "replace_data = {}\n",
    "# loop through each row in df\n",
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i]\n",
    "    # get the key\n",
    "    key = (row['MaskID'], row['Visit'])\n",
    "    # loop through each column in df\n",
    "    for col in columns_to_replace:\n",
    "        # get the value of the cell\n",
    "        value = row[col]\n",
    "\n",
    "        # add the value to the dict\n",
    "        if key not in replace_data:\n",
    "            replace_data[key] = {}\n",
    "        replace_data[key][col] = value\n",
    "\n",
    "print('len(replace_data) =', len(replace_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176880, 77)\n",
      "MaskID 0\n",
      "Visit 70\n",
      "glycemia 0\n",
      "bp 0\n",
      "sbp 0\n",
      "dbp 0\n",
      "hr 0\n",
      "hba1c 0\n",
      "TC 0\n",
      "trig 0\n",
      "vldl 0\n",
      "ldl 0\n",
      "hdl 0\n",
      "fpg 0\n",
      "alt 0\n",
      "cpk 121\n",
      "potassium 0\n",
      "screat 0\n",
      "gfr 0\n",
      "ualb 142\n",
      "ucreat 142\n",
      "uacr 541\n",
      "edu_baseline 0\n",
      "yrsdiab_baseline 1708\n",
      "yrstens_baseline 35151\n",
      "cigarett_baseline 0\n",
      "wt_kg_baseline 0\n",
      "ht_cm_baseline 0\n",
      "wt_kg_visit 0\n",
      "ht_cm_visit 0\n",
      "oral_gmed 1\n",
      "medadd 0\n",
      "medchg_intbp 0\n",
      "medchg_stdbp 0\n",
      "bp_med 1\n",
      "BMI 0\n",
      "female 0\n",
      "baseline_age 0\n",
      "cvd_hx_baseline 0\n",
      "raceclass 12169\n",
      "type_po 0\n",
      "CVDRisk 0\n",
      "BPClass 1\n",
      "sbp_discrete 0\n",
      "hba1c_discrete 0\n",
      "BMI_discrete 0\n",
      "hdl_discrete 0\n",
      "TC_discrete 0\n",
      "sbp_feedback 0\n",
      "hba1c_feedback 0\n",
      "CVDRisk_feedback 0\n",
      "bpclass_none 0\n",
      "Diur 0\n",
      "ACE 0\n",
      "Beta-blocker 0\n",
      "CCB 0\n",
      "ARB 0\n",
      "Alpha-Beta-blocker 0\n",
      "Alpha-blocker 0\n",
      "Sympath 0\n",
      "Vasod 0\n",
      "baseline_BMI 0\n",
      "race_whiteother 0\n",
      "race_black 0\n",
      "CVDRisk_feedback_binary 0\n",
      "BMI_feedback 0\n",
      "TC_feedback 0\n",
      "hdl_feedback 0\n",
      "sbp_feedback_discrete 0\n",
      "hba1c_feedback_discrete 0\n",
      "BMI_feedback_discrete 0\n",
      "hdl_feedback_discrete 0\n",
      "TC_feedback_discrete 0\n",
      "sbp_discrete_merged 0\n",
      "action_code 0\n",
      "state_code 0\n",
      "baseline_BMI_discrete 0\n",
      "MaskID 0\n",
      "Visit 70\n",
      "glycemia 0\n",
      "bp 0\n",
      "sbp 81398\n",
      "dbp 81400\n",
      "hr 81453\n",
      "hba1c 118771\n",
      "TC 152130\n",
      "trig 152130\n",
      "vldl 152138\n",
      "ldl 152138\n",
      "hdl 152137\n",
      "fpg 143243\n",
      "alt 141553\n",
      "cpk 168816\n",
      "potassium 142608\n",
      "screat 143883\n",
      "gfr 143883\n",
      "ualb 161705\n",
      "ucreat 161704\n",
      "uacr 162330\n",
      "edu_baseline 0\n",
      "yrsdiab_baseline 1708\n",
      "yrstens_baseline 35151\n",
      "cigarett_baseline 0\n",
      "wt_kg_baseline 0\n",
      "ht_cm_baseline 0\n",
      "wt_kg_visit 151619\n",
      "ht_cm_visit 151738\n",
      "oral_gmed 1\n",
      "medadd 0\n",
      "medchg_intbp 0\n",
      "medchg_stdbp 0\n",
      "bp_med 1\n",
      "BMI 151801\n",
      "female 0\n",
      "baseline_age 0\n",
      "cvd_hx_baseline 0\n",
      "raceclass 12169\n",
      "type_po 0\n",
      "CVDRisk 0\n",
      "BPClass 1\n",
      "sbp_discrete 0\n",
      "hba1c_discrete 0\n",
      "BMI_discrete 0\n",
      "hdl_discrete 0\n",
      "TC_discrete 0\n",
      "sbp_feedback 0\n",
      "hba1c_feedback 0\n",
      "CVDRisk_feedback 0\n",
      "bpclass_none 0\n",
      "Diur 0\n",
      "ACE 0\n",
      "Beta-blocker 0\n",
      "CCB 0\n",
      "ARB 0\n",
      "Alpha-Beta-blocker 0\n",
      "Alpha-blocker 0\n",
      "Sympath 0\n",
      "Vasod 0\n",
      "baseline_BMI 0\n",
      "race_whiteother 0\n",
      "race_black 0\n",
      "CVDRisk_feedback_binary 0\n",
      "BMI_feedback 0\n",
      "TC_feedback 0\n",
      "hdl_feedback 0\n",
      "sbp_feedback_discrete 0\n",
      "hba1c_feedback_discrete 0\n",
      "BMI_feedback_discrete 0\n",
      "hdl_feedback_discrete 0\n",
      "TC_feedback_discrete 0\n",
      "sbp_discrete_merged 0\n",
      "action_code 0\n",
      "state_code 0\n",
      "baseline_BMI_discrete 0\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "df_target = pd.read_csv('../data/ACCORD_BPClass_v2_merged_Contextual.csv')\n",
    "print(df_target.shape)\n",
    "\n",
    "for col in df_target.columns:\n",
    "    print(col, df_target[col].value_counts().get(-1, 0))\n",
    "\n",
    "# loop through each row in df_target\n",
    "for i in tqdm(range(df_target.shape[0])):\n",
    "    row = df_target.iloc[i]\n",
    "    # get the key\n",
    "    key = (row['MaskID'], row['Visit'])\n",
    "    # loop through each column in df_target\n",
    "    for col in columns_to_replace:\n",
    "        # get the value of the cell\n",
    "        value = row[col]\n",
    "\n",
    "        # replace the value in df_target\n",
    "        if key in replace_data:\n",
    "            df_target.loc[i, col] = replace_data[key][col]\n",
    "        else:\n",
    "            print('key not found:', key)\n",
    "            exit()\n",
    "\n",
    "# count the number of -1 in each column of df_target\n",
    "for col in df_target.columns:\n",
    "    print(col, df_target[col].value_counts().get(-1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df_target to csv\n",
    "df_target.to_csv('../data/ACCORD_BPClass_v2_merged_Contextual_-1NotAvg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151801, 77)\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "# get rows with Visit=-1 in df_target\n",
    "df_target_error = df_target[df_target['BMI']==-1]\n",
    "print(df_target_error.shape)\n",
    "\n",
    "print(df_target['Visit'].value_counts().get(-1, 0))\n",
    "\n",
    "# print(df_target_error.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP---------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCORD_BPMed.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Medicine Combo frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "count_med_freq: data/ACCORD.csv bp_med\n",
      "(388523, 42)\n",
      "len(med_freq_dict) = 4986\n",
      "                                 bp_med    freq  length\n",
      "0                                  none  287496       1\n",
      "1                            lisinopril    4538       1\n",
      "2                       hctz+lisinopril    4018       2\n",
      "3                              ramipril    3449       1\n",
      "4            hctz+lisinopril+metoprolol    2909       3\n",
      "5             chlorthalidone+lisinopril    2078       2\n",
      "6               chlorthalidone+ramipril    1978       2\n",
      "7                        hctz+valsartan    1903       2\n",
      "8  chlorthalidone+lisinopril+metoprolol    1497       3\n",
      "9                 lisinopril+metoprolol    1488       2\n",
      "\n",
      "count_med_freq: data/ACCORD.csv oral_gmed\n",
      "(388523, 42)\n",
      "len(med_freq_dict) = 439\n",
      "                                         oral_gmed   freq  length\n",
      "0                                             none  88205       1\n",
      "1              glimepiride+metformin+rosiglitazone  65290       3\n",
      "2                          metformin+rosiglitazone  35592       2\n",
      "3                            glimepiride+metformin  35433       2\n",
      "4                                        metformin  32932       1\n",
      "5              metformin+repaglinide+rosiglitazone  20584       3\n",
      "6  glimepiride+metformin+repaglinide+rosiglitazone  14842       4\n",
      "7                                    rosiglitazone  11136       1\n",
      "8                        glimepiride+rosiglitazone  11107       2\n",
      "9                                      glimepiride   8063       1\n"
     ]
    }
   ],
   "source": [
    "# read in the table with added features / read in the f15_bptrialmedicationslog_medlist.csv\n",
    "# count the frequency of each value in the bp_med column, notice the value is a string\n",
    "\n",
    "def count_med_freq(fn, col):\n",
    "    print('\\ncount_med_freq:', fn, col)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "    # print(df.info())\n",
    "\n",
    "    # count the frequency of each value in the bp_med column\n",
    "    med_freq_dict = {}\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        med = row[col]\n",
    "        # print('med =', med)\n",
    "\n",
    "        # check if there is duplicate in med\n",
    "        # med_list = med.split('+') # convert med to a list\n",
    "        # med_set = set(med_list)\n",
    "        # if (len(med_set) != len(med_list)):\n",
    "        #     print('error: duplicate in med_list =', med_list)\n",
    "        #     print('med_set =', med_set)\n",
    "        #     exit()\n",
    "        \n",
    "        # count the frequency using str as key\n",
    "        if med in med_freq_dict:\n",
    "            med_freq_dict[med] += 1\n",
    "        else:\n",
    "            med_freq_dict[med] = 1\n",
    "\n",
    "    # sort the med_freq_dict by decreasing value\n",
    "    med_freq_dict = {k: v for k, v in sorted(med_freq_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    print('len(med_freq_dict) =', len(med_freq_dict))\n",
    "\n",
    "    # convert the med_freq_dict to a pandas dataframe, use key as a column, and value as another column\n",
    "    med_key = list(med_freq_dict.keys())\n",
    "    med_val = list(med_freq_dict.values())\n",
    "    med_length = [len(med.split('+')) for med in med_key]\n",
    "    med_freq_df = pd.DataFrame({col: med_key, 'freq': med_val, 'length': med_length})\n",
    "    med_freq_df.to_csv('data/temp/' + col + '_combo_freq.csv', index=False)\n",
    "    print(med_freq_df.head(10))\n",
    "\n",
    "# count_med_freq('data/features_red/f15_bptrialmedicationslog_medlist.csv', 'bp_med')\n",
    "# count_med_freq('data/features_red/f10_glycemiamedicationslog_medlist.csv', 'oral_gmed')\n",
    "count_med_freq('data/ACCORD.csv', 'bp_med')\n",
    "count_med_freq('data/ACCORD.csv', 'oral_gmed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for patients who have used \"other xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "check_med_freq: data/ACCORD.csv\n",
      "(388523, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10251/10251 [00:06<00:00, 1588.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(BP_other_patients) = 2799\n",
      "df_BP_other_patients.shape = (112736, 42)\n",
      "len(BP_other_med_names) = 7\n",
      "BP_other_med_names = {'other anti-hypertensive', 'other beta blocker', 'other ace inhibitor', 'other diuretic', 'other ccb', 'other alpha blocker', 'other a ii rb'}\n"
     ]
    }
   ],
   "source": [
    "# get the patient MaskID set who had ever used the \"other xxx\" in their BP_med column\n",
    "\n",
    "global BP_other_med_names    \n",
    "BP_other_med_names = set()\n",
    "\n",
    "def check_other(med_list):\n",
    "    has_other_med = False\n",
    "    for med_visit in med_list:\n",
    "        med_names_list = med_visit.split('+')\n",
    "        for med_name in med_names_list: \n",
    "            if med_name[:5]=='other':\n",
    "                has_other_med = True\n",
    "                BP_other_med_names.add(med_name)\n",
    "                return has_other_med\n",
    "\n",
    "    return has_other_med\n",
    "\n",
    "def check_other_med(fn):\n",
    "    print('\\ncheck_med_freq:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)    \n",
    "\n",
    "    BP_other_patients = set()\n",
    "    # loop through each patient\n",
    "    for maskid in tqdm(range(100001, 110252)):\n",
    "        # print('maskid =', maskid)\n",
    "        df_patient = df[df['MaskID'] == maskid]\n",
    "        patient_bpmed = df_patient['bp_med'].tolist()\n",
    "        \n",
    "        has_other_bpmed = check_other(patient_bpmed)\n",
    "\n",
    "        if has_other_bpmed:\n",
    "            BP_other_patients.add(maskid)\n",
    "            # BP_other_med_names.add(med_name)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    \n",
    "    print('len(BP_other_patients) =', len(BP_other_patients))\n",
    "    # check how many rows in df are in BP_other_patients\n",
    "    df_BP_other_patients = df[df['MaskID'].isin(BP_other_patients)]\n",
    "    print('df_BP_other_patients.shape =', df_BP_other_patients.shape)\n",
    "\n",
    "    print('len(BP_other_med_names) =', len(BP_other_med_names))\n",
    "    print('BP_other_med_names =', BP_other_med_names)\n",
    "\n",
    "check_other_med('data/ACCORD.csv')\n",
    "# check_other_med('data/temp/features_red_merge_BMI_addfea_handlemissing_removepatients_addCVDrisk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We would remove 2799 patients (112736/388523 rows) if we remove patients who had any usage of 'other xx' BP_med."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check how many rows have 'other xxx' in bp_med\n",
    "\n",
    "Also, check how many rows have more than 5 bp medications, and crresponding to how many patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "check_med_freq: data/ACCORD.csv\n",
      "(388523, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388523/388523 [00:44<00:00, 8747.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(BP_other_rows) = 14807\n",
      "df_other_rows.shape = (14807, 42)\n",
      "len(BP_other_patients) = 2799\n",
      "df_morethan_5bp_rows.shape = (4814, 42)\n",
      "len(morethan_5bp_patients) = 884\n",
      "df_morethan_5bp_patients.shape = (38044, 42)\n"
     ]
    }
   ],
   "source": [
    "def check_other(med_list):\n",
    "    has_other_med = False\n",
    "    for med_visit in med_list:\n",
    "        med_names_list = med_visit.split('+')\n",
    "        for med_name in med_names_list: \n",
    "            if med_name[:5]=='other':\n",
    "                has_other_med = True\n",
    "                BP_other_med_names.add(med_name)\n",
    "                return has_other_med\n",
    "\n",
    "    return has_other_med\n",
    "\n",
    "def check_other_med_rows(fn):\n",
    "    print('\\ncheck_med_freq:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)    \n",
    "\n",
    "    BP_other_rows = set()\n",
    "    morethan_5bp_rows = set()\n",
    "    # loop through each row\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        bpmed_names_list = row['bp_med'].split('+')\n",
    "        if len(bpmed_names_list) > 5:\n",
    "            morethan_5bp_rows.add(i)\n",
    "\n",
    "        for bpmed_name in bpmed_names_list:\n",
    "            if bpmed_name[:5]=='other':\n",
    "                BP_other_rows.add(i)\n",
    "                break\n",
    "    \n",
    "    print('len(BP_other_rows) =', len(BP_other_rows))\n",
    "\n",
    "    # keep only rows that are in BP_other_rows\n",
    "    df_other_rows = df[df.index.isin(BP_other_rows)]\n",
    "    print('df_other_rows.shape =', df_other_rows.shape)\n",
    "\n",
    "    # check how many different patients in df_other_rows\n",
    "    BP_other_patients = set(df_other_rows['MaskID'].tolist())\n",
    "    print('len(BP_other_patients) =', len(BP_other_patients))\n",
    "\n",
    "\n",
    "\n",
    "    # check how many rows in df are in more than 5 bpmed rows\n",
    "    df_morethan_5bp_rows = df[df.index.isin(morethan_5bp_rows)]\n",
    "    print('df_morethan_5bp_rows.shape =', df_morethan_5bp_rows.shape)\n",
    "\n",
    "    # check how many different patients in df_morethan_5bp_rows\n",
    "    morethan_5bp_patients = set(df_morethan_5bp_rows['MaskID'].tolist())\n",
    "    print('len(morethan_5bp_patients) =', len(morethan_5bp_patients))\n",
    "\n",
    "    # check how many rows in df with MaskID in morethan_5bp_patients\n",
    "    df_morethan_5bp_patients = df[df['MaskID'].isin(morethan_5bp_patients)]\n",
    "    print('df_morethan_5bp_patients.shape =', df_morethan_5bp_patients.shape)\n",
    "\n",
    "check_other_med_rows('data/ACCORD.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the frequency of 17 BP medications and 13 BG medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "check_med_freq: data/ACCORD.csv\n",
      "(388523, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388523/388523 [00:45<00:00, 8477.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def check_med_freq(fn, BGMED_freq_dict, BPMED_freq_dict):\n",
    "    print('\\ncheck_med_freq:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "   \n",
    "    # loop through each row/visit\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        BPMED = row['bp_med']\n",
    "        BGMED = row['oral_gmed']\n",
    "        # print('BGMED =', BGMED)\n",
    "        # print('BPMED =', BPMED)\n",
    "\n",
    "        BGMED_list = BGMED.split('+') # convert BGMED to a list\n",
    "        for med in BGMED_list:\n",
    "            if med in BGMED_freq_dict:\n",
    "                BGMED_freq_dict[med] += 1\n",
    "            else:\n",
    "                # continue\n",
    "                BGMED_freq_dict[med] = 1\n",
    "\n",
    "        BPMED_list = BPMED.split('+') # convert BPMED to a list\n",
    "        for med in BPMED_list:\n",
    "            if med in BPMED_freq_dict:\n",
    "                BPMED_freq_dict[med] += 1\n",
    "            else:\n",
    "                # continue\n",
    "                BPMED_freq_dict[med] = 1\n",
    "\n",
    "    # sort the med_freq_dict by decreasing value\n",
    "    BGMED_freq_dict = {k: v for k, v in sorted(BGMED_freq_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    BPMED_freq_dict = {k: v for k, v in sorted(BPMED_freq_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    # save the BGMED_freq_dict and BPMED_freq_dict to csv\n",
    "    BGMED_key = list(BGMED_freq_dict.keys())\n",
    "    BGMED_val = list(BGMED_freq_dict.values())\n",
    "    BGMED_freq_df = pd.DataFrame({'BGMED': BGMED_key, 'freq': BGMED_val})\n",
    "    BGMED_freq_df.to_csv('data/temp/BGMED_freq.csv', index=False)\n",
    "\n",
    "    BPMED_key = list(BPMED_freq_dict.keys())\n",
    "    BPMED_val = list(BPMED_freq_dict.values())\n",
    "    BPMED_freq_df = pd.DataFrame({'BPMED': BPMED_key, 'freq': BPMED_val})\n",
    "    BPMED_freq_df.to_csv('data/temp/BPMED_freq.csv', index=False)\n",
    "    \n",
    "\n",
    "# 13 BG meds\n",
    "BGMED_list = ['gliclazide','glimepiride','glipizide','glyburide','metformin',\n",
    "              'exanatide','repaglinide','nateglinide','rosiglitazone','pioglitazone',\n",
    "              'sitagliptin','acarbose','pramlintide']\n",
    "\n",
    "# 17 BP meds\n",
    "BPMED_list = ['chlorthalidone','hctz', 'triamterene', 'furosemide', 'candesartan',\n",
    "              'valsartan', 'benazepril', 'lisinopril','ramipril', 'felodipine',\n",
    "              'amlodipine','diltiazem', 'terazosin','metoprolol', 'carvedilol',\n",
    "              'reserpine','hydralazine']\n",
    "\n",
    "BGMED_freq_dict = {k:v for k,v in zip(BGMED_list, [0]*len(BGMED_list))}\n",
    "BPMED_freq_dict = {k:v for k,v in zip(BPMED_list, [0]*len(BPMED_list))}\n",
    "\n",
    "check_med_freq('data/ACCORD.csv', BGMED_freq_dict, BPMED_freq_dict)\n",
    "# check_med_freq('data/temp/features_blue_merge_BMI_addfea_handlemissing.csv', BGMED_freq_dict, BPMED_freq_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any patients who has ever used \"other anti-hypertensive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388523, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388523/388523 [00:47<00:00, 8194.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of visit rows containing \"other anti-hypertensive\"= 1246\n",
      "# of patients with \"other anti-hypertensive\"= 314\n",
      "df_other_rows.shape = (375317, 42)\n",
      "# of visit rows removed = 13206\n"
     ]
    }
   ],
   "source": [
    "def remove_anti_hypertensive_meds(fn):\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    antihypertensive_rows = []\n",
    "    antihypertensive_patients = set()\n",
    "    # loop through each row\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        BPMED = row['bp_med']\n",
    "        BPMED_list = BPMED.split('+')\n",
    "        BPMED_set = set(BPMED_list)\n",
    "\n",
    "        if 'other anti-hypertensive' in BPMED_set:\n",
    "            antihypertensive_rows.append(i)\n",
    "            antihypertensive_patients.add(row['MaskID'])\n",
    "    \n",
    "    print('# of visit rows containing \"other anti-hypertensive\"=', len(antihypertensive_rows))\n",
    "    print('# of patients with \"other anti-hypertensive\"=', len(antihypertensive_patients))\n",
    "\n",
    "    # remove rows whose MaskID is in antihypertensive_patients\n",
    "    df_other_rows = df[~df['MaskID'].isin(antihypertensive_patients)]\n",
    "\n",
    "    # save df_other_rows to csv\n",
    "    df_other_rows.to_csv('data/temp/ACCORD_removeantihypertensive.csv', index=False)\n",
    "    print('df_other_rows.shape =', df_other_rows.shape)\n",
    "    print(\"# of visit rows removed =\", df.shape[0] - df_other_rows.shape[0])\n",
    "\n",
    "remove_anti_hypertensive_meds('data/ACCORD.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ACCORD.BPMed.csv\n",
    "\n",
    "1. reorder each medvisit by its medicine-frequency from high to low, throw away any >5 BP medicine\n",
    "2. replace any \"other xxx\" with the most-frequent medicine under the same category, if highest-freq results duplicates, then take the 2nd freq med, etc.\n",
    "3. keep the original bp_med column, name the new column 'bp_med_most5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'none': 287496, 'metoprolol': 40506, 'hctz': 34493, 'lisinopril': 34222, 'chlorthalidone': 31587, 'valsartan': 19483, 'benazepril': 16473, 'furosemide': 15870, 'candesartan': 15025, 'ramipril': 14858, 'amlodipine': 13203, 'diltiazem': 13198, 'carvedilol': 8049, 'felodipine': 7603, 'terazosin': 7091, 'reserpine': 5725, 'other ccb': 5149, 'other diuretic': 4770, 'triamterene': 3887, 'hydralazine': 3229, 'other beta blocker': 3021, 'other ace inhibitor': 2240, 'other a ii rb': 1542, 'other anti-hypertensive': 1246, 'other alpha blocker': 1108}\n",
      "(375317, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375317/375317 [00:46<00:00, 8152.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape = (375317, 43)\n",
      "# of rows has duplicates = 0\n"
     ]
    }
   ],
   "source": [
    "def process_bpmed_by_freq(fn, col_name, MED_freq_dict, other_bp_med_dict):\n",
    "    \"\"\"\n",
    "    Sort the MED_list by decreasing freq, \n",
    "    truncate to top 5 meds with highest freq, \n",
    "    sort again by alphabetical order\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    duplicate_ct = 0\n",
    "    med_new_list = []\n",
    "    # loop through each row/visit\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        MED = row['bp_med']\n",
    "        MED_list = MED.split('+')\n",
    "        \n",
    "        # if len(MED_list)>5, sort the MED_list by decreasing freq\n",
    "        if len(MED_list) > 5:\n",
    "            MED_list.sort(key=lambda x: MED_freq_dict[x], reverse=True)\n",
    "            MED_list = MED_list[:5] # truncate to top 5 meds with highest freq\n",
    "        \n",
    "        # replace any 'other xxx' with corresponding highest freq med under same category\n",
    "        for i in range(len(MED_list)):\n",
    "            if MED_list[i] in other_bp_med_dict:\n",
    "                replace = other_bp_med_dict[MED_list[i]][0] # replace with the highest freq med\n",
    "                med_set = set(MED_list)\n",
    "                if replace in med_set:\n",
    "                    replace = other_bp_med_dict[MED_list[i]][1] # replace with the 2nd highest freq med\n",
    "                if replace in med_set:\n",
    "                    replace = other_bp_med_dict[MED_list[i]][2] # replace with the 3rd highest freq med\n",
    "                if replace in med_set:\n",
    "                    replace = other_bp_med_dict[MED_list[i]][3] # replace with the 4th highest freq med\n",
    "                MED_list[i] = replace\n",
    "        \n",
    "        # check if there are any duplicates in MED_list\n",
    "        MED_set = set(MED_list)\n",
    "        # MED_list = list(MED_set)\n",
    "        if len(MED_set) < len(MED_list):\n",
    "\n",
    "            duplicate_ct += 1\n",
    "            print('MED=', MED)\n",
    "            print('MED_list=', MED_list)\n",
    "            print('MED_set=', MED_set)\n",
    "            raise Exception('MED_list has duplicates')\n",
    "        \n",
    "        # remove '' item in MED_list\n",
    "        MED_list = [x for x in MED_list if x != '']\n",
    "\n",
    "        # sort again by alphabetical order based on the truncated and replaced MED_list\n",
    "        MED_list.sort()\n",
    "        MED_new = '+'.join(MED_list)\n",
    "        med_new_list.append(MED_new)\n",
    "    \n",
    "    df['{}_most5'.format(col_name)] = med_new_list\n",
    "\n",
    "    # save df to csv\n",
    "    df.to_csv('data/temp/ACCORD_removeantihypertensive_most5.csv', index=False)\n",
    "    print('df.shape =', df.shape)\n",
    "    print(\"# of rows has duplicates =\", duplicate_ct)\n",
    "\n",
    "\n",
    "\n",
    "# read in the 'data/temp/BPMED_freq.csv' into a dictionary\n",
    "BPMED_freq_dict = {}\n",
    "df = pd.read_csv('data/temp/BPMED_freq.csv')\n",
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i]\n",
    "    BPMED_freq_dict[row['BPMED']] = row['freq']\n",
    "print(BPMED_freq_dict)\n",
    "\n",
    "other_bp_med_dict = {'other ccb': ['amlodipine','diltiazem','felodipine'], \n",
    "                     'other diuretic':['hctz','chlorthalidone','furosemide','triamterene'], \n",
    "                     'other beta blocker':['metoprolol', ''], \n",
    "                     'other ace inhibitor':['lisinopril', 'benazepril', 'ramipril'], \n",
    "                     'other a ii rb': ['valsartan','candesartan'], \n",
    "                     'other alpha blocker': ['terazosin', '']}\n",
    "\n",
    "process_bpmed_by_freq('data/temp/ACCORD_removeantihypertensive.csv', 'bp_med', BPMED_freq_dict, other_bp_med_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy file 'data/temp/ACCORD_removeantihypertensive_most5.csv' to 'data/ACCORD_BPMed.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT USED -  Remove any patients who has ever used other medications\n",
    "\n",
    "Also checked how many patients had at least 1 visit with more than 5 medications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "check_other_med: data/temp/features_red_merge_BMI_addfea_handlemissing.csv\n",
      "(388771, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10251/10251 [00:07<00:00, 1453.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(BP_to_remove) = 4660\n",
      "df_bp_to_remove.shape = (189808, 41)\n",
      "\n",
      "len(BG_to_remove) = 10055\n",
      "df_bg_to_remove.shape = (384139, 41)\n",
      "\n",
      "len(BP_to_remove5) = 884\n",
      "df_bp_to_remove5.shape = (38044, 41)\n",
      "\n",
      "len(BG_to_remove5) = 45\n",
      "df_bg_to_remove5.shape = (2332, 41)\n"
     ]
    }
   ],
   "source": [
    "def check_patient_med_5(patient_med_list):\n",
    "\n",
    "    has_morethan_5med = False\n",
    "    for med_visit in patient_med_list:\n",
    "        med_list = med_visit.split('+')\n",
    "        if len(med_list) > 5: # as long as one visit has more than 5 meds, return True\n",
    "            return True\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return has_morethan_5med\n",
    "\n",
    "\n",
    "def check_patient_med(patient_med_list, MED_set):\n",
    "\n",
    "    has_other_med = False\n",
    "    for med_visit in patient_med_list:\n",
    "        med_list = med_visit.split('+')\n",
    "        for med in med_list:\n",
    "            if med[:5]=='other': # consider 'other' in the med_set\n",
    "                continue\n",
    "            elif med not in MED_set:\n",
    "                return True\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return has_other_med\n",
    "\n",
    "def check_other_med(fn, BPMED_set, BGMED_set):\n",
    "\n",
    "    print('\\ncheck_other_med:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    BP_to_remove = set()\n",
    "    BG_to_remove = set()\n",
    "\n",
    "    BP_to_remove5 = set()\n",
    "    BG_to_remove5 = set()\n",
    "\n",
    "    # loop through each patient\n",
    "    for maskid in tqdm(range(100001, 110252)):\n",
    "        # print('maskid =', maskid)\n",
    "        df_patient = df[df['MaskID'] == maskid]\n",
    "        patient_bpmed = df_patient['bp_med'].tolist()\n",
    "        patient_bgmed = df_patient['oral_gmed'].tolist()\n",
    "\n",
    "        has_other_bp = check_patient_med(patient_bpmed, BPMED_set)\n",
    "        has_other_bg = check_patient_med(patient_bgmed, BGMED_set)\n",
    "\n",
    "        has_5_bp = check_patient_med_5(patient_bpmed)\n",
    "        has_5_bg = check_patient_med_5(patient_bgmed)\n",
    "\n",
    "        if has_other_bp == True:\n",
    "            BP_to_remove.add(maskid)\n",
    "        if has_other_bg == True:\n",
    "            BG_to_remove.add(maskid)\n",
    "        \n",
    "        if has_5_bp == True:\n",
    "            BP_to_remove5.add(maskid)\n",
    "        if has_5_bg == True:\n",
    "            BG_to_remove5.add(maskid)\n",
    "    \n",
    "    # count how many rows with MaskID in BP_to_remove and BG_to_remove\n",
    "    print('\\nlen(BP_to_remove) =', len(BP_to_remove))\n",
    "    df_bp_to_remove = df[df['MaskID'].isin(BP_to_remove)]\n",
    "    print('df_bp_to_remove.shape =', df_bp_to_remove.shape)\n",
    "        \n",
    "    print('\\nlen(BG_to_remove) =', len(BG_to_remove))\n",
    "    df_bg_to_remove = df[df['MaskID'].isin(BG_to_remove)]\n",
    "    print('df_bg_to_remove.shape =', df_bg_to_remove.shape)\n",
    "\n",
    "    print('\\nlen(BP_to_remove5) =', len(BP_to_remove5))\n",
    "    df_bp_to_remove5 = df[df['MaskID'].isin(BP_to_remove5)]\n",
    "    print('df_bp_to_remove5.shape =', df_bp_to_remove5.shape)\n",
    "\n",
    "    print('\\nlen(BG_to_remove5) =', len(BG_to_remove5))\n",
    "    df_bg_to_remove5 = df[df['MaskID'].isin(BG_to_remove5)]\n",
    "    print('df_bg_to_remove5.shape =', df_bg_to_remove5.shape)\n",
    "\n",
    "BGMED_set = set(BGMED_list)\n",
    "BGMED_set.add('none')\n",
    "BPMED_set = set(BPMED_list)\n",
    "BPMED_set.add('none') # need to consider 'none' case\n",
    "\n",
    "check_other_med('data/temp/features_red_merge_BMI_addfea_handlemissing.csv', BGMED_set, BPMED_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCORD_BGMed.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many rows and patients related to removing less-frequent BG_Med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "process_bg_med: data/ACCORD_BPMed.csv\n",
      "(375317, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375317/375317 [00:47<00:00, 7852.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows containing less freq bg_med = 2030\n",
      "# of associated patients = 499\n",
      "# of total rows removed if remove assocaiated patients = (21771, 43)\n",
      "after removing associated patients, df_keep.shape = (353546, 43)\n",
      "\n",
      "# of rows containing more than 5 bg_med = 101\n",
      "# of associated patients = 43\n",
      "# of total rows removed if remove assocaiated patients = (2239, 43)\n",
      "after removing associated morethan5 patients, df_keep.shape = (351481, 43)\n"
     ]
    }
   ],
   "source": [
    "def process_bg_med(fn, bg_med_to_remove):\n",
    "\n",
    "    print('\\nprocess_bg_med:', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    row_id_to_remove = []\n",
    "    MaskID_to_remove = set()\n",
    "    row_morethan5 = []\n",
    "    MaskID_moretthan5 = set()\n",
    "    # loop through each row\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        patient_bgmed = row['oral_gmed'].split('+')        \n",
    "        if len(patient_bgmed) > 5:\n",
    "            row_morethan5.append(i)\n",
    "            MaskID_moretthan5.add(row['MaskID'])\n",
    "            \n",
    "        for med in patient_bgmed:\n",
    "            if med in bg_med_to_remove:\n",
    "                row_id_to_remove.append(i)\n",
    "                MaskID_to_remove.add(row['MaskID'])\n",
    "                break\n",
    "    \n",
    "    print('# of rows containing less freq bg_med =', len(row_id_to_remove))\n",
    "    print('# of associated patients =', len(MaskID_to_remove))\n",
    "\n",
    "    # count how many rows with MaskID in BG_to_remove\n",
    "    df_to_remove = df[df['MaskID'].isin(MaskID_to_remove)]\n",
    "    print('# of total rows removed if remove assocaiated patients =', df_to_remove.shape)\n",
    "\n",
    "    # remove patients with MaskID in BG_to_remove\n",
    "    df_keep = df[~df['MaskID'].isin(MaskID_to_remove)]\n",
    "    print('after removing associated patients, df_keep.shape =', df_keep.shape)\n",
    "\n",
    "\n",
    "    # more than 5 bg_med\n",
    "    print('\\n# of rows containing more than 5 bg_med =', len(row_morethan5))\n",
    "    print('# of associated patients =', len(MaskID_moretthan5))\n",
    "    df_morethan5 = df[df['MaskID'].isin(MaskID_moretthan5)]\n",
    "    print('# of total rows removed if remove assocaiated patients =', df_morethan5.shape)\n",
    "\n",
    "    # remove patients with MaskID in MaskID_moretthan5\n",
    "    df_keep = df_keep[~df_keep['MaskID'].isin(MaskID_moretthan5)]\n",
    "    print('after removing associated morethan5 patients, df_keep.shape =', df_keep.shape)\n",
    "\n",
    "    df_keep.to_csv('data/temp/ACCORD_BPMed_BGMed.csv', index=False)\n",
    "\n",
    "bg_med_to_remove = {'nateglinide','gliclazide', 'pramlintide', 'sulfonylurea'}\n",
    "process_bg_med('data/ACCORD_BPMed.csv', bg_med_to_remove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy file 'data/temp/ACCORD_BPMed_BGMed.csv' to 'data/ACCORD_BGMed.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCORD_BPBGMed.csv\n",
    "\n",
    "* select only BP active patients\n",
    "* 17 BP med, 10 BG med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(bp_active_set) = 4733\n",
      "(351481, 43)\n",
      "after selecting only rows with MaskID in bp_active_set, df.shape = (167939, 43)\n"
     ]
    }
   ],
   "source": [
    "def process_bpbg_med(fn, bp_active_set):\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # select only rows with MaskID in bp_active_set\n",
    "    df = df[df['MaskID'].isin(bp_active_set)]\n",
    "    print('after selecting only rows with MaskID in bp_active_set, df.shape =', df.shape)\n",
    "\n",
    "    # save to csv\n",
    "    df.to_csv('data/ACCORD_BPBGMed.csv', index=False)\n",
    "\n",
    "\n",
    "# load bp_active_set from the csv file, each line is a MaskID\n",
    "with open('data/temp/candidates_bp.csv', 'r') as f:\n",
    "    bp_active_set = set()\n",
    "    for line in f:\n",
    "        bp_active_set.add(int(line.strip()))\n",
    "    print('len(bp_active_set) =', len(bp_active_set))\n",
    "\n",
    "process_bpbg_med('data/ACCORD_BGMed.csv', bp_active_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCORD_BPClass.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert bp_med to BPClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bp_class_dict = {'chlorthalidone': 'Diur', 'hctz': 'Diur', 'triamterene': 'Diur', 'furosemide': 'Diur', 'other diuretic': 'Diur', 'candesartan': 'ARB', 'valsartan': 'ARB', 'other a ii rb': 'ARB', 'benazepril': 'ACE', 'lisinopril': 'ACE', 'ramipril': 'ACE', 'other ace inhibitor': 'ACE', 'felodipine': 'CCB', 'amlodipine': 'CCB', 'diltiazem': 'CCB', 'other ccb': 'CCB', 'terazosin': 'Alpha-blocker', 'other alpha blocker': 'Alpha-blocker', 'metoprolol': 'Beta-blocker', 'other beta blocker': 'Beta-blocker', 'carvedilol': 'Alpha-Beta-blocker', 'reserpine': 'Sympath', 'hydralazine': 'Vasod'}\n",
      "(375317, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375317/375317 [00:42<00:00, 8934.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def med_to_class(df, col_name, col_name_new, class_dict):\n",
    "\n",
    "    # add new column 'BPClass'\n",
    "    med_class = []\n",
    "\n",
    "    # loop through each row\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        med = row[col_name]\n",
    "        if med != 'none':\n",
    "            med_list = med.split('+')\n",
    "            class_set = set()\n",
    "            for med in med_list:\n",
    "                if med in class_dict:\n",
    "                    class_set.add(class_dict[med])\n",
    "                else:\n",
    "                    print('error: med not in class_dict:', med)\n",
    "                    raise Exception('med not in class_dict')\n",
    "\n",
    "            class_list = list(class_set)\n",
    "            # if len(class_list) > 5:\n",
    "            #     print('error: len(class_list) > 5')\n",
    "            #     print('class_list =', class_list)\n",
    "            #     exit()\n",
    "\n",
    "            class_list.sort()\n",
    "            med_class.append('+'.join(class_list))\n",
    "        else:\n",
    "            med_class.append('none')\n",
    "    \n",
    "    df[col_name_new] = med_class\n",
    "    return df\n",
    "    \n",
    "def process_BPclass(fn, class_dict):\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    df = med_to_class(df, 'bp_med', 'BPClass', class_dict)\n",
    "\n",
    "    df.to_csv('data/temp/ACCORD_BPMed2Class.csv', index=False)\n",
    "\n",
    "# load bp_class_dict from the csv file, keys are bp_med column, values are class column\n",
    "df = pd.read_csv('data/temp/bp_class_dict.csv')\n",
    "bp_class_dict = {k:v for k,v in zip(df['bp_med'], df['class'])}\n",
    "print('bp_class_dict =', bp_class_dict)\n",
    "\n",
    "# notice here we use the file with anti-hypertensive removed from ACCORD.csv as a starting point\n",
    "process_BPclass('data/temp/ACCORD_removeantihypertensive.csv', bp_class_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete non-active BP patients from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(bp_active_set) = 4733\n",
      "(178792, 43)\n",
      "after selecting only rows with MaskID in bp_active_set, df.shape = (178792, 43)\n",
      "(375317, 43)\n",
      "after selecting only rows with MaskID in bp_active_set, df.shape = (178792, 43)\n"
     ]
    }
   ],
   "source": [
    "def delete_nonactive_bp(fn, fn_new, bp_active_set):\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # select only rows with MaskID in bp_active_set\n",
    "    df = df[df['MaskID'].isin(bp_active_set)]\n",
    "    print('after selecting only rows with MaskID in bp_active_set, df.shape =', df.shape)\n",
    "\n",
    "    # save to csv\n",
    "    df.to_csv(fn_new, index=False)\n",
    "\n",
    "# load bp_active_set from the csv file, each line is a MaskID\n",
    "with open('data/temp/candidates_bp.csv', 'r') as f:\n",
    "    bp_active_set = set()\n",
    "    for line in f:\n",
    "        bp_active_set.add(int(line.strip()))\n",
    "    print('len(bp_active_set) =', len(bp_active_set))\n",
    "    \n",
    "delete_nonactive_bp('data/ACCORD_BPMed.csv', 'data/ACCORD_BPMed.csv', bp_active_set)\n",
    "delete_nonactive_bp('data/temp/ACCORD_BPMed2Class.csv', 'data/temp/ACCORD_BPMed2Class_activeBP.csv', bp_active_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count frequency of each BPClass and BPClass combo\n",
    "\n",
    "Delete patients who had more than 6 bp classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178792, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178792/178792 [00:20<00:00, 8578.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(bp_class) = 10\n",
      "len(bp_class_combo) = 289\n",
      "len(MaskID_morethan6) = 41\n",
      "len(rows_morethan6) = 182\n",
      "# of rows whose MaskID is in MaskID_morethan6 = 1761\n",
      "df_keep.shape = (177031, 43)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/temp/ACCORD_BPMed2Class_activeBP.csv')\n",
    "print(df.shape)\n",
    "\n",
    "bp_class = dict()\n",
    "bp_class_combo = dict()\n",
    "MaskID_morethan6 = set()\n",
    "rows_morethan6 = []\n",
    "# loop through each row\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[i]\n",
    "    med = row['BPClass']\n",
    "    if med not in bp_class_combo:\n",
    "        bp_class_combo[med] = 1\n",
    "    else:\n",
    "        bp_class_combo[med] += 1\n",
    "\n",
    "    class_list = med.split('+')\n",
    "    for c in class_list:\n",
    "        if c not in bp_class:\n",
    "            bp_class[c] = 1\n",
    "        else:\n",
    "            bp_class[c] += 1\n",
    "\n",
    "    if len(class_list) > 6:\n",
    "        MaskID_morethan6.add(row['MaskID'])\n",
    "        rows_morethan6.append(i)\n",
    "\n",
    "print('len(bp_class) =', len(bp_class))\n",
    "print('len(bp_class_combo) =', len(bp_class_combo))\n",
    "\n",
    "print('len(MaskID_morethan6) =', len(MaskID_morethan6))\n",
    "\n",
    "# count how many rows whose MaskID is in MaskID_morethan6\n",
    "df_morethan6 = df[df['MaskID'].isin(MaskID_morethan6)]\n",
    "print('len(rows_morethan6) =', len(rows_morethan6))\n",
    "print('# of rows whose MaskID is in MaskID_morethan6 =', df_morethan6.shape[0])\n",
    "\n",
    "df_keep = df[~df['MaskID'].isin(MaskID_morethan6)]\n",
    "print('df_keep.shape =', df_keep.shape)\n",
    "df_keep.to_csv('data/temp/ACCORD_BPMed2Class_activeBP_removemorethan6class.csv', index=False)\n",
    "\n",
    "# sort by value\n",
    "bp_class = {k: v for k, v in sorted(bp_class.items(), key=lambda item: item[1], reverse=True)}\n",
    "bp_class_combo = {k: v for k, v in sorted(bp_class_combo.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# save to csv\n",
    "name = bp_class.keys()\n",
    "freq = bp_class.values()\n",
    "df = pd.DataFrame({'class':name, 'freq':freq})\n",
    "df.to_csv('data/temp/bp_class.csv', index=False)\n",
    "\n",
    "name = bp_class_combo.keys()\n",
    "freq = bp_class_combo.values()\n",
    "df = pd.DataFrame({'class_combo':name, 'freq':freq, 'length': [len(x.split('+')) for x in name]})\n",
    "df.to_csv('data/temp/bp_class_combo.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy file '/data/temp/ACCORD_BPMed2Class_activeBP_removemorethan6class.csv' to 'data/ACCORD_BPClass.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCORD_BGClass.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete patients who had ever used any of the 4 bg med\n",
    "\n",
    "bg_med_to_remove = {'nateglinide','gliclazide', 'pramlintide', 'sulfonylurea'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375317, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375317/375317 [00:43<00:00, 8696.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(MaskID_to_remove) = 499\n",
      "df_keep.shape = (353546, 43)\n"
     ]
    }
   ],
   "source": [
    "bg_med_to_remove = {'nateglinide','gliclazide', 'pramlintide', 'sulfonylurea'}\n",
    "\n",
    "df = pd.read_csv('data/temp/ACCORD_BPMed2Class.csv')\n",
    "print(df.shape)\n",
    "\n",
    "MaskID_to_remove = set()\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[i]\n",
    "    med = row['oral_gmed']\n",
    "    if med == 'none':\n",
    "        continue\n",
    "\n",
    "    class_list = med.split('+')\n",
    "    for c in class_list:\n",
    "        if c in bg_med_to_remove:\n",
    "            MaskID_to_remove.add(row['MaskID'])\n",
    "            break\n",
    "\n",
    "print('len(MaskID_to_remove) =', len(MaskID_to_remove))\n",
    "\n",
    "df_keep = df[~df['MaskID'].isin(MaskID_to_remove)]\n",
    "print('df_keep.shape =', df_keep.shape)\n",
    "\n",
    "df_keep.to_csv('data/temp/ACCORD_BPMed2Class_removebgmed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace the bg med to BGClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg_class_dict = {'gliclazide': 'Sulfon', 'glimepiride': 'Sulfon', 'glipizide': 'Sulfon', 'glyburide': 'Sulfon', 'metformin': 'Bingu', 'exanatide': 'Incr-ago', 'repaglinide': 'Meglit', 'nateglinide': 'Meglit', 'rosiglitazone': 'Thiaz', 'pioglitazone': 'Thiaz', 'sitagliptin': 'DPP-4', 'acarbose': 'Alpha-gluc', 'pramlintide': 'Amy-ana'}\n",
      "(353546, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 353546/353546 [00:41<00:00, 8622.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_BGclass(fn, class_dict):\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "    df = med_to_class(df, 'oral_gmed', 'BGClass', class_dict)\n",
    "    df.to_csv('data/temp/ACCORD_BGMed2Class.csv', index=False)\n",
    "\n",
    "# load the bg_class_dict from the csv file, keys are bg_med column, values are class column\n",
    "df = pd.read_csv('data/temp/bg_class_dict.csv')\n",
    "bg_class_dict = {k:v for k,v in zip(df['bg_med'], df['class'])}\n",
    "print('bg_class_dict =', bg_class_dict)\n",
    "\n",
    "process_BGclass('data/temp/ACCORD_BPMed2Class_removebgmed.csv', bg_class_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count frequency of each BPClass and BPClass combo\n",
    "\n",
    "also remove patients who had ever used more than 5 BGclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353546, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 353546/353546 [00:45<00:00, 7760.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(bp_class) = 10\n",
      "len(bp_class_combo) = 289\n",
      "len(MaskID_morethan5) = 28\n",
      "len(rows_morethan5) = 78\n",
      "# of rows whose MaskID is in MaskID_morethan5 = 1505\n",
      "df_keep.shape = (352041, 44)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/temp/ACCORD_BGMed2Class.csv')\n",
    "print(df.shape)\n",
    "\n",
    "bg_class = dict()\n",
    "bg_class_combo = dict()\n",
    "MaskID_morethan5 = set()\n",
    "rows_morethan5 = []\n",
    "# loop through each row\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[i]\n",
    "    med = row['BGClass']\n",
    "    if med not in bg_class_combo:\n",
    "        bg_class_combo[med] = 1\n",
    "    else:\n",
    "        bg_class_combo[med] += 1\n",
    "\n",
    "    class_list = med.split('+')\n",
    "    for c in class_list:\n",
    "        if c not in bg_class:\n",
    "            bg_class[c] = 1\n",
    "        else:\n",
    "            bg_class[c] += 1\n",
    "\n",
    "    if len(class_list) > 5:\n",
    "        MaskID_morethan5.add(row['MaskID'])\n",
    "        rows_morethan5.append(i)\n",
    "\n",
    "print('len(bp_class) =', len(bp_class))\n",
    "print('len(bp_class_combo) =', len(bp_class_combo))\n",
    "\n",
    "print('len(MaskID_morethan5) =', len(MaskID_morethan5))\n",
    "\n",
    "# count how many rows whose MaskID is in MaskID_morethan6\n",
    "df_morethan5 = df[df['MaskID'].isin(MaskID_morethan5)]\n",
    "print('len(rows_morethan5) =', len(rows_morethan5))\n",
    "print('# of rows whose MaskID is in MaskID_morethan5 =', df_morethan5.shape[0])\n",
    "\n",
    "df_keep = df[~df['MaskID'].isin(MaskID_morethan5)]\n",
    "print('df_keep.shape =', df_keep.shape)\n",
    "df_keep.to_csv('data/temp/ACCORD_BGMed2Class_removemorethan5class.csv', index=False)\n",
    "\n",
    "# sort by value\n",
    "bg_class = {k: v for k, v in sorted(bg_class.items(), key=lambda item: item[1], reverse=True)}\n",
    "bg_class_combo = {k: v for k, v in sorted(bg_class_combo.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# save to csv\n",
    "name = bg_class.keys()\n",
    "freq = bg_class.values()\n",
    "df = pd.DataFrame({'class':name, 'freq':freq})\n",
    "df.to_csv('data/temp/bg_class.csv', index=False)\n",
    "\n",
    "name = bg_class_combo.keys()\n",
    "freq = bg_class_combo.values()\n",
    "df = pd.DataFrame({'class_combo':name, 'freq':freq, 'length': [len(x.split('+')) for x in name]})\n",
    "df.to_csv('data/temp/bg_class_combo.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove patients who had ever used Incr-ago or DPP-4 BGClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352041, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352041/352041 [00:41<00:00, 8448.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(MaskID_to_remove) = 1318\n",
      "df_keep.shape = (290676, 44)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/temp/ACCORD_BGMed2Class_removemorethan5class.csv')\n",
    "print(df.shape)\n",
    "\n",
    "bgclass_to_remove = {'Incr-ago', 'DPP-4'}\n",
    "\n",
    "MaskID_to_remove = set()\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[i]\n",
    "    med = row['BGClass']\n",
    "    if med == 'none':\n",
    "        continue\n",
    "\n",
    "    class_list = med.split('+')\n",
    "    for c in class_list:\n",
    "        if c in bgclass_to_remove:\n",
    "            MaskID_to_remove.add(row['MaskID'])\n",
    "            break\n",
    "\n",
    "print('len(MaskID_to_remove) =', len(MaskID_to_remove))\n",
    "\n",
    "df_keep = df[~df['MaskID'].isin(MaskID_to_remove)]\n",
    "print('df_keep.shape =', df_keep.shape)\n",
    "\n",
    "df_keep.to_csv('data/temp/ACCORD_BGMed2Class_removemorethan5class_removebgclass.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy 'data/temp/ACCORD_BGMed2Class_removemorethan5class_removebgclass.csv' to 'data/ACCORD_BGClass.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCORD_BPBGClass.csv\n",
    "\n",
    "simply select active BP patients from 'data/ACCORD_BGClass.csv' obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(bp_active_set) = 4733\n",
      "(290676, 44)\n",
      "after selecting only rows with MaskID in bp_active_set, df.shape = (139099, 44)\n"
     ]
    }
   ],
   "source": [
    "def process_bpbg_med(fn, bp_active_set):\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # select only rows with MaskID in bp_active_set\n",
    "    df = df[df['MaskID'].isin(bp_active_set)]\n",
    "    print('after selecting only rows with MaskID in bp_active_set, df.shape =', df.shape)\n",
    "\n",
    "    # save to csv\n",
    "    df.to_csv('data/ACCORD_BPBGClass.csv', index=False)\n",
    "\n",
    "\n",
    "# load bp_active_set from the csv file, each line is a MaskID\n",
    "with open('data/temp/candidates_bp.csv', 'r') as f:\n",
    "    bp_active_set = set()\n",
    "    for line in f:\n",
    "        bp_active_set.add(int(line.strip()))\n",
    "    print('len(bp_active_set) =', len(bp_active_set))\n",
    "\n",
    "process_bpbg_med('data/ACCORD_BGClass.csv', bp_active_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v2.csv\n",
    "\n",
    "1. discretize some numeric variables\n",
    "2. add feedback\n",
    "3. one-hot encode BPmed and BGmed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fn = data/ACCORD_BPMed.csv\n",
      "(178792, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178792/178792 [00:23<00:00, 7582.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fn = data/ACCORD_BGMed.csv\n",
      "(351481, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351481/351481 [00:50<00:00, 6905.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fn = data/ACCORD_BPBGMed.csv\n",
      "(167939, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167939/167939 [00:24<00:00, 6821.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fn = data/ACCORD_BPClass.csv\n",
      "(177031, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177031/177031 [00:25<00:00, 7023.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fn = data/ACCORD_BGClass.csv\n",
      "(290676, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290676/290676 [00:41<00:00, 7037.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fn = data/ACCORD_BPBGClass.csv\n",
      "(139099, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139099/139099 [00:19<00:00, 7049.27it/s]\n"
     ]
    }
   ],
   "source": [
    "def discretize_var(fn):\n",
    "\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # discretize sbp, hba1c, BMI, hdl, TC\n",
    "    sbp_discrete = []\n",
    "    hba1c_discrete = []\n",
    "    BMI_discrete = []\n",
    "    hdl_discrete = []\n",
    "    TC_discrete = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        sbp = row['sbp']\n",
    "        hba1c = row['hba1c']\n",
    "        BMI = row['BMI']\n",
    "        hdl = row['hdl']\n",
    "        TC = row['TC']\n",
    "\n",
    "        if sbp < 120:\n",
    "            sbp_discrete.append(0)\n",
    "        elif sbp < 140:\n",
    "            sbp_discrete.append(1)\n",
    "        elif sbp < 160:\n",
    "            sbp_discrete.append(2)\n",
    "        else:\n",
    "            sbp_discrete.append(3)\n",
    "\n",
    "        if hba1c < 6:\n",
    "            hba1c_discrete.append(0)\n",
    "        elif hba1c < 6.5:\n",
    "            hba1c_discrete.append(1)\n",
    "        elif hba1c < 7:\n",
    "            hba1c_discrete.append(2)\n",
    "        elif hba1c < 7.5:\n",
    "            hba1c_discrete.append(3)\n",
    "        elif hba1c < 8:\n",
    "            hba1c_discrete.append(4)\n",
    "        elif hba1c < 8.5:\n",
    "            hba1c_discrete.append(5)\n",
    "        elif hba1c < 9:\n",
    "            hba1c_discrete.append(6)\n",
    "        else:\n",
    "            hba1c_discrete.append(7)            \n",
    "\n",
    "        if BMI < 18.5:\n",
    "            BMI_discrete.append(0)\n",
    "        elif BMI < 25:\n",
    "            BMI_discrete.append(1)\n",
    "        elif BMI < 30:\n",
    "            BMI_discrete.append(2)\n",
    "        else:\n",
    "            BMI_discrete.append(3)\n",
    "\n",
    "        if hdl < 40:\n",
    "            hdl_discrete.append(0)\n",
    "        elif hdl < 50:\n",
    "            hdl_discrete.append(1)\n",
    "        elif hdl < 60:\n",
    "            hdl_discrete.append(2)\n",
    "        else:\n",
    "            hdl_discrete.append(3)\n",
    "\n",
    "        if TC < 160:\n",
    "            TC_discrete.append(0)\n",
    "        elif TC < 200:\n",
    "            TC_discrete.append(1)\n",
    "        elif TC < 240:\n",
    "            TC_discrete.append(2)\n",
    "        else:\n",
    "            TC_discrete.append(3)\n",
    "    \n",
    "    df['sbp_discrete'] = sbp_discrete\n",
    "    df['hba1c_discrete'] = hba1c_discrete\n",
    "    df['BMI_discrete'] = BMI_discrete\n",
    "    df['hdl_discrete'] = hdl_discrete\n",
    "    df['TC_discrete'] = TC_discrete\n",
    "\n",
    "    # save to csv\n",
    "    fn_out = fn.replace('.csv', '_v2.csv')\n",
    "    df.to_csv(fn_out, index=False)\n",
    "\n",
    "\n",
    "discretize_var('data/ACCORD_BPMed.csv')\n",
    "discretize_var('data/ACCORD_BGMed.csv')\n",
    "discretize_var('data/ACCORD_BPBGMed.csv')\n",
    "discretize_var('data/ACCORD_BPClass.csv')\n",
    "discretize_var('data/ACCORD_BGClass.csv')  \n",
    "discretize_var('data/ACCORD_BPBGClass.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPClass_v2.csv\n",
      "(176906, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10251/10251 [00:05<00:00, 2034.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_feedback_patient(df_patient, col_name):\n",
    "\n",
    "    # get df_patient[col_name] and convert it to list\n",
    "    target_col = df_patient[col_name].tolist()\n",
    "    res_col = target_col.copy()\n",
    "\n",
    "    if len(target_col) == 1:\n",
    "        return res_col\n",
    "    \n",
    "    for idx in range(len(target_col)-1):\n",
    "        res_col[idx] = target_col[idx+1]\n",
    "    res_col[-1] = target_col[-1]\n",
    "    \n",
    "    return res_col\n",
    "\n",
    "\n",
    "def add_feedback(fn):\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # add feedback\n",
    "    sbp_fb = [] \n",
    "    hba1c_fb = []\n",
    "    cvdrisk_fb = []\n",
    "    bmi_fb = []\n",
    "    TC_fb = []\n",
    "    hdl_fb = []\n",
    "    \n",
    "    # loop through each patient\n",
    "    for maskid in tqdm(range(100001, 110252)):\n",
    "        # print('maskid =', maskid)\n",
    "        df_patient = df[df['MaskID'] == maskid]\n",
    "        if df_patient.shape[0] == 0: # no data for this patient\n",
    "            continue\n",
    "        sbp_fb_patient = get_feedback_patient(df_patient, 'sbp')\n",
    "        hba1c_fb_patient = get_feedback_patient(df_patient, 'hba1c')\n",
    "        cvdrisk_fb_patient = get_feedback_patient(df_patient, 'CVDRisk')\n",
    "        bmi_fb_patient = get_feedback_patient(df_patient, 'BMI')\n",
    "        TC_fb_patient = get_feedback_patient(df_patient, 'TC')\n",
    "        hdl_fb_patient = get_feedback_patient(df_patient, 'hdl')\n",
    "        sbp_fb.extend(sbp_fb_patient)\n",
    "        hba1c_fb.extend(hba1c_fb_patient)\n",
    "        cvdrisk_fb.extend(cvdrisk_fb_patient)\n",
    "        bmi_fb.extend(bmi_fb_patient)\n",
    "        TC_fb.extend(TC_fb_patient)\n",
    "        hdl_fb.extend(hdl_fb_patient)\n",
    "    \n",
    "    # assert the length of feedback is the same as the original data\n",
    "    assert len(sbp_fb) == df.shape[0]\n",
    "    assert len(hba1c_fb) == df.shape[0]\n",
    "    assert len(cvdrisk_fb) == df.shape[0]\n",
    "\n",
    "    df['sbp_feedback'] = sbp_fb\n",
    "    df['hba1c_feedback'] = hba1c_fb\n",
    "    df['CVDRisk_feedback'] = cvdrisk_fb\n",
    "    df['BMI_feedback'] = bmi_fb\n",
    "    df['TC_feedback'] = TC_fb\n",
    "    df['hdl_feedback'] = hdl_fb\n",
    "\n",
    "    # overwrite the original csv\n",
    "    df.to_csv(fn, index=False)\n",
    "\n",
    "# add_feedback('data/ACCORD_BPMed_v2.csv')\n",
    "# add_feedback('data/ACCORD_BGMed_v2.csv')\n",
    "# add_feedback('data/ACCORD_BPBGMed_v2.csv')\n",
    "add_feedback('data/ACCORD_BPClass_v2.csv')\n",
    "# add_feedback('data/ACCORD_BGClass_v2.csv')\n",
    "# add_feedback('data/ACCORD_BPBGClass_v2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize the feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPClass_v2.csv\n",
      "(176906, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176906/176906 [00:26<00:00, 6698.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# discretize the feedback\n",
    "def discretize_feedback(fn):\n",
    "\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # discretize sbp, hba1c, BMI, hdl, TC\n",
    "    sbp_discrete = []\n",
    "    hba1c_discrete = []\n",
    "    BMI_discrete = []\n",
    "    hdl_discrete = []\n",
    "    TC_discrete = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[i]\n",
    "        sbp = row['sbp_feedback']\n",
    "        hba1c = row['hba1c_feedback']\n",
    "        BMI = row['BMI_feedback']\n",
    "        hdl = row['hdl_feedback']\n",
    "        TC = row['TC_feedback']\n",
    "\n",
    "        if sbp < 120:\n",
    "            sbp_discrete.append(0)\n",
    "        elif sbp < 140:\n",
    "            sbp_discrete.append(1)\n",
    "        elif sbp < 160:\n",
    "            sbp_discrete.append(2)\n",
    "        else:\n",
    "            sbp_discrete.append(3)\n",
    "\n",
    "        if hba1c < 6:\n",
    "            hba1c_discrete.append(0)\n",
    "        elif hba1c < 6.5:\n",
    "            hba1c_discrete.append(1)\n",
    "        elif hba1c < 7:\n",
    "            hba1c_discrete.append(2)\n",
    "        elif hba1c < 7.5:\n",
    "            hba1c_discrete.append(3)\n",
    "        elif hba1c < 8:\n",
    "            hba1c_discrete.append(4)\n",
    "        elif hba1c < 8.5:\n",
    "            hba1c_discrete.append(5)\n",
    "        elif hba1c < 9:\n",
    "            hba1c_discrete.append(6)\n",
    "        else:\n",
    "            hba1c_discrete.append(7)            \n",
    "\n",
    "        if BMI < 18.5:\n",
    "            BMI_discrete.append(0)\n",
    "        elif BMI < 25:\n",
    "            BMI_discrete.append(1)\n",
    "        elif BMI < 30:\n",
    "            BMI_discrete.append(2)\n",
    "        else:\n",
    "            BMI_discrete.append(3)\n",
    "\n",
    "        if hdl < 40:\n",
    "            hdl_discrete.append(0)\n",
    "        elif hdl < 50:\n",
    "            hdl_discrete.append(1)\n",
    "        elif hdl < 60:\n",
    "            hdl_discrete.append(2)\n",
    "        else:\n",
    "            hdl_discrete.append(3)\n",
    "\n",
    "        if TC < 160:\n",
    "            TC_discrete.append(0)\n",
    "        elif TC < 200:\n",
    "            TC_discrete.append(1)\n",
    "        elif TC < 240:\n",
    "            TC_discrete.append(2)\n",
    "        else:\n",
    "            TC_discrete.append(3)\n",
    "    \n",
    "    df['sbp_feedback_discrete'] = sbp_discrete\n",
    "    df['hba1c_feedback_discrete'] = hba1c_discrete\n",
    "    df['BMI_feedback_discrete'] = BMI_discrete\n",
    "    df['hdl_feedback_discrete'] = hdl_discrete\n",
    "    df['TC_feedback_discrete'] = TC_discrete\n",
    "\n",
    "    # save to csv\n",
    "    fn_out = fn\n",
    "    # fn_out = fn.replace('.csv', '_v2.csv')\n",
    "    df.to_csv(fn_out, index=False)\n",
    "\n",
    "\n",
    "# discretize_feedback('data/ACCORD_BPMed_v2.csv')\n",
    "# discretize_feedback('data/ACCORD_BGMed_v2.csv')\n",
    "# discretize_feedback('data/ACCORD_BPBGMed_v2.csv')\n",
    "discretize_feedback('data/ACCORD_BPClass_v2.csv')\n",
    "# discretize_feedback('data/ACCORD_BGClass_v2.csv')  \n",
    "# discretize_feedback('data/ACCORD_BPBGClass_v2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode BPMed and BGMed, BPClass and BGClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPMed_v2.csv\n",
      "(178792, 51)\n",
      "fn = data/ACCORD_BGMed_v2.csv\n",
      "(351481, 51)\n",
      "fn = data/ACCORD_BPBGMed_v2.csv\n",
      "(167939, 51)\n",
      "fn = data/ACCORD_BPBGMed_v2.csv\n",
      "(167939, 51)\n",
      "fn = data/ACCORD_BPClass_v2.csv\n",
      "(177031, 51)\n",
      "fn = data/ACCORD_BGClass_v2.csv\n",
      "(290676, 52)\n",
      "fn = data/ACCORD_BPBGClass_v2.csv\n",
      "(139099, 52)\n",
      "fn = data/ACCORD_BPBGClass_v2.csv\n",
      "(139099, 52)\n"
     ]
    }
   ],
   "source": [
    "# add prefix to 'none' values in med columns\n",
    "def fix_none(fn, col_name, new_value):\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # replace the none values in column 'bp_med_most5' with 'bpmed_none'\n",
    "    df[col_name] = df[col_name].replace('none', new_value)\n",
    "    df.to_csv(fn, index=False)\n",
    "\n",
    "fix_none('data/ACCORD_BPMed_v2.csv', 'bp_med_most5', 'bpmed_none')\n",
    "fix_none('data/ACCORD_BGMed_v2.csv', 'oral_gmed', 'bgmed_none')\n",
    "fix_none('data/ACCORD_BPBGMed_v2.csv', 'bp_med_most5', 'bpmed_none')\n",
    "fix_none('data/ACCORD_BPBGMed_v2.csv', 'oral_gmed', 'bgmed_none')\n",
    "\n",
    "fix_none('data/ACCORD_BPClass_v2.csv', 'BPClass', 'bpclass_none')\n",
    "fix_none('data/ACCORD_BGClass_v2.csv', 'BGClass', 'bgclass_none')\n",
    "fix_none('data/ACCORD_BPBGClass_v2.csv', 'BPClass', 'bpclass_none')\n",
    "fix_none('data/ACCORD_BPBGClass_v2.csv', 'BGClass', 'bgclass_none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPMed_v2.csv\n",
      "(178792, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178792/178792 [00:21<00:00, 8270.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BGMed_v2.csv\n",
      "(351481, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351481/351481 [00:43<00:00, 8091.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPBGMed_v2.csv\n",
      "(167939, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167939/167939 [00:21<00:00, 7919.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPClass_v2.csv\n",
      "(177031, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177031/177031 [00:21<00:00, 8427.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BGClass_v2.csv\n",
      "(290676, 52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290676/290676 [00:34<00:00, 8470.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPBGClass_v2.csv\n",
      "(139099, 52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139099/139099 [00:17<00:00, 7999.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def onehot_encode(fn, col_name_list, names_list):\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # build a dict with keys are names in names_list and values are empty lists\n",
    "    dict_onehot = {}\n",
    "    for name in names_list:\n",
    "        dict_onehot[name] = []\n",
    "    \n",
    "    # loop through each row    \n",
    "    for idx in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[idx]\n",
    "        med_set = set()\n",
    "        for col_name in col_name_list:\n",
    "            med = row[col_name]\n",
    "            med_items = med.split('+')\n",
    "            med_set.update(med_items)\n",
    "\n",
    "        for name in names_list:\n",
    "            if name in med_set:\n",
    "                dict_onehot[name].append(1)\n",
    "            else:\n",
    "                dict_onehot[name].append(0)\n",
    "    \n",
    "    # add onehot columns to df\n",
    "    for name in names_list:\n",
    "        df[name] = dict_onehot[name]\n",
    "        # check if the sum of each column is 0, check if any bpmed or bgmed has no occurrence, this means we messed up\n",
    "        if df[name].sum() == 0:\n",
    "            print(\"error: sum of column {} is 0\".format(name))\n",
    "            raise Exception(\"error: sum of column {} is 0\".format(name))\n",
    "    \n",
    "    # overwrite the original csv\n",
    "    fn_out = fn.replace('.csv', '_onehot.csv')\n",
    "    df.to_csv(fn_out, index=False)\n",
    "\n",
    "\n",
    "# 18 bp meds\n",
    "bp_med_list = ['bpmed_none', 'metoprolol', 'hctz', 'lisinopril', 'chlorthalidone', \n",
    "            'valsartan', 'benazepril', 'furosemide', 'candesartan', 'ramipril', \n",
    "            'amlodipine', 'diltiazem', 'carvedilol', 'felodipine', 'terazosin', \n",
    "            'reserpine', 'triamterene', 'hydralazine']\n",
    "\n",
    "# 11 bg meds    \n",
    "bg_med_list = ['bgmed_none', 'metformin', 'rosiglitazone', 'glimepiride', 'repaglinide', \n",
    "            'acarbose', 'pioglitazone', 'exanatide', 'glyburide', 'sitagliptin', \n",
    "            'glipizide']\n",
    "\n",
    "bpbg_med_list = bp_med_list + bg_med_list\n",
    "\n",
    "# 10 bp classes\n",
    "bp_class_list = ['bpclass_none', 'Diur', 'ACE', 'Beta-blocker', 'CCB', \n",
    "                'ARB', 'Alpha-Beta-blocker', 'Alpha-blocker', 'Sympath', 'Vasod']\n",
    "\n",
    "# 6 bg classes\n",
    "bg_class_list = ['bgclass_none', 'Bingu', 'Thiaz', 'Sulfon', 'Meglit', 'Alpha-gluc']\n",
    "\n",
    "bpbg_class_list = bp_class_list + bg_class_list\n",
    "\n",
    "onehot_encode('data/ACCORD_BPMed_v2.csv', ['bp_med_most5'], bp_med_list)\n",
    "onehot_encode('data/ACCORD_BGMed_v2.csv', ['oral_gmed'], bg_med_list)\n",
    "onehot_encode('data/ACCORD_BPBGMed_v2.csv', ['bp_med_most5','oral_gmed'], bp_med_list)\n",
    "\n",
    "onehot_encode('data/ACCORD_BPClass_v2.csv', ['BPClass'], bp_class_list)\n",
    "onehot_encode('data/ACCORD_BGClass_v2.csv', ['BGClass'], bg_class_list)\n",
    "onehot_encode('data/ACCORD_BPBGClass_v2.csv', ['BPClass','BGClass'], bpbg_class_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the suffix '_onehot' to fix v2 datasets names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify datasets for running RL algorithms\n",
    "\n",
    "For ACCORD_BPClass_v2.csv, ACCORD_BGClass_v2.csv, ACCORD_BPBGClass_v2.csv:\n",
    "\n",
    "1. remove patients/rows with missing edu_baseline, 125 rows with 3 patients in BPClass_v2.csv\n",
    "2. add baseline_BMI column\n",
    "3. one-hot enncode the raceclass into 2 category: race_whiteother, race_black\n",
    "4. turn the CVDRisk_feedback into CVDRisk_feedback_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPClass_v2.csv\n",
      "(177031, 61)\n",
      "after removing mising edu_baseline rows: (176906, 61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176906/176906 [00:25<00:00, 6834.65it/s]\n"
     ]
    }
   ],
   "source": [
    "def update_dataset(fn):\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    # remove the rows with edu_baseline = -1, and count the number of rows\n",
    "    df = df[df['edu_baseline'] != -1]\n",
    "    print(\"after removing mising edu_baseline rows:\", df.shape)\n",
    "\n",
    "    baseline_BMI = []\n",
    "    # loop through each row, calculate the baseline_BMI\n",
    "    for idx in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[idx]\n",
    "        weight = row['wt_kg_baseline']\n",
    "        height = row['ht_cm_baseline']\n",
    "        bmi = weight / (height/100)**2\n",
    "        baseline_BMI.append(bmi)\n",
    "    \n",
    "    # add a column 'baseline_BMI' to df\n",
    "    df['baseline_BMI'] = baseline_BMI\n",
    "\n",
    "    # overwrite the original csv\n",
    "    df.to_csv(fn, index=False)\n",
    "\n",
    "update_dataset('data/ACCORD_BPClass_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BGClass_v2.csv\n",
      "(290676, 58)\n",
      "after removing mising edu_baseline rows: (290467, 58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290467/290467 [00:41<00:00, 7033.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPBGClass_v2.csv\n",
      "(139099, 68)\n",
      "after removing mising edu_baseline rows: (139005, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139005/139005 [00:18<00:00, 7384.02it/s]\n"
     ]
    }
   ],
   "source": [
    "update_dataset('data/ACCORD_BGClass_v2.csv')\n",
    "update_dataset('data/ACCORD_BPBGClass_v2.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPClass_v2.csv\n",
      "(176906, 62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176906/176906 [00:23<00:00, 7618.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BGClass_v2.csv\n",
      "(290467, 59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290467/290467 [00:39<00:00, 7285.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPBGClass_v2.csv\n",
      "(139005, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139005/139005 [00:20<00:00, 6671.76it/s]\n"
     ]
    }
   ],
   "source": [
    "def onehot_encode_raceclass(fn):\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    race_whiteother = []\n",
    "    race_black = []\n",
    "    # loop through each row, calculate the baseline_BMI\n",
    "    for idx in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[idx]\n",
    "        race = row['raceclass']\n",
    "        if race == 'White' or race == 'Other' or race =='Hispanic':\n",
    "            race_whiteother.append(1)\n",
    "            race_black.append(0)\n",
    "        elif race == 'Black':\n",
    "            race_whiteother.append(0)\n",
    "            race_black.append(1)\n",
    "        else:\n",
    "            print('race =', race)\n",
    "            raise Exception(\"error: raceclass is not White, Black or Other\")\n",
    "            exit()\n",
    "    \n",
    "    df['race_whiteother'] = race_whiteother\n",
    "    df['race_black'] = race_black\n",
    "\n",
    "    # overwrite the original csv\n",
    "    df.to_csv(fn, index=False)\n",
    "\n",
    "onehot_encode_raceclass('data/ACCORD_BPClass_v2.csv')\n",
    "onehot_encode_raceclass('data/ACCORD_BGClass_v2.csv')\n",
    "onehot_encode_raceclass('data/ACCORD_BPBGClass_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn = data/ACCORD_BPClass_v2.csv\n",
      "(176906, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176906/176906 [00:24<00:00, 7152.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of CVDRisk_feedback_binary = 0.49197879099634834\n",
      "median of CVDRisk_feedback_binary = 0.0\n",
      "std of CVDRisk_feedback_binary = 0.4999370690703593\n",
      "fn = data/ACCORD_BGClass_v2.csv\n",
      "(290467, 61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290467/290467 [00:43<00:00, 6648.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of CVDRisk_feedback_binary = 0.5505444680462841\n",
      "median of CVDRisk_feedback_binary = 1.0\n",
      "std of CVDRisk_feedback_binary = 0.497439552751152\n",
      "fn = data/ACCORD_BPBGClass_v2.csv\n",
      "(139005, 71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139005/139005 [00:21<00:00, 6612.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of CVDRisk_feedback_binary = 0.5183770367972375\n",
      "median of CVDRisk_feedback_binary = 1.0\n",
      "std of CVDRisk_feedback_binary = 0.49966396768047716\n"
     ]
    }
   ],
   "source": [
    "# turn the CVDRisk_feedback into a binary variable using threshold value of 0.5\n",
    "def binarize_cvdrisk(fn):\n",
    "    print('fn =', fn)\n",
    "    df = pd.read_csv(fn)\n",
    "    print(df.shape)\n",
    "\n",
    "    CVDRisk_feedback_binary = []\n",
    "    # loop through each row, calculate the baseline_BMI\n",
    "    for idx in tqdm(range(df.shape[0])):\n",
    "        row = df.iloc[idx]\n",
    "        CVDRisk_feedback = row['CVDRisk_feedback']\n",
    "        if CVDRisk_feedback >= 0.2: # here we use 0.2 as the threshold to make the binarized class balance, as only 3% data has CVDRisk_feedback >= 0.5\n",
    "            CVDRisk_feedback_binary.append(1)\n",
    "        else:\n",
    "            CVDRisk_feedback_binary.append(0)\n",
    "    \n",
    "    df['CVDRisk_feedback_binary'] = CVDRisk_feedback_binary\n",
    "\n",
    "    # print the mean of CVDRisk_feedback_binary\n",
    "    print('mean of CVDRisk_feedback_binary =', df['CVDRisk_feedback_binary'].mean())\n",
    "    print('median of CVDRisk_feedback_binary =', df['CVDRisk_feedback_binary'].median())\n",
    "    print('std of CVDRisk_feedback_binary =', df['CVDRisk_feedback_binary'].std())\n",
    "\n",
    "    # overwrite the original csv\n",
    "    df.to_csv(fn, index=False)\n",
    "\n",
    "binarize_cvdrisk('data/ACCORD_BPClass_v2.csv')\n",
    "binarize_cvdrisk('data/ACCORD_BGClass_v2.csv')\n",
    "binarize_cvdrisk('data/ACCORD_BPBGClass_v2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f']\n"
     ]
    }
   ],
   "source": [
    "lst1 = ['a', 'b', 'c']\n",
    "lst2 = ['d', 'e', 'f']\n",
    "res = lst1 + lst2\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b+\n"
     ]
    }
   ],
   "source": [
    "lst = ['a', 'b', '']\n",
    "res = '+'.join(lst)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc']\n"
     ]
    }
   ],
   "source": [
    " med_visit = 'abc'\n",
    " med_list = med_visit.split('+')\n",
    " print(med_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 2, -1, 2, -1, 4, -1, -1]\n",
      "[2, 2, 2.0, 2, 3.0, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "old = [-1,2,-1, 2, -1, 4, -1, -1]\n",
    "print(old)\n",
    "new = fill_with_adjacent_avg_list(old,0)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    2\n",
      "Name: weight, dtype: int64\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe with 1 column 'weight' with 5 rows value of 1,\n",
    "\n",
    "wt = [1,1,None] \n",
    "df = pd.DataFrame(wt, columns=['weight'])\n",
    "print(df['weight'].value_counts())\n",
    "print(df['weight'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration\n",
      "r1    Spark  20000   30days\n",
      "r2  PySpark  25000   40days\n",
      "r3   Python  22000   35days\n",
      "r4   pandas  30000   50days\n",
      "   Courses  Discount\n",
      "r1   Spark      2000\n",
      "r6    Java      2300\n",
      "r3  Python      1200\n",
      "r5      Go      2000\n",
      "   Courses      Fee Duration  Discount\n",
      "0    Spark  20000.0   30days    2000.0\n",
      "1  PySpark  25000.0   40days       NaN\n",
      "2   Python  22000.0   35days    1200.0\n",
      "3   pandas  30000.0   50days       NaN\n",
      "4     Java      NaN      NaN    2300.0\n",
      "5       Go      NaN      NaN    2000.0\n",
      "   Courses      Fee Duration  Discount\n",
      "0    Spark  20000.0   30days    2000.0\n",
      "1  PySpark  25000.0   40days       NaN\n",
      "2   Python  22000.0   35days    1200.0\n",
      "3   pandas  30000.0   50days       NaN\n",
      "4     Java      NaN      NaN    2300.0\n",
      "5       Go      NaN      NaN    2000.0\n",
      "   Courses      Fee Duration  Discount\n",
      "0    Spark  20000.0   30days    2000.0\n",
      "1  PySpark  25000.0   40days       NaN\n",
      "2   Python  22000.0   35days    1200.0\n",
      "3   pandas  30000.0   50days       NaN\n",
      "4     Java      NaN      NaN    2300.0\n",
      "5       Go      NaN      NaN    2000.0\n",
      "   Courses      Fee Duration  Discount\n",
      "0    Spark  20000.0   30days    2000.0\n",
      "1  PySpark  25000.0   40days       NaN\n",
      "2   Python  22000.0   35days    1200.0\n",
      "3   pandas  30000.0   50days       NaN\n",
      "4     Java      NaN      NaN    2300.0\n",
      "5       Go      NaN      NaN    2000.0\n",
      "    Courses      Fee Duration Courses  Discount\n",
      "r1    Spark  20000.0   30days   Spark    2000.0\n",
      "r2  PySpark  25000.0   40days     NaN       NaN\n",
      "r3   Python  22000.0   35days  Python    1200.0\n",
      "r4   pandas  30000.0   50days     NaN       NaN\n",
      "r6      NaN      NaN      NaN    Java    2300.0\n",
      "r5      NaN      NaN      NaN      Go    2000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Python\",\"pandas\"],\n",
    "    'Fee' :[20000,25000,22000,30000],\n",
    "    'Duration':['30days','40days','35days','50days'],\n",
    "              }\n",
    "index_labels=['r1','r2','r3','r4']\n",
    "df1 = pd.DataFrame(technologies,index=index_labels)\n",
    "\n",
    "technologies2 = {\n",
    "    'Courses':[\"Spark\",\"Java\",\"Python\",\"Go\"],\n",
    "    'Discount':[2000,2300,1200,2000]\n",
    "              }\n",
    "index_labels2=['r1','r6','r3','r5']\n",
    "df2 = pd.DataFrame(technologies2,index=index_labels2)\n",
    "\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "# pandas join two DataFrames\n",
    "# df3=df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how='outer')\n",
    "# print(df3)\n",
    "\n",
    "# pandas.merge()\n",
    "df3=pd.merge(df1,df2, how='outer')\n",
    "print(df3)\n",
    "\n",
    "# DataFrame.merge()\n",
    "# df3=df1.merge(df2, how='outer')\n",
    "# print(df3)\n",
    "\n",
    "# Merge DataFrames by Columns\n",
    "df3=pd.merge(df1,df2, on='Courses', how='outer')\n",
    "print(df3)\n",
    "\n",
    "# When column names are different\n",
    "df3=pd.merge(df1,df2, left_on='Courses', right_on='Courses', how='outer')\n",
    "print(df3)\n",
    "\n",
    "# By using concat()\n",
    "df3=pd.concat([df1,df2],axis=1,join='outer')\n",
    "print(df3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c86494cdbaab790faf1630f8596bee794fd9c939f53713dc51278a7ffca15d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
