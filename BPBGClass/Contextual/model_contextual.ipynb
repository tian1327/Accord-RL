{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from UtilityMethods import utils\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import pulp as p\n",
    "import math\n",
    "from copy import copy\n",
    "import pprint as pp\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# IS_VISIT_DEPENDENT = False # whether the above empirical estimates are visit-dependent or not\n",
    "\n",
    "DATA3= '../data/ACCORD_BPBGClass_v2_merged.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MaskID', 'Visit', 'glycemia', 'bp', 'sbp', 'dbp', 'hr', 'hba1c', 'TC',\n",
      "       'trig', 'vldl', 'ldl', 'hdl', 'fpg', 'alt', 'cpk', 'potassium',\n",
      "       'screat', 'gfr', 'ualb', 'ucreat', 'uacr', 'edu_baseline',\n",
      "       'yrsdiab_baseline', 'yrstens_baseline', 'cigarett_baseline',\n",
      "       'wt_kg_baseline', 'ht_cm_baseline', 'wt_kg_visit', 'ht_cm_visit',\n",
      "       'oral_gmed', 'medadd', 'medchg_intbp', 'medchg_stdbp', 'bp_med', 'BMI',\n",
      "       'female', 'baseline_age', 'cvd_hx_baseline', 'raceclass', 'type_po',\n",
      "       'CVDRisk', 'BPClass', 'BGClass', 'sbp_discrete', 'hba1c_discrete',\n",
      "       'BMI_discrete', 'hdl_discrete', 'TC_discrete', 'sbp_feedback',\n",
      "       'hba1c_feedback', 'CVDRisk_feedback', 'bpclass_none', 'Diur', 'ACE',\n",
      "       'Beta-blocker', 'CCB', 'ARB', 'Alpha-Beta-blocker', 'Alpha-blocker',\n",
      "       'Sympath', 'Vasod', 'bgclass_none', 'Bingu', 'Thiaz', 'Sulfon',\n",
      "       'Meglit', 'Alpha-gluc', 'baseline_BMI', 'race_whiteother', 'race_black',\n",
      "       'CVDRisk_feedback_binary', 'BMI_feedback', 'TC_feedback',\n",
      "       'hba1c_discrete_merged', 'action_code', 'state_code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA3)\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize the context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catrgorize the edu_baseline into 3 columns \n",
    "\n",
    "edu1=[]\n",
    "edu2=[]\n",
    "edu3=[]\n",
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i]\n",
    "    edu = row['edu_baseline']      \n",
    "\n",
    "    if edu == 1:\n",
    "        edu1.append(1)\n",
    "        edu2.append(0)\n",
    "        edu3.append(0)\n",
    "    elif edu == 2:\n",
    "        edu1.append(0)\n",
    "        edu2.append(1)\n",
    "        edu3.append(0)\n",
    "    elif edu == 3:\n",
    "        edu1.append(0)\n",
    "        edu2.append(0)\n",
    "        edu3.append(1)\n",
    "    elif edu == 4:\n",
    "        edu1.append(0)\n",
    "        edu2.append(0)\n",
    "        edu3.append(0)\n",
    "    else:\n",
    "        print('error')\n",
    "        exit()\n",
    "\n",
    "df['edu_baseline_1'] = edu1\n",
    "df['edu_baseline_2'] = edu2\n",
    "df['edu_baseline_3'] = edu3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize the cigarett_baseline into 0/1, 1  = 1, 2 = 0\n",
    "cig1 = []\n",
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i]\n",
    "    cig = row['cigarett_baseline']\n",
    "    if cig == 1:\n",
    "        cig1.append(1)\n",
    "    elif cig == 2:\n",
    "        cig1.append(0)\n",
    "    else:\n",
    "        print('error')\n",
    "        exit()\n",
    "\n",
    "df['cigarett_baseline_1'] = cig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize the sbp_discrete_merged (0, 1, 2) into 2 columns, BUT WE WILL NOT USE 2 columns, but just 1 column\n",
    "# sbp1 = []\n",
    "# sbp2 = []\n",
    "# for i in range(df.shape[0]):\n",
    "#     row = df.iloc[i]\n",
    "#     sbp = row['sbp_discrete_merged']\n",
    "#     if sbp == 0:\n",
    "#         sbp1.append(1)\n",
    "#         sbp2.append(0)\n",
    "#     elif sbp == 1:\n",
    "#         sbp1.append(0)\n",
    "#         sbp2.append(1)\n",
    "#     elif sbp == 2:\n",
    "#         sbp1.append(0)\n",
    "#         sbp2.append(0)\n",
    "#     else:\n",
    "#         print('error')\n",
    "#         exit()\n",
    "\n",
    "# df['sbp_discrete_merged_1'] = sbp1\n",
    "# df['sbp_discrete_merged_2'] = sbp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139005, 81)\n",
      "Index(['MaskID', 'Visit', 'glycemia', 'bp', 'sbp', 'dbp', 'hr', 'hba1c', 'TC',\n",
      "       'trig', 'vldl', 'ldl', 'hdl', 'fpg', 'alt', 'cpk', 'potassium',\n",
      "       'screat', 'gfr', 'ualb', 'ucreat', 'uacr', 'edu_baseline',\n",
      "       'yrsdiab_baseline', 'yrstens_baseline', 'cigarett_baseline',\n",
      "       'wt_kg_baseline', 'ht_cm_baseline', 'wt_kg_visit', 'ht_cm_visit',\n",
      "       'oral_gmed', 'medadd', 'medchg_intbp', 'medchg_stdbp', 'bp_med', 'BMI',\n",
      "       'female', 'baseline_age', 'cvd_hx_baseline', 'raceclass', 'type_po',\n",
      "       'CVDRisk', 'BPClass', 'BGClass', 'sbp_discrete', 'hba1c_discrete',\n",
      "       'BMI_discrete', 'hdl_discrete', 'TC_discrete', 'sbp_feedback',\n",
      "       'hba1c_feedback', 'CVDRisk_feedback', 'bpclass_none', 'Diur', 'ACE',\n",
      "       'Beta-blocker', 'CCB', 'ARB', 'Alpha-Beta-blocker', 'Alpha-blocker',\n",
      "       'Sympath', 'Vasod', 'bgclass_none', 'Bingu', 'Thiaz', 'Sulfon',\n",
      "       'Meglit', 'Alpha-gluc', 'baseline_BMI', 'race_whiteother', 'race_black',\n",
      "       'CVDRisk_feedback_binary', 'BMI_feedback', 'TC_feedback',\n",
      "       'hba1c_discrete_merged', 'action_code', 'state_code', 'edu_baseline_1',\n",
      "       'edu_baseline_2', 'edu_baseline_3', 'cigarett_baseline_1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State space and action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(states) = 9\n",
      "['00', '01', '02', '10', '11']\n",
      "00 0\n",
      "01 1\n",
      "02 2\n",
      "\n",
      "len(actions) = 16\n",
      "0000 0\n",
      "0001 1\n",
      "0010 2\n",
      "0011 3\n",
      "0100 4\n",
      "Actions for State 0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# state space, actions available in each state are always the same\n",
    "\n",
    "\"\"\"\n",
    "state_features = ['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete','BMI_discrete'] \n",
    "sbp_level = ['0', '1', '2', '3'] # possible values for sbp_discrete\n",
    "hba1c_level = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "TC_level = ['0', '1', '2', '3']\n",
    "hdl_level = ['0', '1', '2', '3']\n",
    "BMI_level = ['0', '1', '2', '3']\n",
    "\"\"\"\n",
    "\n",
    "# here we merge levels\n",
    "sbp_level = ['0', '1', '2'] # sbp_discrete, 0: 0, 1:1, 2+3: 2\n",
    "hba1c_level = ['0', '1', '2'] # hba1c_discrete, 0+1: 0, 2+3: 1, 4+5+6+7: 2\n",
    "TC_level = ['0', '1'] # TC_discrete, 0+1: 0, 2+3: 1\n",
    "hdl_level = ['0', '1'] # hdl_discrete, 0+1: 0, 2+3: 1\n",
    "\n",
    "sbp_discrete_code_dict = {'0': '0', '1': '1',\n",
    "                          '2': '2', '3': '2',}\n",
    "\n",
    "hba1c_discrete_code_dict = {'0': '0', '1': '0', \n",
    "                            '2': '1', '3': '1', \n",
    "                            '4': '2', '5': '2', \n",
    "                            '6': '2', '7': '2'}\n",
    "\n",
    "TC_discrete_code_dict = {'0': '0', '1': '0',\n",
    "                         '2': '1', '3': '1'}\n",
    "\n",
    "hdl_discrete_code_dict = {'0': '0', '1': '0',\n",
    "                          '2': '1', '3': '1'}\n",
    "\n",
    "# 4 features, state space = 36\n",
    "# state_features = ['sbp_discrete', 'hba1c_discrete', 'TC_discrete', 'hdl_discrete'] \n",
    "# combinations = itertools.product(sbp_level, hba1c_level, TC_level, hdl_level)\n",
    "\n",
    "# 3 features, state space = 18\n",
    "# state_features = ['sbp_discrete', 'hba1c_discrete', 'TC_discrete'] \n",
    "# combinations = itertools.product(sbp_level, hba1c_level, TC_level)\n",
    "\n",
    "# 2 features, state space = 9\n",
    "combinations = itertools.product(sbp_level, hba1c_level)\n",
    "state_features = ['sbp_discrete', 'hba1c_discrete'] \n",
    "\n",
    "# 1 feature, srtate space = 3\n",
    "# combinations = itertools.product(hba1c_level)\n",
    "# state_features = ['hba1c_discrete'] \n",
    "\n",
    "states = [''.join(i) for i in combinations]\n",
    "print('len(states) =', len(states))\n",
    "print(states[:5])\n",
    "\n",
    "N_STATES = len(states) \n",
    "state_code_to_index = {code: i for i, code in enumerate(states)}\n",
    "state_index_to_code = {i: code for i, code in enumerate(states)}\n",
    "# print the first 5 state_code_to_index\n",
    "for i in range(3):\n",
    "    print(states[i], state_code_to_index[states[i]])\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# action space, 000000000 means bgclass_none, 111111111 means all bgmed class are precribed\n",
    "# we donot include 'bgclass_none' as a action, because 000000000 means bgclass_none\n",
    "# action_features = ['Bingu', 'Thiaz', 'Sulfon', 'Meglit'] # pick the top 4 most frequently prescribed bgmed class \n",
    "\n",
    "action_features = ['Diur', 'ACE',   \n",
    "                    'Bingu', 'Thiaz', ] # pick the top 2 most frequently prescribed BP and BG Med class \n",
    "\n",
    "combinations = list(itertools.product('01', repeat=len(action_features)))\n",
    "actions = [''.join(i) for i in combinations]\n",
    "print('len(actions) =', len(actions))\n",
    "N_ACTIONS = len(actions) # number of actions = 512\n",
    "action_code_to_index = {code: i for i, code in enumerate(actions)}\n",
    "action_index_to_code = {i: code for i, code in enumerate(actions)}\n",
    "# print the first 5 action_code_to_index\n",
    "for i in range(5):\n",
    "    print(actions[i], action_code_to_index[actions[i]])\n",
    "\n",
    "# build the action space for each state, assign the same action space to all states\n",
    "ACTIONS_PER_STATE = {}\n",
    "for s in range(N_STATES):\n",
    "    ACTIONS_PER_STATE[s] = [i for i in range(N_ACTIONS)] # this is the action code index\n",
    "print('Actions for State 0:', ACTIONS_PER_STATE[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate empirical estimates of P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding action_code and state_code columns\n"
     ]
    }
   ],
   "source": [
    "# add the state and action code columns\n",
    "action_code = []\n",
    "state_code = []\n",
    "sbp_discrete_merged = []\n",
    "hba1c_discrete_merged = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    s_code = ''\n",
    "    a_code = ''\n",
    "    for state_fea in state_features:\n",
    "        code = str(row[state_fea])\n",
    "\n",
    "        # merge 3 with 2 for sbp_discrete and TC_discrete\n",
    "        if state_fea == 'sbp_discrete':\n",
    "            code = sbp_discrete_code_dict[code]\n",
    "            sbp_discrete_merged.append(code)\n",
    "        elif state_fea == 'hba1c_discrete':\n",
    "            code = hba1c_discrete_code_dict[code]\n",
    "            hba1c_discrete_merged.append(code)\n",
    "        elif state_fea == 'TC_discrete':\n",
    "            code = TC_discrete_code_dict[code]\n",
    "        elif state_fea == 'hdl_discrete':\n",
    "            code = hdl_discrete_code_dict[code]\n",
    "        else:\n",
    "            raise ValueError('state_fea not recognized')\n",
    "            exit(1)       \n",
    "        \n",
    "        s_code += code\n",
    "    \n",
    "    for action_fea in action_features:\n",
    "        a_code += str(row[action_fea])\n",
    "    \n",
    "    action_code.append(a_code)\n",
    "    state_code.append(s_code)\n",
    "\n",
    "assert len(hba1c_discrete_merged) == len(df)\n",
    "\n",
    "df['sbp_discrete_merged'] = sbp_discrete_merged\n",
    "df['hba1c_discrete_merged'] = hba1c_discrete_merged\n",
    "df['action_code'] = action_code\n",
    "df['state_code'] = state_code\n",
    "print('Finished adding action_code and state_code columns')\n",
    "\n",
    "# DATA_MERGED = DATA[:-4] + '_merged.csv'\n",
    "# # write the merged data to file\n",
    "# df.to_csv(DATA_MERGED, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA3)\n",
    "\n",
    "# save df to csv, replace _merged.csv with _contextual.csv\n",
    "fn = '../data/ACCORD_BPBGClass_v2_contextual.csv'\n",
    "df.to_csv(fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10251/10251 [00:47<00:00, 215.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(visit_number) = 3595\n",
      "averge visit_number = 38.666203059805284\n",
      "len(count_s_a) = 144\n",
      "len(count_s_a_d) = 1131\n",
      "Finished counting by looping through the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#------------- calculate the empirical estimate of P based on entire dataset ----------------\n",
    "        \n",
    "count_s_a = {} # count the number of times state s and action a appear in the dataset, sparse format\n",
    "count_s_a_d = {} # count the number of times state s, action a, and next state s' appear in the dataset\n",
    "visit_number = [] # number of visits for each patient\n",
    "\n",
    "# loop through each patient in the dataset\n",
    "for i in tqdm(range(100001, 110252)):\n",
    "    df_patient = df[df['MaskID'] == i]\n",
    "\n",
    "    if len(df_patient) > 0:\n",
    "        visit_number.append(len(df_patient))\n",
    "\n",
    "    # loop through each visit of the patient\n",
    "    for j in range(len(df_patient)-1): # loop before last visit\n",
    "        row = df_patient.iloc[j]\n",
    "        s_code = row['state_code']\n",
    "        a_code = row['action_code']\n",
    "        ns_code = df_patient.iloc[j+1]['state_code']\n",
    "\n",
    "        # convert from code to index\n",
    "        s = state_code_to_index[s_code]\n",
    "        a = action_code_to_index[a_code]\n",
    "        s_ = state_code_to_index[ns_code]\n",
    "\n",
    "        if (s, a) not in count_s_a:\n",
    "            count_s_a[(s, a)] = 1\n",
    "        else:\n",
    "            count_s_a[(s, a)] += 1\n",
    "\n",
    "        if (s, a, s_) not in count_s_a_d:\n",
    "            count_s_a_d[(s, a, s_)] = 1\n",
    "        else:\n",
    "            count_s_a_d[(s, a, s_)] += 1\n",
    "\n",
    "print('len(visit_number) =', len(visit_number))\n",
    "print('averge visit_number =', sum(visit_number)/len(visit_number))\n",
    "\n",
    "print('len(count_s_a) =', len(count_s_a))\n",
    "print('len(count_s_a_d) =', len(count_s_a_d))\n",
    "print('Finished counting by looping through the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible state-action pairs = 144\n",
      "Seen state-action pairs = 144\n",
      "Unseen state-action pairs = 0\n",
      "Sparsity of state-action pairs = 0.0\n"
     ]
    }
   ],
   "source": [
    "# calculate the sparsity of state-action pairs\n",
    "print('Total possible state-action pairs =', N_STATES * N_ACTIONS)\n",
    "print('Seen state-action pairs =', len(count_s_a))\n",
    "print('Unseen state-action pairs =', N_STATES * N_ACTIONS - len(count_s_a))\n",
    "print('Sparsity of state-action pairs =', 1 - len(count_s_a)/(N_STATES * N_ACTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initializing P\n",
      "Finished calculating the empirical estimate of P\n",
      "\n",
      "Details of P, R, C:\n",
      "P: 87.268519% are non-zeros\n",
      "\n",
      "Sample values of P, R, C:\n",
      "P[0][0][0] = 0.8931297709923665\n"
     ]
    }
   ],
   "source": [
    "# initialize P, NOT using sparse matrix format\n",
    "P = {} # N_STATES * N_ACTIONS * N_STATES, dictionary of transition probability matrices, based on the entire dataset\n",
    "\n",
    "for s in range(N_STATES):\n",
    "    l = len(actions)\n",
    "\n",
    "    P[s] = {}    \n",
    "    for a in range(N_ACTIONS):\n",
    "        P[s][a] = np.zeros(N_STATES)\n",
    "        \n",
    "print('Finished initializing P')\n",
    "\n",
    "for (s, a, s_) in count_s_a_d:\n",
    "    P[s][a][s_] = count_s_a_d[(s, a, s_)]/max(count_s_a[(s, a)],1)\n",
    "\n",
    "print('Finished calculating the empirical estimate of P')\n",
    "\n",
    "#------------- check the sparsity of P, R, C\n",
    "print('\\nDetails of P, R, C:')\n",
    "print('P: {:.6f}% are non-zeros'.format(len(count_s_a_d)*100/(N_STATES*N_ACTIONS*N_STATES)))\n",
    "\n",
    "# print sample values of P, R, C\n",
    "print('\\nSample values of P, R, C:')\n",
    "print('P[0][0][0] =', P[0][0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Init states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(INIT_STATES_LIST) = 9\n",
      "df_blr.shape = (3595, 82)\n",
      "state_code\n",
      "22    1320\n",
      "12    1271\n",
      "11     327\n",
      "02     290\n",
      "21     285\n",
      "01      68\n",
      "10      17\n",
      "20      15\n",
      "00       2\n",
      "Name: state_code, dtype: int64\n",
      "\n",
      "most_freq_blr_state = 22\n",
      "INIT_STATE_INDEX = 8\n"
     ]
    }
   ],
   "source": [
    "def check_frequency(df, col_name):\n",
    "    print(col_name)\n",
    "    df = df[col_name]\n",
    "    df = df.value_counts()\n",
    "    print(df)\n",
    "    print()\n",
    "\n",
    "    # return the first index in the series\n",
    "    return df.index[0]\n",
    "    \n",
    "# get the rows when the visit=='BLR' in df\n",
    "df_blr = df[df['Visit']=='BLR']\n",
    "INIT_STATES_LIST = df_blr['state_code'].unique() # we will sample uniformly from this list\n",
    "print('len(INIT_STATES_LIST) =', len(INIT_STATES_LIST))\n",
    "\n",
    "print('df_blr.shape =', df_blr.shape)\n",
    "most_freq_blr_state = check_frequency(df_blr, 'state_code')\n",
    "print('most_freq_blr_state =', most_freq_blr_state)\n",
    "\n",
    "INIT_STATE_INDEX = state_code_to_index[most_freq_blr_state]\n",
    "print('INIT_STATE_INDEX =', INIT_STATE_INDEX)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check frequency of context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_fea = ['baseline_age', 'female', 'race_whiteother',\n",
    "                'edu_baseline_1',\n",
    "                'edu_baseline_2',\n",
    "                'edu_baseline_3',\n",
    "                'cvd_hx_baseline', \n",
    "                'baseline_BMI', \n",
    "                # 'baseline_BMI_discrete',\n",
    "                # 'cigarett_baseline',\n",
    "                'cigarett_baseline_1',\n",
    "               ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the CONTEXT_VECTOR_dict \n",
    "\n",
    "each key is the MaskID, value is the corresponding CONTEXT_VECTOR for the patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(mask_id_list) = 3595\n",
      "df_blr.shape = (3595, 82)\n",
      "len(CONTEXT_VECTOR_dict) = 3595\n"
     ]
    }
   ],
   "source": [
    "def get_context_vec(row, context_fea):\n",
    "    context_vec = np.zeros(len(context_fea))\n",
    "    for i in range(len(context_fea)):\n",
    "        context_vec[i] = row[context_fea[i]]\n",
    "    return context_vec \n",
    "\n",
    "# build the CONTEXT_VECTOR_dict, each key is the MaskID, value is the corresponding CONTEXT_VECTOR for the patient\n",
    "CONTEXT_VECTOR_dict = {}\n",
    "\n",
    "# get unique MaskID, 4366 patients\n",
    "mask_id_list = df['MaskID'].unique()\n",
    "print('len(mask_id_list) =', len(mask_id_list))\n",
    "\n",
    "# get the BLR visit only\n",
    "df_blr = df[df['Visit']=='BLR']\n",
    "print('df_blr.shape =', df_blr.shape)\n",
    "\n",
    "# loop through each row of df_blr\n",
    "for r in range(df_blr.shape[0]):\n",
    "    row = df_blr.iloc[r]\n",
    "    mask_id = row['MaskID']\n",
    "    # state_code = row['state_code']\n",
    "    context_vec = get_context_vec(row, context_fea)\n",
    "    CONTEXT_VECTOR_dict[mask_id] = context_vec\n",
    "\n",
    "print('len(CONTEXT_VECTOR_dict) =', len(CONTEXT_VECTOR_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139005, 82)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODE_LENGTH = 20 # average number of visits per patient\n",
    "# CONSTRAINT_list = [16, 10, 10] # deviation * 20 visits \n",
    "# C_b_list = [8, 5, 5]  # change this if you want different baseline policy.\n",
    "\n",
    "# CONSTRAINT_list = [166, 160, 160,\n",
    "#                    166, 160, 160,\n",
    "#                    166, 160, 160,]  \n",
    "\n",
    "CONSTRAINT_list = [210] * 9\n",
    "\n",
    "C_b_list = [50] * 9\n",
    "\n",
    "\n",
    "delta = 0.01 # bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT_VEC_LENGTH = 9\n",
      "ACTION_CODE_LENGTH = 4\n"
     ]
    }
   ],
   "source": [
    "# dump the model settings and parameters to a pickle file\n",
    "CONTEXT_VEC_LENGTH = len(context_fea)\n",
    "ACTION_CODE_LENGTH = len(action_index_to_code[0])\n",
    "print('CONTEXT_VEC_LENGTH =', CONTEXT_VEC_LENGTH)\n",
    "print('ACTION_CODE_LENGTH =', ACTION_CODE_LENGTH)\n",
    "\n",
    "with open('output/model_contextual_BPBG.pkl', 'wb') as f:\n",
    "    pickle.dump([P, CONTEXT_VEC_LENGTH, ACTION_CODE_LENGTH, CONTEXT_VECTOR_dict, INIT_STATE_INDEX, INIT_STATES_LIST, state_code_to_index, state_index_to_code, action_index_to_code,\n",
    "                CONSTRAINT_list, C_b_list, N_STATES, N_ACTIONS, ACTIONS_PER_STATE, EPISODE_LENGTH, delta], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c86494cdbaab790faf1630f8596bee794fd9c939f53713dc51278a7ffca15d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
