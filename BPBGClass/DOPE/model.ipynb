{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from UtilityMethods import utils\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import pulp as p\n",
    "import math\n",
    "from copy import copy\n",
    "import pprint as pp\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# IS_VISIT_DEPENDENT = False # whether the above empirical estimates are visit-dependent or not\n",
    "DATA = '../data/ACCORD_BPBGClass_v2.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State space and action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(states) = 4\n",
      "['00', '01', '10', '11']\n",
      "00 0\n",
      "01 1\n",
      "10 2\n",
      "11 3\n",
      "\n",
      "len(actions) = 16\n",
      "0000 0\n",
      "0001 1\n",
      "0010 2\n",
      "0011 3\n",
      "0100 4\n",
      "Actions for State 0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# state space, actions available in each state are always the same\n",
    "\n",
    "\"\"\"\n",
    "# original fine-grained levels\n",
    "state_features = ['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete','BMI_discrete'] \n",
    "sbp_level = ['0', '1', '2', '3'] # possible values for sbp_discrete\n",
    "hba1c_level = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "TC_level = ['0', '1', '2', '3']\n",
    "hdl_level = ['0', '1', '2', '3']\n",
    "BMI_level = ['0', '1', '2', '3']\n",
    "\"\"\"\n",
    "\n",
    "# here we merge levels\n",
    "# sbp_level = ['0', '1', '2'] # sbp_discrete, 0: 0, 1:1, 2+3: 2\n",
    "# hba1c_level = ['0', '1', '2'] # hba1c_discrete, 0+1: 0, 2+3: 1, 4+5+6+7: 2\n",
    "\n",
    "sbp_level = ['0', '1', ] # sbp_discrete, 0: 0, 1:1, 2+3: 2\n",
    "hba1c_level = ['0', '1'] # hba1c_discrete, 0+1: 0, 2+3: 1, 4+5+6+7: 2\n",
    "\n",
    "TC_level = ['0', '1'] # TC_discrete, 0+1: 0, 2+3: 1\n",
    "hdl_level = ['0', '1'] # hdl_discrete, 0+1: 0, 2+3: 1\n",
    "\n",
    "# sbp_discrete_code_dict = {'0': '0', '1': '1',\n",
    "#                           '2': '2', '3': '2',}\n",
    "\n",
    "sbp_discrete_code_dict = {'0': '0', '1': '0',\n",
    "                          '2': '1', '3': '1',}\n",
    "\n",
    "# hba1c_discrete_code_dict = {'0': '0', '1': '0', \n",
    "#                             '2': '1', '3': '1', \n",
    "#                             '4': '2', '5': '2', \n",
    "#                             '6': '2', '7': '2'}\n",
    "\n",
    "hba1c_discrete_code_dict = {'0': '0', '1': '0', \n",
    "                            '2': '0', '3': '0', \n",
    "                            '4': '1', '5': '1', \n",
    "                            '6': '1', '7': '1'}\n",
    "\n",
    "TC_discrete_code_dict = {'0': '0', '1': '0',\n",
    "                         '2': '1', '3': '1'}\n",
    "\n",
    "hdl_discrete_code_dict = {'0': '0', '1': '0',\n",
    "                          '2': '1', '3': '1'}\n",
    "\n",
    "# 4 features, state space = 36\n",
    "# state_features = ['sbp_discrete', 'hba1c_discrete', 'TC_discrete', 'hdl_discrete'] \n",
    "# combinations = itertools.product(sbp_level, hba1c_level, TC_level, hdl_level)\n",
    "\n",
    "# 3 features, state space = 18\n",
    "# state_features = ['sbp_discrete', 'hba1c_discrete', 'TC_discrete'] \n",
    "# combinations = itertools.product(sbp_level, hba1c_level, TC_level)\n",
    "\n",
    "# 2 features, state space = 9\n",
    "combinations = itertools.product(sbp_level, hba1c_level)\n",
    "state_features = ['sbp_discrete', 'hba1c_discrete'] \n",
    "\n",
    "# 1 feature, srtate space = 3\n",
    "# combinations = itertools.product(hba1c_level)\n",
    "# state_features = ['hba1c_discrete'] \n",
    "\n",
    "states = [''.join(i) for i in combinations]\n",
    "print('len(states) =', len(states))\n",
    "print(states[:5])\n",
    "\n",
    "N_STATES = len(states) \n",
    "state_code_to_index = {code: i for i, code in enumerate(states)}\n",
    "state_index_to_code = {i: code for i, code in enumerate(states)}\n",
    "for i in range(N_STATES):\n",
    "    print(states[i], state_code_to_index[states[i]])\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# action space, 000000000 means bgclass_none, 111111111 means all bgmed class are precribed\n",
    "# we donot include 'bgclass_none' as a action, because 000000000 means bgclass_none\n",
    "# action_features = ['Diur', 'ACE', 'Beta-blocker', 'CCB', \n",
    "#                     'Bingu', 'Thiaz', 'Sulfon', 'Meglit'] # pick the top 4 most frequently prescribed BP and BG Med class \n",
    "                    \n",
    "# action_features = ['Diur', 'ACE', 'Beta-blocker',  \n",
    "#                     'Bingu', 'Thiaz', 'Sulfon', ] # pick the top 3 most frequently prescribed BP and BG Med class \n",
    "\n",
    "action_features = ['Diur', 'ACE',   \n",
    "                    'Bingu', 'Thiaz', ] # pick the top 2 most frequently prescribed BP and BG Med class \n",
    "                    \n",
    "\n",
    "combinations = list(itertools.product('01', repeat=len(action_features)))\n",
    "actions = [''.join(i) for i in combinations]\n",
    "print('len(actions) =', len(actions))\n",
    "N_ACTIONS = len(actions) # number of actions = 512\n",
    "action_code_to_index = {code: i for i, code in enumerate(actions)}\n",
    "# print the first 5 action_code_to_index\n",
    "for i in range(5):\n",
    "    print(actions[i], action_code_to_index[actions[i]])\n",
    "\n",
    "# build the action space for each state, assign the same action space to all states\n",
    "ACTIONS_PER_STATE = {}\n",
    "for s in range(N_STATES):\n",
    "    ACTIONS_PER_STATE[s] = [i for i in range(N_ACTIONS)] # this is the action code index\n",
    "print('Actions for State 0:', ACTIONS_PER_STATE[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate empirical estimates of P, R, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139005, 74)\n",
      "len(patients_set) = 3595\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "patients_set = set(df['MaskID'].unique())\n",
    "print('len(patients_set) =', len(patients_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding action_code and state_code columns\n"
     ]
    }
   ],
   "source": [
    "# add the state and action code columns\n",
    "action_code = []\n",
    "state_code = []\n",
    "hba1c_discrete_merged = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    s_code = ''\n",
    "    a_code = ''\n",
    "    for state_fea in state_features:\n",
    "        code = str(row[state_fea])\n",
    "\n",
    "        if state_fea == 'sbp_discrete':\n",
    "            code = sbp_discrete_code_dict[code]            \n",
    "        elif state_fea == 'hba1c_discrete':\n",
    "            code = hba1c_discrete_code_dict[code]\n",
    "            hba1c_discrete_merged.append(code)\n",
    "        elif state_fea == 'TC_discrete':\n",
    "            code = TC_discrete_code_dict[code]\n",
    "        elif state_fea == 'hdl_discrete':\n",
    "            code = hdl_discrete_code_dict[code]\n",
    "        else:\n",
    "            raise ValueError('state_fea not recognized')\n",
    "            exit(1)       \n",
    "        \n",
    "        s_code += code\n",
    "    \n",
    "    for action_fea in action_features:\n",
    "        a_code += str(row[action_fea])\n",
    "    \n",
    "    action_code.append(a_code)\n",
    "    state_code.append(s_code)\n",
    "\n",
    "assert len(hba1c_discrete_merged) == len(df)\n",
    "\n",
    "df['hba1c_discrete_merged'] = hba1c_discrete_merged\n",
    "df['action_code'] = action_code\n",
    "df['state_code'] = state_code\n",
    "print('Finished adding action_code and state_code columns')\n",
    "\n",
    "DATA_MERGED = DATA[:-4] + '_merged.csv'\n",
    "# write the merged data to file\n",
    "df.to_csv(DATA_MERGED, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10251/10251 [01:31<00:00, 111.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(visit_number) = 3595\n",
      "averge visit_number = 38.666203059805284\n",
      "len(count_s_a) = 64\n",
      "len(count_s_a_d) = 256\n",
      "Finished counting by looping through the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#------------- calculate the empirical estimate of P, R, C based on entire dataset ----------------\n",
    "        \n",
    "count_s_a = {} # count the number of times state s and action a appear in the dataset, sparse format\n",
    "count_s_a_d = {} # count the number of times state s, action a, and next state s' appear in the dataset\n",
    "sum_r_s_a = {} # sum of the reward of state s and action a\n",
    "sum_c1_s_a = {} # sum of the cost of state s and action a, this is the absolute value of SBP feedback\n",
    "sum_c2_s_a = {} # sum of the cost of state s and action a, this is the absolute value of hba1c feedback\n",
    "visit_number = [] # number of visits for each patient\n",
    "\n",
    "# loop through each patient in the dataset\n",
    "for i in tqdm(range(100001, 110252)):\n",
    "    df_patient = df[df['MaskID'] == i]\n",
    "\n",
    "    if len(df_patient) > 0:\n",
    "        visit_number.append(len(df_patient))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # loop through each visit of the patient\n",
    "    for j in range(len(df_patient)-1): # loop before last visit\n",
    "        row = df_patient.iloc[j]\n",
    "        s_code = row['state_code']\n",
    "        a_code = row['action_code']\n",
    "        ns_code = df_patient.iloc[j+1]['state_code']\n",
    "\n",
    "        # convert from code to index\n",
    "        s = state_code_to_index[s_code]\n",
    "        a = action_code_to_index[a_code]\n",
    "        s_ = state_code_to_index[ns_code]\n",
    "\n",
    "        r = df_patient.iloc[j]['CVDRisk_feedback']\n",
    "        hba1c_fb = df_patient.iloc[j]['hba1c_feedback']\n",
    "        sbp_fb = df_patient.iloc[j]['sbp_feedback']\n",
    "        c1 = sbp_fb\n",
    "        c2 = hba1c_fb\n",
    "\n",
    "        if (s, a) not in count_s_a:\n",
    "            count_s_a[(s, a)] = 1\n",
    "            sum_r_s_a[(s, a)] = r \n",
    "            sum_c1_s_a[(s, a)] = c1\n",
    "            sum_c2_s_a[(s, a)] = c2\n",
    "        else:\n",
    "            count_s_a[(s, a)] += 1\n",
    "            sum_r_s_a[(s, a)] += r\n",
    "            sum_c1_s_a[(s, a)] += c1\n",
    "            sum_c2_s_a[(s, a)] += c2\n",
    "\n",
    "        if (s, a, s_) not in count_s_a_d:\n",
    "            count_s_a_d[(s, a, s_)] = 1\n",
    "        else:\n",
    "            count_s_a_d[(s, a, s_)] += 1\n",
    "\n",
    "print('len(visit_number) =', len(visit_number))\n",
    "print('averge visit_number =', sum(visit_number)/len(visit_number))\n",
    "\n",
    "print('len(count_s_a) =', len(count_s_a))\n",
    "print('len(count_s_a_d) =', len(count_s_a_d))\n",
    "print('Finished counting by looping through the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible state-action pairs = 64\n",
      "Seen state-action pairs = 64\n",
      "Unseen state-action pairs = 0\n",
      "Sparsity of state-action pairs = 0.0\n"
     ]
    }
   ],
   "source": [
    "# calculate the sparsity of state-action pairs\n",
    "print('Total possible state-action pairs =', N_STATES * N_ACTIONS)\n",
    "print('Seen state-action pairs =', len(count_s_a))\n",
    "print('Unseen state-action pairs =', N_STATES * N_ACTIONS - len(count_s_a))\n",
    "print('Sparsity of state-action pairs =', 1 - len(count_s_a)/(N_STATES * N_ACTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initializing R, C, P\n",
      "Finished calculating the empirical estimate of P, R, C\n",
      "\n",
      "Details of P, R, C:\n",
      "P: 100.000000% are non-zeros\n",
      "R: 100.000000% are non-zeros\n",
      "C1: 100.000000% are non-zeros\n",
      "C2: 100.000000% are non-zeros\n",
      "\n",
      "Sample values of P, R, C:\n",
      "P[0][0][0] = 0.9473557499398122\n",
      "R[0][0] = 0.21955534155996564\n",
      "C1[0][0] = 122.56592568814702\n",
      "C2[0][0] = 6.5586670411685395\n",
      "\n",
      "Statistics of R and C:\n",
      "R: min = 0.195295, max = 0.351946, mean = 0.256444, median = 0.255423, std = 0.045990\n",
      "C1: min = 118.544858, max = 151.597127, mean = 132.507139, median = 131.618390, std = 9.961479\n",
      "C2: min = 6.380569, max = 8.585431, mean = 7.467460, median = 7.500988, std = 0.793282\n"
     ]
    }
   ],
   "source": [
    "# calculate the empirical estimate of P, R, C using counts\n",
    "\n",
    "# initialize R, C, P, NOT using sparse matrix format\n",
    "R = {} # N_STATES * N_ACTIONS, dictionary of reward matrices, this is the CVDRisk empirical estimate based on entire dataset\n",
    "C1 = {} # N_STATES * N_ACTIONS, dictionary of cost matrices, this is SBP empirical estimate based on entire dataset\n",
    "C2 = {} # N_STATES * N_ACTIONS, dictionary of cost matrices, this is hba1c empirical estimate based on entire dataset\n",
    "P = {} # N_STATES * N_ACTIONS * N_STATES, dictionary of transition probability matrices, based on the entire dataset\n",
    "\n",
    "for s in range(N_STATES):\n",
    "    l = len(actions)\n",
    "    R[s] = np.zeros(l)\n",
    "    C1[s] = np.zeros(l)\n",
    "    C2[s] = np.zeros(l)\n",
    "    P[s] = {}    \n",
    "    for a in range(N_ACTIONS):\n",
    "        P[s][a] = np.zeros(N_STATES)\n",
    "        \n",
    "print('Finished initializing R, C, P')\n",
    "\n",
    "for (s,a) in count_s_a: # only calculate for the states and actions that appearedin the dataset, for efficiency\n",
    "\n",
    "    R[s][a] = sum_r_s_a[(s, a)]/max(count_s_a[(s, a)],1)\n",
    "    C1[s][a] = sum_c1_s_a[(s, a)]/max(count_s_a[(s, a)],1)\n",
    "    C2[s][a] = sum_c2_s_a[(s, a)]/max(count_s_a[(s, a)],1)\n",
    "\n",
    "for (s, a, s_) in count_s_a_d:\n",
    "    P[s][a][s_] = count_s_a_d[(s, a, s_)]/max(count_s_a[(s, a)],1)\n",
    "\n",
    "print('Finished calculating the empirical estimate of P, R, C')\n",
    "\n",
    "#------------- check the sparsity of P, R, C\n",
    "print('\\nDetails of P, R, C:')\n",
    "print('P: {:.6f}% are non-zeros'.format(len(count_s_a_d)*100/(N_STATES*N_ACTIONS*N_STATES)))\n",
    "print('R: {:.6f}% are non-zeros'.format(len(sum_r_s_a)*100/(N_STATES*N_ACTIONS)))\n",
    "print('C1: {:.6f}% are non-zeros'.format(len(sum_c1_s_a)*100/(N_STATES*N_ACTIONS)))\n",
    "print('C2: {:.6f}% are non-zeros'.format(len(sum_c2_s_a)*100/(N_STATES*N_ACTIONS)))\n",
    "\n",
    "# print sample values of P, R, C\n",
    "print('\\nSample values of P, R, C:')\n",
    "print('P[0][0][0] =', P[0][0][0])\n",
    "print('R[0][0] =', R[0][0])\n",
    "print('C1[0][0] =', C1[0][0])\n",
    "print('C2[0][0] =', C2[0][0])\n",
    "\n",
    "# print the min, max, mean, median of R and C, R and C are dictionaries of numpy arrays\n",
    "print('\\nStatistics of R and C:')\n",
    "print('R: min = {:.6f}, max = {:.6f}, mean = {:.6f}, median = {:.6f}, std = {:.6f}'.format(np.min(list(R.values())), np.max(list(R.values())), np.mean(list(R.values())), np.median(list(R.values())), np.std(list(R.values()))))\n",
    "print('C1: min = {:.6f}, max = {:.6f}, mean = {:.6f}, median = {:.6f}, std = {:.6f}'.format(np.min(list(C1.values())), np.max(list(C1.values())), np.mean(list(C1.values())), np.median(list(C1.values())), np.std(list(C1.values()))))\n",
    "print('C2: min = {:.6f}, max = {:.6f}, mean = {:.6f}, median = {:.6f}, std = {:.6f}'.format(np.min(list(C2.values())), np.max(list(C2.values())), np.mean(list(C2.values())), np.median(list(C2.values())), np.std(list(C2.values()))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Init states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(INIT_STATES_LIST) = 4\n",
      "df_blr.shape = (3595, 77)\n",
      "01    1561\n",
      "11    1320\n",
      "00     414\n",
      "10     300\n",
      "Name: state_code, dtype: int64\n",
      "\n",
      "most_freq_blr_state = 01\n",
      "INIT_STATE_INDEX = 1\n"
     ]
    }
   ],
   "source": [
    "def check_frequency(df, col_name):\n",
    "    df = df[col_name]\n",
    "    df = df.value_counts()\n",
    "    print(df)\n",
    "    print()\n",
    "\n",
    "    # return the first index in the series\n",
    "    return df.index[0]\n",
    "    \n",
    "# get the rows when the visit=='BLR' in df\n",
    "df_blr = df[df['Visit']=='BLR']\n",
    "INIT_STATES_LIST = df_blr['state_code'].unique() # we will sample uniformly from this list\n",
    "print('len(INIT_STATES_LIST) =', len(INIT_STATES_LIST))\n",
    "\n",
    "print('df_blr.shape =', df_blr.shape)\n",
    "most_freq_blr_state = check_frequency(df_blr, 'state_code')\n",
    "print('most_freq_blr_state =', most_freq_blr_state)\n",
    "INIT_STATE_INDEX = state_code_to_index[most_freq_blr_state]\n",
    "print('INIT_STATE_INDEX =', INIT_STATE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00    77239\n",
      "01    36697\n",
      "10    14845\n",
      "11    10224\n",
      "Name: state_code, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_freq_state = check_frequency(df, 'state_code')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute solution.pkl and baseline.pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_code_to_index = {'00': 0, '01': 1, '10': 2, '11': 3}\n",
      "state_index_to_code = {0: '00', 1: '01', 2: '10', 3: '11'}\n"
     ]
    }
   ],
   "source": [
    "print('state_code_to_index =', state_code_to_index)\n",
    "print('state_index_to_code =', state_index_to_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSTRAINT1_list = [100, 100, 100, 100]\n",
      "C1_b_list = [40, 40, 40, 40]\n",
      "CONSTRAINT2_list = [16, 16, 16, 16]\n",
      "C2_b_list = [8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "EPISODE_LENGTH = 20 # average number of visits per patient\n",
    "\n",
    "CONSTRAINT1_list = [100] * N_STATES # deviation * 20 visits\n",
    "C1_b_list = [40] * N_STATES # constraint for baseline policy\n",
    "\n",
    "# CONSTRAINT2_list = [16, 10, 10] * 3 # deviation * 20 visits \n",
    "# C2_b_list = [8, 5, 5] * 3  # constraint for baseline policy\n",
    "\n",
    "CONSTRAINT2_list = [16] * N_STATES # deviation * 20 visits \n",
    "C2_b_list = [8] * N_STATES  # constraint for baseline policy\n",
    "\n",
    "delta = 0.01 # bound\n",
    "\n",
    "EPS = 0.01 # not used\n",
    "M = 0 # not used\n",
    "\n",
    "print('CONSTRAINT1_list =', CONSTRAINT1_list)\n",
    "print('C1_b_list =', C1_b_list)\n",
    "print('CONSTRAINT2_list =', CONSTRAINT2_list)\n",
    "print('C2_b_list =', C2_b_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model settings and parameters to a pickle file\n",
    "with open('output/model.pkl', 'wb') as f:\n",
    "    pickle.dump([P, R, C1, C2, INIT_STATE_INDEX, INIT_STATES_LIST, state_code_to_index,\n",
    "                CONSTRAINT1_list, C1_b_list, CONSTRAINT2_list, C2_b_list, N_STATES, N_ACTIONS, ACTIONS_PER_STATE, EPISODE_LENGTH, delta], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy:\n",
      "\n",
      "state_idx = 0\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.0949047878067235\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.0949047878067235\n",
      "cost1 of policy = 23.869942506200008\n",
      "cost2 of policy = 8.34493858178205\n",
      "opt_value_LP_con[INIT_STATE_INDEX, 0] = 4.0949047884010055\n",
      "opt_cost1_LP_con[INIT_STATE_INDEX, 0] = 23.869942485841474\n",
      "opt_cost2_LP_con[INIT_STATE_INDEX, 0] = 8.344938586684478\n",
      "\n",
      "state_idx = 1\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.09253400981072\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.09253400981072\n",
      "cost1 of policy = 29.062001631432853\n",
      "cost2 of policy = 7.014366066960507\n",
      "opt_value_LP_con[INIT_STATE_INDEX, 0] = 4.092534011685285\n",
      "opt_cost1_LP_con[INIT_STATE_INDEX, 0] = 29.062001617081314\n",
      "opt_cost2_LP_con[INIT_STATE_INDEX, 0] = 7.014366067079475\n",
      "\n",
      "state_idx = 2\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.215612417976746\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.215612417976746\n",
      "cost1 of policy = 48.99897436370466\n",
      "cost2 of policy = 7.424264519577009\n",
      "opt_value_LP_con[INIT_STATE_INDEX, 0] = 4.215612423607358\n",
      "opt_cost1_LP_con[INIT_STATE_INDEX, 0] = 48.99897434295835\n",
      "opt_cost2_LP_con[INIT_STATE_INDEX, 0] = 7.424264529909219\n",
      "\n",
      "state_idx = 3\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.19492505050475\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.19492505050475\n",
      "cost1 of policy = 51.75389312433943\n",
      "cost2 of policy = 7.138637432140999\n",
      "opt_value_LP_con[INIT_STATE_INDEX, 0] = 4.194925045482098\n",
      "opt_cost1_LP_con[INIT_STATE_INDEX, 0] = 51.75389297925122\n",
      "opt_cost2_LP_con[INIT_STATE_INDEX, 0] = 7.138637422228831\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['UtilityMethods'])\n",
    "from UtilityMethods import utils\n",
    "\n",
    "opt_policy_con_list = []\n",
    "opt_value_LP_con_list = []\n",
    "opt_cost1_LP_con_list = []\n",
    "opt_cost2_LP_con_list = []\n",
    "opt_q_con_list = []\n",
    "\n",
    "print('Optimal policy:')\n",
    "for state_idx in range(N_STATES):\n",
    "    print('\\nstate_idx =', state_idx)\n",
    "    INIT_STATE_INDEX = state_idx\n",
    "    CONSTRAINT1 = CONSTRAINT1_list[INIT_STATE_INDEX]\n",
    "    CONSTRAINT2 = CONSTRAINT2_list[INIT_STATE_INDEX]\n",
    "    C1_b = C1_b_list[INIT_STATE_INDEX]\n",
    "    C2_b = C2_b_list[INIT_STATE_INDEX]\n",
    "\n",
    "    print('CONSTRAINT1 =', CONSTRAINT1)\n",
    "    print('CONSTRAINT2 =', CONSTRAINT2)\n",
    "    print('C1_b =', C1_b)\n",
    "    print('C2_b =', C2_b)\n",
    "\n",
    "    util_methods_1 = utils(EPS, delta, M, P, R, C1, C2, INIT_STATE_INDEX, EPISODE_LENGTH, N_STATES, N_ACTIONS, ACTIONS_PER_STATE, CONSTRAINT1, C1_b, CONSTRAINT2, C2_b)\n",
    "\n",
    "    # constrained MDP, solve the optimal policy using LP\n",
    "    opt_policy_con, opt_value_LP_con, opt_cost1_LP_con, opt_cost2_LP_con, opt_q_con, flag = util_methods_1.compute_opt_LP_Constrained(0)\n",
    "\n",
    "    if flag != 'Optimal':\n",
    "        raise ValueError('LP not solved to optimality')\n",
    "        \n",
    "\n",
    "    # unconstrained = standard MDP, not used in DOPE\n",
    "    # opt_policy_uncon, opt_value_LP_uncon, opt_cost_LP_uncon, opt_q_uncon = util_methods_1.compute_opt_LP_Unconstrained(0) \n",
    "\n",
    "    opt_policy_con_list.append(opt_policy_con)\n",
    "    opt_value_LP_con_list.append(opt_value_LP_con)\n",
    "    opt_cost1_LP_con_list.append(opt_cost1_LP_con)\n",
    "    opt_cost2_LP_con_list.append(opt_cost2_LP_con)\n",
    "    opt_q_con_list.append(opt_q_con)\n",
    "\n",
    "    print(\"opt_value_LP_con[INIT_STATE_INDEX, 0] =\",opt_value_LP_con[INIT_STATE_INDEX, 0])\n",
    "    print(\"opt_cost1_LP_con[INIT_STATE_INDEX, 0] =\",opt_cost1_LP_con[INIT_STATE_INDEX, 0])\n",
    "    print(\"opt_cost2_LP_con[INIT_STATE_INDEX, 0] =\",opt_cost2_LP_con[INIT_STATE_INDEX, 0])\n",
    "    \n",
    "\n",
    "with open('output/solution.pkl', 'wb') as f:\n",
    "    pickle.dump([opt_policy_con_list, opt_value_LP_con_list, opt_cost1_LP_con_list,  opt_cost2_LP_con_list, opt_q_con_list], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the baseline policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline policy:\n",
      "\n",
      "state_idx = 0\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.097421393259504\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.097421393259504\n",
      "cost1 of policy = 24.16660403568475\n",
      "cost2 of policy = 7.999999990383125\n",
      "value_b[INIT_STATE_INDEX, 0] = 4.09742139800955\n",
      "cost1_b[INIT_STATE_INDEX, 0] = 24.166604017293324\n",
      "cost2_b[INIT_STATE_INDEX, 0] = 7.999999999818228\n",
      "\n",
      "state_idx = 1\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.09253400981072\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.09253400981072\n",
      "cost1 of policy = 29.062001631432853\n",
      "cost2 of policy = 7.014366066960507\n",
      "value_b[INIT_STATE_INDEX, 0] = 4.092534011685285\n",
      "cost1_b[INIT_STATE_INDEX, 0] = 29.062001617081314\n",
      "cost2_b[INIT_STATE_INDEX, 0] = 7.014366067079475\n",
      "\n",
      "state_idx = 2\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.218559732036442\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.218559732036442\n",
      "cost1 of policy = 40.000000028727165\n",
      "cost2 of policy = 7.537688514553506\n",
      "value_b[INIT_STATE_INDEX, 0] = 4.218559727888791\n",
      "cost1_b[INIT_STATE_INDEX, 0] = 39.999999999665434\n",
      "cost2_b[INIT_STATE_INDEX, 0] = 7.5376885110367615\n",
      "\n",
      "state_idx = 3\n",
      "CONSTRAINT1 = 100\n",
      "CONSTRAINT2 = 16\n",
      "C1_b = 40\n",
      "C2_b = 8\n",
      "\n",
      "Computing optimal policy with constrained LP solver ...\n",
      "+++++ Optimal\n",
      "printing best value constrained: 4.210216673166702\n",
      "\n",
      "value from the conLPsolver:\n",
      "value of policy = 4.210216673166702\n",
      "cost1 of policy = 40.00000002282361\n",
      "cost2 of policy = 7.681584087897843\n",
      "value_b[INIT_STATE_INDEX, 0] = 4.210216672282769\n",
      "cost1_b[INIT_STATE_INDEX, 0] = 40.00000001048505\n",
      "cost2_b[INIT_STATE_INDEX, 0] = 7.681584084909959\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['UtilityMethods'])\n",
    "from UtilityMethods import utils\n",
    "\n",
    "\n",
    "# baseline policy\n",
    "print(\"Baseline policy:\")\n",
    "\n",
    "policy_b_list = []\n",
    "value_b_list = []\n",
    "cost1_b_list = []\n",
    "cost2_b_list = []\n",
    "q_b_list = []\n",
    "\n",
    "for state_idx in range(N_STATES):\n",
    "    print('\\nstate_idx =', state_idx)\n",
    "    INIT_STATE_INDEX = state_idx\n",
    "    CONSTRAINT1 = CONSTRAINT1_list[INIT_STATE_INDEX]\n",
    "    CONSTRAINT2 = CONSTRAINT2_list[INIT_STATE_INDEX]\n",
    "    C1_b = C1_b_list[INIT_STATE_INDEX]\n",
    "    C2_b = C2_b_list[INIT_STATE_INDEX]\n",
    "\n",
    "    print('CONSTRAINT1 =', CONSTRAINT1)\n",
    "    print('CONSTRAINT2 =', CONSTRAINT2)\n",
    "    print('C1_b =', C1_b)\n",
    "    print('C2_b =', C2_b)  \n",
    "\n",
    "    util_methods_1 = utils(EPS, delta, M, P, R, C1, C2, INIT_STATE_INDEX, EPISODE_LENGTH, N_STATES, N_ACTIONS, ACTIONS_PER_STATE, C1_b, C1_b, C2_b, C2_b)\n",
    "    policy_b, value_b, cost1_b, cost2_b, q_b, flag = util_methods_1.compute_opt_LP_Constrained(0)\n",
    "\n",
    "    if flag != 'Optimal':\n",
    "        raise ValueError('LP not solved to optimality')\n",
    "\n",
    "    policy_b_list.append(policy_b)\n",
    "    value_b_list.append(value_b)\n",
    "    cost1_b_list.append(cost1_b)\n",
    "    cost2_b_list.append(cost2_b)\n",
    "    q_b_list.append(q_b)\n",
    "\n",
    "    print(\"value_b[INIT_STATE_INDEX, 0] =\",value_b[INIT_STATE_INDEX, 0])\n",
    "    print(\"cost1_b[INIT_STATE_INDEX, 0] =\",cost1_b[INIT_STATE_INDEX, 0])\n",
    "    print(\"cost2_b[INIT_STATE_INDEX, 0] =\",cost2_b[INIT_STATE_INDEX, 0])\n",
    "\n",
    "with open('output/base.pkl', 'wb') as f:\n",
    "    pickle.dump([policy_b_list, value_b_list, cost1_b_list, cost2_b_list, q_b_list], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------STOP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode calculated optimal and baseline policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0, timestep 0, action_code 0000, prob 0.0625: BPBGClass_none\n",
      "state 0, timestep 0, action_code 0001, prob 0.0625: Thiaz\n",
      "state 0, timestep 0, action_code 0010, prob 0.0625: Bingu\n",
      "state 0, timestep 0, action_code 0011, prob 0.0625: Bingu+Thiaz\n",
      "state 0, timestep 0, action_code 0100, prob 0.0625: ACE\n",
      "state 0, timestep 0, action_code 0101, prob 0.0625: ACE+Thiaz\n",
      "state 0, timestep 0, action_code 0110, prob 0.0625: ACE+Bingu\n",
      "state 0, timestep 0, action_code 0111, prob 0.0625: ACE+Bingu+Thiaz\n",
      "state 0, timestep 0, action_code 1000, prob 0.0625: Diur\n",
      "state 0, timestep 0, action_code 1001, prob 0.0625: Diur+Thiaz\n",
      "state 0, timestep 0, action_code 1010, prob 0.0625: Diur+Bingu\n",
      "state 0, timestep 0, action_code 1011, prob 0.0625: Diur+Bingu+Thiaz\n",
      "state 0, timestep 0, action_code 1100, prob 0.0625: Diur+ACE\n",
      "state 0, timestep 0, action_code 1101, prob 0.0625: Diur+ACE+Thiaz\n",
      "state 0, timestep 0, action_code 1110, prob 0.0625: Diur+ACE+Bingu\n",
      "state 0, timestep 0, action_code 1111, prob 0.0625: Diur+ACE+Bingu+Thiaz\n",
      "state 0, timestep 1, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 2, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 3, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 4, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 5, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 6, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 7, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 8, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 9, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 10, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 11, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 12, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 13, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 14, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 15, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 16, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 17, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 18, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 19, action_code 1111, prob 1.0: Diur+ACE+Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 0000, prob 0.0625: BPBGClass_none\n",
      "state 1, timestep 0, action_code 0001, prob 0.0625: Thiaz\n",
      "state 1, timestep 0, action_code 0010, prob 0.0625: Bingu\n",
      "state 1, timestep 0, action_code 0011, prob 0.0625: Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 0100, prob 0.0625: ACE\n",
      "state 1, timestep 0, action_code 0101, prob 0.0625: ACE+Thiaz\n",
      "state 1, timestep 0, action_code 0110, prob 0.0625: ACE+Bingu\n",
      "state 1, timestep 0, action_code 0111, prob 0.0625: ACE+Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 1000, prob 0.0625: Diur\n",
      "state 1, timestep 0, action_code 1001, prob 0.0625: Diur+Thiaz\n",
      "state 1, timestep 0, action_code 1010, prob 0.0625: Diur+Bingu\n",
      "state 1, timestep 0, action_code 1011, prob 0.0625: Diur+Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 1100, prob 0.0625: Diur+ACE\n",
      "state 1, timestep 0, action_code 1101, prob 0.0625: Diur+ACE+Thiaz\n",
      "state 1, timestep 0, action_code 1110, prob 0.0625: Diur+ACE+Bingu\n",
      "state 1, timestep 0, action_code 1111, prob 0.0625: Diur+ACE+Bingu+Thiaz\n",
      "state 1, timestep 1, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 2, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 3, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 4, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 5, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 6, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 7, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 8, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 9, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 10, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 11, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 12, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 13, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 14, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 15, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 16, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 17, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 18, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 19, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 0000, prob 0.0625: BPBGClass_none\n",
      "state 2, timestep 0, action_code 0001, prob 0.0625: Thiaz\n",
      "state 2, timestep 0, action_code 0010, prob 0.0625: Bingu\n",
      "state 2, timestep 0, action_code 0011, prob 0.0625: Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 0100, prob 0.0625: ACE\n",
      "state 2, timestep 0, action_code 0101, prob 0.0625: ACE+Thiaz\n",
      "state 2, timestep 0, action_code 0110, prob 0.0625: ACE+Bingu\n",
      "state 2, timestep 0, action_code 0111, prob 0.0625: ACE+Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 1000, prob 0.0625: Diur\n",
      "state 2, timestep 0, action_code 1001, prob 0.0625: Diur+Thiaz\n",
      "state 2, timestep 0, action_code 1010, prob 0.0625: Diur+Bingu\n",
      "state 2, timestep 0, action_code 1011, prob 0.0625: Diur+Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 1100, prob 0.0625: Diur+ACE\n",
      "state 2, timestep 0, action_code 1101, prob 0.0625: Diur+ACE+Thiaz\n",
      "state 2, timestep 0, action_code 1110, prob 0.0625: Diur+ACE+Bingu\n",
      "state 2, timestep 0, action_code 1111, prob 0.0625: Diur+ACE+Bingu+Thiaz\n",
      "state 2, timestep 1, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 2, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 3, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 4, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 5, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 6, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 7, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 8, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 9, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 10, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 11, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 12, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 13, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 14, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 15, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 16, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 17, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 18, action_code 0110, prob 1.0: ACE+Bingu\n",
      "state 2, timestep 19, action_code 0111, prob 1.0: ACE+Bingu+Thiaz\n",
      "state 3, timestep 0, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 1, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 2, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 3, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 4, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 5, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 6, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 7, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 8, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 9, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 10, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 11, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 12, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 13, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 14, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 15, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 16, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 17, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 18, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 19, action_code 1110, prob 1.0: Diur+ACE+Bingu\n"
     ]
    }
   ],
   "source": [
    "# decode the opt_policy_con [s, h, a]\n",
    "\n",
    "def action_code_to_med_action(action_code):\n",
    "    med_action = []\n",
    "    for i in range(len(action_code)):\n",
    "        if action_code[i] == '0':\n",
    "            continue\n",
    "        elif action_code[i] == '1':\n",
    "            med_action.append(action_features[i])\n",
    "    \n",
    "    if len(med_action) == 0:\n",
    "        return 'BPBGClass_none'\n",
    "    else:\n",
    "        return '+'.join(med_action)\n",
    "\n",
    "for s in range(N_STATES):\n",
    "    for h in range(EPISODE_LENGTH):\n",
    "        for a in range(N_ACTIONS):\n",
    "            if opt_policy_con[s, h, a] != 0:\n",
    "                action_code = actions[a]\n",
    "                med_action = action_code_to_med_action(action_code)\n",
    "                # print('opt_policy_con[', s, ',', h, ',', a, '] =', opt_policy_con[s, h, a], ', action_code =', actions[a])\n",
    "                print('state {}, timestep {}, action_code {}, prob {}: {}'.format(s, h, action_code, opt_policy_con[s, h, a], med_action))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0, timestep 0, action_code 0000, prob 0.0625: BPBGClass_none\n",
      "state 0, timestep 0, action_code 0001, prob 0.0625: Thiaz\n",
      "state 0, timestep 0, action_code 0010, prob 0.0625: Bingu\n",
      "state 0, timestep 0, action_code 0011, prob 0.0625: Bingu+Thiaz\n",
      "state 0, timestep 0, action_code 0100, prob 0.0625: ACE\n",
      "state 0, timestep 0, action_code 0101, prob 0.0625: ACE+Thiaz\n",
      "state 0, timestep 0, action_code 0110, prob 0.0625: ACE+Bingu\n",
      "state 0, timestep 0, action_code 0111, prob 0.0625: ACE+Bingu+Thiaz\n",
      "state 0, timestep 0, action_code 1000, prob 0.0625: Diur\n",
      "state 0, timestep 0, action_code 1001, prob 0.0625: Diur+Thiaz\n",
      "state 0, timestep 0, action_code 1010, prob 0.0625: Diur+Bingu\n",
      "state 0, timestep 0, action_code 1011, prob 0.0625: Diur+Bingu+Thiaz\n",
      "state 0, timestep 0, action_code 1100, prob 0.0625: Diur+ACE\n",
      "state 0, timestep 0, action_code 1101, prob 0.0625: Diur+ACE+Thiaz\n",
      "state 0, timestep 0, action_code 1110, prob 0.0625: Diur+ACE+Bingu\n",
      "state 0, timestep 0, action_code 1111, prob 0.0625: Diur+ACE+Bingu+Thiaz\n",
      "state 0, timestep 1, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 2, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 3, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 4, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 5, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 6, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 7, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 8, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 9, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 10, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 11, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 12, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 13, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 14, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 15, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 16, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 17, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 18, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 0, timestep 19, action_code 1111, prob 1.0: Diur+ACE+Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 0000, prob 0.0625: BPBGClass_none\n",
      "state 1, timestep 0, action_code 0001, prob 0.0625: Thiaz\n",
      "state 1, timestep 0, action_code 0010, prob 0.0625: Bingu\n",
      "state 1, timestep 0, action_code 0011, prob 0.0625: Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 0100, prob 0.0625: ACE\n",
      "state 1, timestep 0, action_code 0101, prob 0.0625: ACE+Thiaz\n",
      "state 1, timestep 0, action_code 0110, prob 0.0625: ACE+Bingu\n",
      "state 1, timestep 0, action_code 0111, prob 0.0625: ACE+Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 1000, prob 0.0625: Diur\n",
      "state 1, timestep 0, action_code 1001, prob 0.0625: Diur+Thiaz\n",
      "state 1, timestep 0, action_code 1010, prob 0.0625: Diur+Bingu\n",
      "state 1, timestep 0, action_code 1011, prob 0.0625: Diur+Bingu+Thiaz\n",
      "state 1, timestep 0, action_code 1100, prob 0.0625: Diur+ACE\n",
      "state 1, timestep 0, action_code 1101, prob 0.0625: Diur+ACE+Thiaz\n",
      "state 1, timestep 0, action_code 1110, prob 0.0625: Diur+ACE+Bingu\n",
      "state 1, timestep 0, action_code 1111, prob 0.0625: Diur+ACE+Bingu+Thiaz\n",
      "state 1, timestep 1, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 2, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 3, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 4, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 5, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 6, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 7, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 8, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 9, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 10, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 11, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 12, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 13, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 14, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 15, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 16, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 17, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 18, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 1, timestep 19, action_code 1011, prob 1.0: Diur+Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 0000, prob 0.0625: BPBGClass_none\n",
      "state 2, timestep 0, action_code 0001, prob 0.0625: Thiaz\n",
      "state 2, timestep 0, action_code 0010, prob 0.0625: Bingu\n",
      "state 2, timestep 0, action_code 0011, prob 0.0625: Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 0100, prob 0.0625: ACE\n",
      "state 2, timestep 0, action_code 0101, prob 0.0625: ACE+Thiaz\n",
      "state 2, timestep 0, action_code 0110, prob 0.0625: ACE+Bingu\n",
      "state 2, timestep 0, action_code 0111, prob 0.0625: ACE+Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 1000, prob 0.0625: Diur\n",
      "state 2, timestep 0, action_code 1001, prob 0.0625: Diur+Thiaz\n",
      "state 2, timestep 0, action_code 1010, prob 0.0625: Diur+Bingu\n",
      "state 2, timestep 0, action_code 1011, prob 0.0625: Diur+Bingu+Thiaz\n",
      "state 2, timestep 0, action_code 1100, prob 0.0625: Diur+ACE\n",
      "state 2, timestep 0, action_code 1101, prob 0.0625: Diur+ACE+Thiaz\n",
      "state 2, timestep 0, action_code 1110, prob 0.0625: Diur+ACE+Bingu\n",
      "state 2, timestep 0, action_code 1111, prob 0.0625: Diur+ACE+Bingu+Thiaz\n",
      "state 2, timestep 1, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 2, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 3, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 4, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 5, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 6, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 7, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 8, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 9, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 10, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 11, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 12, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 13, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 14, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 15, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 16, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 17, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 18, action_code 0100, prob 0.0: ACE\n",
      "state 2, timestep 19, action_code 0111, prob 1.0: ACE+Bingu+Thiaz\n",
      "state 3, timestep 0, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 0, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 1, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 2, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 3, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 4, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 5, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 6, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 7, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 8, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 9, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 10, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 11, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 12, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 13, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 14, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 15, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 16, action_code 1100, prob 0.0: Diur+ACE\n",
      "state 3, timestep 17, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 18, action_code 1110, prob 1.0: Diur+ACE+Bingu\n",
      "state 3, timestep 19, action_code 1110, prob 1.0: Diur+ACE+Bingu\n"
     ]
    }
   ],
   "source": [
    "# decode the policy_b [s, h, a]\n",
    "for s in range(N_STATES):\n",
    "    for h in range(EPISODE_LENGTH):\n",
    "        for a in range(N_ACTIONS):\n",
    "            if policy_b[s, h, a] != 0:\n",
    "                # print('policy_b[', s, ',', h, ',', a, '] =', policy_b[s, h, a], ', action_code =', actions[a])\n",
    "                action_code = actions[a]\n",
    "                med_action = action_code_to_med_action(action_code)\n",
    "                # print('opt_policy_con[', s, ',', h, ',', a, '] =', opt_policy_con[s, h, a], ', action_code =', actions[a])\n",
    "                print('state {}, timestep {}, action_code {}, prob {}: {}'.format(s, h, action_code, opt_policy_con[s, h, a], med_action))                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c86494cdbaab790faf1630f8596bee794fd9c939f53713dc51278a7ffca15d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
