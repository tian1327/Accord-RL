{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from UtilityMethods import utils\n",
    "import sys\n",
    "#import gym\n",
    "import pickle\n",
    "import time\n",
    "import pulp as p\n",
    "import math\n",
    "from copy import copy\n",
    "import pprint as pp\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "IS_VISIT_DEPENDENT = False # whether the above empirical estimates are visit-dependent or not\n",
    "DATA = '../../../../Codes/Accord/data/ACCORD_BPClass_v2.csv'\n",
    "\n",
    "EPISODE_LENGTH = 40 # average number of visits per patient\n",
    "CONSTRAINT = EPISODE_LENGTH/2\n",
    "C_b = CONSTRAINT/5  #Change this if you want different baseline policy. here is 0.2C\n",
    "\n",
    "NUMBER_EPISODES = 1e4\n",
    "NUMBER_SIMULATIONS = 1\n",
    "\n",
    "delta = 0.01 # bound\n",
    "EPS = 0.01 # not used\n",
    "M = 0 # not used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State space and action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(states) = 288\n",
      "['2713', '2720', '2721', '2722', '2723']\n",
      "0000 0\n",
      "0001 1\n",
      "0002 2\n",
      "0003 3\n",
      "0010 4\n",
      "\n",
      "len(actions) = 32\n",
      "00000 0\n",
      "00001 1\n",
      "00010 2\n",
      "00011 3\n",
      "00100 4\n"
     ]
    }
   ],
   "source": [
    "# state space, actions available in each state are always the same\n",
    "\"\"\"\n",
    "state_features = ['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete','BMI_discrete'] \n",
    "fea1 = ['0', '1', '2', '3'] # possible values for sbp_discrete\n",
    "fea2 = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "fea3 = ['0', '1', '2', '3']\n",
    "fea4 = ['0', '1', '2', '3']\n",
    "fea5 = ['0', '1', '2', '3']\n",
    "\"\"\"\n",
    "\n",
    "state_features = ['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete'] \n",
    "fea1 = ['0', '1', '2'] # possible values for sbp_discrete, merge 3 with 2\n",
    "fea2 = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "fea3 = ['0', '1', '2'] # possible values for TC_discrete, merge 3 with 2\n",
    "fea4 = ['0', '1', '2', '3']\n",
    "\n",
    "combinations = itertools.product(fea1, fea2, fea3, fea4)\n",
    "states = [''.join(i) for i in combinations]\n",
    "print('len(states) =', len(states))\n",
    "print(states[-5:])\n",
    "\n",
    "N_STATES = len(states) # number of states = 2048\n",
    "state_code_to_index = {code: i for i, code in enumerate(states)}\n",
    "# print the first 5 state_code_to_index\n",
    "for i in range(5):\n",
    "    print(states[i], state_code_to_index[states[i]])\n",
    "print()\n",
    "\n",
    "# action space, 000000000 means bpclass_none, 111111111 means all bpmed class are precribed\n",
    "\"\"\"\n",
    "action_features = ['Diur', 'ACE', 'Beta-blocker', 'CCB', 'ARB', \n",
    "                   'Alpha-Beta-blocker', 'Alpha-blocker', 'Sympath', 'Vasod'] # we donot include 'bpclass_none' as a action, because 000000000 means bpclass_none\n",
    "\"\"\"\n",
    "\n",
    "action_features = ['Diur', 'ACE', 'Beta-blocker', 'CCB', 'ARB'] \n",
    "\n",
    "combinations = list(itertools.product('01', repeat=len(action_features)))\n",
    "actions = [''.join(i) for i in combinations]\n",
    "print('len(actions) =', len(actions))\n",
    "N_ACTIONS = len(actions) # number of actions = 512\n",
    "action_code_to_index = {code: i for i, code in enumerate(actions)}\n",
    "# print the first 5 action_code_to_index\n",
    "for i in range(5):\n",
    "    print(actions[i], action_code_to_index[actions[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate empirical estimates of P, R, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding action_code and state_code columns\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA)\n",
    "\n",
    "# add the state and action code columns\n",
    "action_code = []\n",
    "state_code = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    s_code = ''\n",
    "    a_code = ''\n",
    "    for state_fea in state_features:\n",
    "        code = str(row[state_fea])\n",
    "\n",
    "        # merge 3 with 2 for sbp_discrete and TC_discrete\n",
    "        if state_fea == 'sbp_discrete' and code == '3':\n",
    "            code = '2'\n",
    "        if state_fea == 'TC_discrete' and code == '3':\n",
    "            code = '2'\n",
    "\n",
    "        s_code += code\n",
    "    \n",
    "    for action_fea in action_features:\n",
    "        a_code += str(row[action_fea])\n",
    "    \n",
    "    action_code.append(a_code)\n",
    "    state_code.append(s_code)\n",
    "\n",
    "df['action_code'] = action_code\n",
    "df['state_code'] = state_code\n",
    "print('Finished adding action_code and state_code columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10251/10251 [01:37<00:00, 105.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(visit_number) = 4368\n",
      "averge visit_number = 40.500457875457876\n",
      "len(count_s_a) = 7115\n",
      "len(count_s_a_d) = 41003\n",
      "Finished counting by looping through the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#------------- calculate the empirical estimate of P, R, C\n",
    "        \n",
    "count_s_a = {} # count the number of times state s and action a appear in the dataset, sparse format\n",
    "count_s_a_d = {} # count the number of times state s, action a, and next state s' appear in the dataset\n",
    "sum_r_s_a = {} # sum of the reward of state s and action a\n",
    "sum_c_s_a = {} # sum of the cost of state s and action a\n",
    "visit_number = [] # number of visits for each patient\n",
    "\n",
    "# loop through each patient in the dataset\n",
    "for i in tqdm(range(100001, 110252)):\n",
    "    df_patient = df[df['MaskID'] == i]\n",
    "\n",
    "    if len(df_patient) > 0:\n",
    "        visit_number.append(len(df_patient))\n",
    "\n",
    "    # loop through each visit of the patient\n",
    "    for j in range(len(df_patient)-1): # loop before last visit\n",
    "        row = df_patient.iloc[j]\n",
    "        s_code = row['state_code']\n",
    "        a_code = row['action_code']\n",
    "        ns_code = df_patient.iloc[j+1]['state_code']\n",
    "\n",
    "        # convert from code to index\n",
    "        s = state_code_to_index[s_code]\n",
    "        a = action_code_to_index[a_code]\n",
    "        s_ = state_code_to_index[ns_code]\n",
    "\n",
    "        r = df_patient.iloc[j]['CVDRisk_feedback']\n",
    "        c = df_patient.iloc[j]['sbp_feedback']\n",
    "\n",
    "        if (s, a) not in count_s_a:\n",
    "            count_s_a[(s, a)] = 1\n",
    "            sum_r_s_a[(s, a)] = r \n",
    "            sum_c_s_a[(s, a)] = c\n",
    "        else:\n",
    "            count_s_a[(s, a)] += 1\n",
    "            sum_r_s_a[(s, a)] += r\n",
    "            sum_c_s_a[(s, a)] += c\n",
    "\n",
    "        if (s, a, s_) not in count_s_a_d:\n",
    "            count_s_a_d[(s, a, s_)] = 1\n",
    "        else:\n",
    "            count_s_a_d[(s, a, s_)] += 1\n",
    "\n",
    "print('len(visit_number) =', len(visit_number))\n",
    "print('averge visit_number =', sum(visit_number)/len(visit_number))\n",
    "\n",
    "print('len(count_s_a) =', len(count_s_a))\n",
    "print('len(count_s_a_d) =', len(count_s_a_d))\n",
    "print('Finished counting by looping through the dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Before reducing state and action space: results above shows that there were 25,658 state-action pairs and 65,912 state-action-nextstate pairs appeared in the dataset.\n",
    "* After: 7,115 state-action pairs, and 41,003 state-action-nextstate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating the empirical estimate of P, R, C\n",
      "\n",
      "Sparsity of P, R, C:\n",
      "P: 1.544830% are non-zeros\n",
      "R: 77.202691% are non-zeros\n",
      "C: 77.202691% are non-zeros\n"
     ]
    }
   ],
   "source": [
    "# calculate the empirical estimate of P, R, C using counts\n",
    "\n",
    "# initialize R, C, P, using sparse matrix format\n",
    "R = {} # N_STATES * N_ACTIONS, dictionary of reward matrices, this is the CVDRisk empirical estimate based on entire dataset\n",
    "C = {} # N_STATES * N_ACTIONS, dictionary of cost matrices, this is SBP empirical estimate based on entire dataset\n",
    "P = {} # N_STATES * N_ACTIONS * N_STATES, dictionary of transition probability matrices, based on the entire dataset\n",
    "\n",
    "# for s in range(N_STATES):\n",
    "#     l = len(actions)\n",
    "#     R[s] = np.zeros(l)\n",
    "#     C[s] = np.zeros(l)\n",
    "#     P[s] = {}    \n",
    "#     for a in range(N_ACTIONS):\n",
    "#         C[s][a] = 0\n",
    "#         P[s][a] = np.zeros(N_STATES)\n",
    "#         R[s][a] = 0\n",
    "# print('Finished initializing R, C, P')\n",
    "\n",
    "for (s,a) in count_s_a: # only calculate for the states and actions that appearedin the dataset, for efficiency\n",
    "\n",
    "    if s not in R:\n",
    "        R[s] = {}\n",
    "        C[s] = {}\n",
    "        P[s] = {}\n",
    "    \n",
    "    if a not in R[s]:\n",
    "        R[s][a] = 0\n",
    "        C[s][a] = 0\n",
    "        P[s][a] = {}\n",
    "\n",
    "    R[s][a] = sum_r_s_a[(s, a)]/max(count_s_a[(s, a)],1)\n",
    "    C[s][a] = sum_c_s_a[(s, a)]/max(count_s_a[(s, a)],1)\n",
    "\n",
    "for (s, a, s_) in count_s_a_d:\n",
    "    P[s][a][s_] = count_s_a_d[(s, a, s_)]/max(count_s_a[(s, a)],1)\n",
    "\n",
    "print('Finished calculating the empirical estimate of P, R, C')\n",
    "\n",
    "#------------- check the sparsity of P, R, C\n",
    "print('\\nSparsity of P, R, C:')\n",
    "print('P: {:.6f}% are non-zeros'.format(len(count_s_a_d)*100/(N_STATES*N_ACTIONS*N_STATES)))\n",
    "print('R: {:.6f}% are non-zeros'.format(len(sum_r_s_a)*100/(N_STATES*N_ACTIONS)))\n",
    "print('C: {:.6f}% are non-zeros'.format(len(sum_c_s_a)*100/(N_STATES*N_ACTIONS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_R = 0.7312023177749944\n",
      "max_C = 189.0\n"
     ]
    }
   ],
   "source": [
    "# normalize R and C to the range [0, 1]\n",
    "\n",
    "max_R = max([R[s][a] for s in R for a in R[s]])\n",
    "max_C = max([C[s][a] for s in C for a in C[s]])\n",
    "\n",
    "print('max_R =', max_R)\n",
    "print('max_C =', max_C)\n",
    "\n",
    "for s in R:\n",
    "    for a in R[s]:\n",
    "        R[s][a] = (R[s][a])/(max_R)\n",
    "        C[s][a] = (C[s][a])/(max_C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute solution.pkl and baseline.pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_methods_1 = utils(EPS, delta, M, P, R, C, EPISODE_LENGTH, N_STATES, actions, CONSTRAINT, C_b)\n",
    "\n",
    "opt_policy_con, opt_value_LP_con, opt_cost_LP_con, opt_q_con = util_methods_1.compute_opt_LP_Constrained(0) # constrained MDP\n",
    "opt_policy_uncon, opt_value_LP_uncon, opt_cost_LP_uncon, opt_q_uncon = util_methods_1.compute_opt_LP_Unconstrained(0) # unconstrained = standard MDP, not used in DOPE\n",
    "with open('solution.pckl', 'wb') as f:\n",
    "    pickle.dump([opt_policy_con, opt_value_LP_con, opt_cost_LP_con, opt_q_con, \n",
    "                 opt_policy_uncon, opt_value_LP_uncon, opt_cost_LP_uncon, opt_q_uncon], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_methods_1 = utils(EPS, delta, M, P,R,C,EPISODE_LENGTH,N_STATES,actions,C_b,C_b)\n",
    "policy_b, value_b, cost_b, q_b = util_methods_1.compute_opt_LP_Constrained(0)\n",
    "with open('base.pckl', 'wb') as f:\n",
    "    pickle.dump([policy_b, value_b, cost_b, q_b], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pckl', 'wb') as f:\n",
    "    pickle.dump([NUMBER_SIMULATIONS, NUMBER_EPISODES, P, R, C, \n",
    "                CONSTRAINT, N_STATES, actions, EPISODE_LENGTH, delta], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n*******')\n",
    "print(\"opt_value_LP_uncon[0, 0] =\",opt_value_LP_uncon[0, 0])\n",
    "print(\"opt_value_LP_con[0, 0] =\",opt_value_LP_con[0, 0])\n",
    "print(\"value_b[0, 0] =\",value_b[0, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    80866\n",
      "0    64732\n",
      "2    26865\n",
      "3     4443\n",
      "Name: sbp_discrete, dtype: int64\n",
      "\n",
      "1    34956\n",
      "2    34414\n",
      "3    32317\n",
      "4    24291\n",
      "0    17289\n",
      "5    15053\n",
      "7    10157\n",
      "6     8429\n",
      "Name: hba1c_discrete, dtype: int64\n",
      "\n",
      "1    69154\n",
      "0    49985\n",
      "2    39101\n",
      "3    18666\n",
      "Name: TC_discrete, dtype: int64\n",
      "\n",
      "0    58248\n",
      "1    54122\n",
      "2    38232\n",
      "3    26304\n",
      "Name: hdl_discrete, dtype: int64\n",
      "\n",
      "3    113017\n",
      "2     48196\n",
      "1     15594\n",
      "0        99\n",
      "Name: BMI_discrete, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the frequency counts of hba1c_discrete in the dataset\n",
    "\n",
    "def check_frequency(df, col_name):\n",
    "    df = df[col_name]\n",
    "    df = df.value_counts()\n",
    "    print(df)\n",
    "    print()\n",
    "\n",
    "# 'sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete','BMI_discrete'\n",
    "check_frequency(df, 'sbp_discrete')\n",
    "check_frequency(df, 'hba1c_discrete')\n",
    "check_frequency(df, 'TC_discrete')\n",
    "check_frequency(df, 'hdl_discrete')\n",
    "check_frequency(df, 'BMI_discrete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency counts above show that:\n",
    "1. we can merge the sbp_discrete 3 with 2. \n",
    "2. hba1c_discrete no change\n",
    "3. TC_discrete: merge 3 with 2\n",
    "4. hdl_discrete: no change\n",
    "5. remove BMI_discrete since most are in 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
