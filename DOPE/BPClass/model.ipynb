{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from UtilityMethods import utils\n",
    "import sys\n",
    "#import gym\n",
    "import pickle\n",
    "import time\n",
    "import pulp as p\n",
    "import math\n",
    "from copy import copy\n",
    "import pprint as pp\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "IS_VISIT_DEPENDENT = False # whether the above empirical estimates are visit-dependent or not\n",
    "DATA = '../../../../Codes/Accord/data/ACCORD_BPClass_v2.csv'\n",
    "\n",
    "EPISODE_LENGTH = 40 # average number of visits per patient\n",
    "CONSTRAINT = 800 # 20 deviation * 40 visits \n",
    "C_b = 20  # change this if you want different baseline policy.\n",
    "\n",
    "NUMBER_EPISODES = 1e4\n",
    "NUMBER_SIMULATIONS = 1\n",
    "\n",
    "delta = 0.01 # bound\n",
    "\n",
    "EPS = 0.01 # not used\n",
    "M = 0 # not used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State space and action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state space, actions available in each state are always the same\n",
    "\"\"\"\n",
    "state_features = ['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete','BMI_discrete'] \n",
    "fea1 = ['0', '1', '2', '3'] # possible values for sbp_discrete\n",
    "fea2 = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "fea3 = ['0', '1', '2', '3']\n",
    "fea4 = ['0', '1', '2', '3']\n",
    "fea5 = ['0', '1', '2', '3']\n",
    "\"\"\"\n",
    "\n",
    "state_features = ['sbp_discrete', 'hba1c_discrete'] \n",
    "fea1 = ['0', '1', '2'] # possible values for sbp_discrete, merge 3 with 2\n",
    "fea2 = ['0', '1', '2', '3'] # merge every 2 adjacent levels into 1 level\n",
    "fea3 = ['0', '1', '2'] # possible values for TC_discrete, merge 3 with 2\n",
    "fea4 = ['0', '1', '2'] # merge hdl_discrete 3 with 2\n",
    "\n",
    "combinations = itertools.product(fea1, fea2)\n",
    "states = [''.join(i) for i in combinations]\n",
    "print('len(states) =', len(states))\n",
    "print(states[:5])\n",
    "\n",
    "N_STATES = len(states) # number of states = 2048\n",
    "state_code_to_index = {code: i for i, code in enumerate(states)}\n",
    "# print the first 5 state_code_to_index\n",
    "for i in range(3):\n",
    "    print(states[i], state_code_to_index[states[i]])\n",
    "print()\n",
    "\n",
    "# action space, 000000000 means bpclass_none, 111111111 means all bpmed class are precribed\n",
    "\"\"\"\n",
    "action_features = ['Diur', 'ACE', 'Beta-blocker', 'CCB', 'ARB', \n",
    "                   'Alpha-Beta-blocker', 'Alpha-blocker', 'Sympath', 'Vasod'] # we donot include 'bpclass_none' as a action, because 000000000 means bpclass_none\n",
    "\"\"\"\n",
    "\n",
    "action_features = ['Diur', 'ACE', 'Beta-blocker', 'CCB', 'ARB'] \n",
    "\n",
    "combinations = list(itertools.product('01', repeat=len(action_features)))\n",
    "actions = [''.join(i) for i in combinations]\n",
    "print('len(actions) =', len(actions))\n",
    "N_ACTIONS = len(actions) # number of actions = 512\n",
    "action_code_to_index = {code: i for i, code in enumerate(actions)}\n",
    "# print the first 5 action_code_to_index\n",
    "for i in range(5):\n",
    "    print(actions[i], action_code_to_index[actions[i]])\n",
    "\n",
    "\n",
    "# build the action space for each state, assign the same action space to all states\n",
    "actions_per_state = {}\n",
    "for s in range(N_STATES):\n",
    "    actions_per_state[s] = [i for i in range(N_ACTIONS)]\n",
    "print('action_space for state 0:', actions_per_state[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate empirical estimates of P, R, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hba1c_discrete_code_dict = {'0': '0', '1': '0', \n",
    "                            '2': '1', '3': '1', \n",
    "                            '4': '2', '5': '2', \n",
    "                            '6': '3', '7': '3'}\n",
    "\n",
    "# add the state and action code columns\n",
    "action_code = []\n",
    "state_code = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    s_code = ''\n",
    "    a_code = ''\n",
    "    for state_fea in state_features:\n",
    "        code = str(row[state_fea])\n",
    "\n",
    "        # merge 3 with 2 for sbp_discrete and TC_discrete\n",
    "        if state_fea == 'sbp_discrete' and code == '3':\n",
    "            code = '2'\n",
    "        if state_fea == 'TC_discrete' and code == '3':\n",
    "            code = '2'\n",
    "        if state_fea == 'hdl_discrete' and code == '3':\n",
    "            code = '2'\n",
    "\n",
    "        # merge every 2 adjacent levels into 1 level for hba1c_discrete\n",
    "        if state_fea == 'hba1c_discrete':\n",
    "            code = hba1c_discrete_code_dict[code]\n",
    "        \n",
    "        s_code += code\n",
    "    \n",
    "    for action_fea in action_features:\n",
    "        a_code += str(row[action_fea])\n",
    "    \n",
    "    action_code.append(a_code)\n",
    "    state_code.append(s_code)\n",
    "\n",
    "df['action_code'] = action_code\n",
    "df['state_code'] = state_code\n",
    "print('Finished adding action_code and state_code columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- calculate the empirical estimate of P, R, C\n",
    "        \n",
    "count_s_a = {} # count the number of times state s and action a appear in the dataset, sparse format\n",
    "count_s_a_d = {} # count the number of times state s, action a, and next state s' appear in the dataset\n",
    "sum_r_s_a = {} # sum of the reward of state s and action a\n",
    "sum_c_s_a = {} # sum of the cost of state s and action a\n",
    "visit_number = [] # number of visits for each patient\n",
    "\n",
    "# loop through each patient in the dataset\n",
    "for i in tqdm(range(100001, 110252)):\n",
    "    df_patient = df[df['MaskID'] == i]\n",
    "\n",
    "    if len(df_patient) > 0:\n",
    "        visit_number.append(len(df_patient))\n",
    "\n",
    "    # loop through each visit of the patient\n",
    "    for j in range(len(df_patient)-1): # loop before last visit\n",
    "        row = df_patient.iloc[j]\n",
    "        s_code = row['state_code']\n",
    "        a_code = row['action_code']\n",
    "        ns_code = df_patient.iloc[j+1]['state_code']\n",
    "\n",
    "        # convert from code to index\n",
    "        s = state_code_to_index[s_code]\n",
    "        a = action_code_to_index[a_code]\n",
    "        s_ = state_code_to_index[ns_code]\n",
    "\n",
    "        r = df_patient.iloc[j]['CVDRisk_feedback']\n",
    "        c = df_patient.iloc[j]['sbp_feedback']\n",
    "\n",
    "        if (s, a) not in count_s_a:\n",
    "            count_s_a[(s, a)] = 1\n",
    "            sum_r_s_a[(s, a)] = r \n",
    "            sum_c_s_a[(s, a)] = c\n",
    "        else:\n",
    "            count_s_a[(s, a)] += 1\n",
    "            sum_r_s_a[(s, a)] += r\n",
    "            sum_c_s_a[(s, a)] += c\n",
    "\n",
    "        if (s, a, s_) not in count_s_a_d:\n",
    "            count_s_a_d[(s, a, s_)] = 1\n",
    "        else:\n",
    "            count_s_a_d[(s, a, s_)] += 1\n",
    "\n",
    "print('len(visit_number) =', len(visit_number))\n",
    "print('averge visit_number =', sum(visit_number)/len(visit_number))\n",
    "\n",
    "print('len(count_s_a) =', len(count_s_a))\n",
    "print('len(count_s_a_d) =', len(count_s_a_d))\n",
    "print('Finished counting by looping through the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sparsity of state-action pairs\n",
    "print('Total possible state-action pairs =', N_STATES * N_ACTIONS)\n",
    "print('seen state-action pairs =', len(count_s_a))\n",
    "print('sparsity of state-action pairs =', 1 - len(count_s_a)/(N_STATES * N_ACTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the empirical estimate of P, R, C using counts\n",
    "\n",
    "# initialize R, C, P, NOT using sparse matrix format\n",
    "R = {} # N_STATES * N_ACTIONS, dictionary of reward matrices, this is the CVDRisk empirical estimate based on entire dataset\n",
    "C = {} # N_STATES * N_ACTIONS, dictionary of cost matrices, this is SBP empirical estimate based on entire dataset\n",
    "P = {} # N_STATES * N_ACTIONS * N_STATES, dictionary of transition probability matrices, based on the entire dataset\n",
    "\n",
    "for s in range(N_STATES):\n",
    "    l = len(actions)\n",
    "    R[s] = np.zeros(l)\n",
    "    C[s] = np.zeros(l)\n",
    "    P[s] = {}    \n",
    "    for a in range(N_ACTIONS):\n",
    "        C[s][a] = 0\n",
    "        P[s][a] = np.zeros(N_STATES)\n",
    "        R[s][a] = 0\n",
    "print('Finished initializing R, C, P')\n",
    "\n",
    "for (s,a) in count_s_a: # only calculate for the states and actions that appearedin the dataset, for efficiency\n",
    "\n",
    "    # if s not in R:\n",
    "    #     R[s] = {}\n",
    "    #     C[s] = {}\n",
    "    #     P[s] = {}\n",
    "    \n",
    "    # if a not in R[s]:\n",
    "    #     R[s][a] = 0\n",
    "    #     C[s][a] = 0\n",
    "    #     P[s][a] = {}\n",
    "\n",
    "    R[s][a] = sum_r_s_a[(s, a)]/max(count_s_a[(s, a)],1)\n",
    "    C[s][a] = sum_c_s_a[(s, a)]/max(count_s_a[(s, a)],1)\n",
    "\n",
    "for (s, a, s_) in count_s_a_d:\n",
    "    P[s][a][s_] = count_s_a_d[(s, a, s_)]/max(count_s_a[(s, a)],1)\n",
    "\n",
    "print('Finished calculating the empirical estimate of P, R, C')\n",
    "\n",
    "#------------- check the sparsity of P, R, C\n",
    "print('\\nSparsity of P, R, C:')\n",
    "print('P: {:.6f}% are non-zeros'.format(len(count_s_a_d)*100/(N_STATES*N_ACTIONS*N_STATES)))\n",
    "print('R: {:.6f}% are non-zeros'.format(len(sum_r_s_a)*100/(N_STATES*N_ACTIONS)))\n",
    "print('C: {:.6f}% are non-zeros'.format(len(sum_c_s_a)*100/(N_STATES*N_ACTIONS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize R and C to the range [0, 1]\n",
    "\n",
    "# # !!! we should not normalize C (sbp), becasue we need to satisfy the constraint that SBP in range 110-125\n",
    "# # maybe no need to normalize R\n",
    "\n",
    "# max_R = max([R[s][a] for s in R for a in range(N_ACTIONS)])\n",
    "# max_C = max([C[s][a] for s in C for a in range(N_ACTIONS)])\n",
    "\n",
    "# # max_R = max([R[s][a] for s in R for a in R[s]])\n",
    "# # max_C = max([C[s][a] for s in C for a in C[s]])\n",
    "\n",
    "# print('max_R =', max_R)\n",
    "# print('max_C =', max_C)\n",
    "\n",
    "# # for s in R:\n",
    "# #     for a in range(N_ACTIONS):\n",
    "# #         R[s][a] = (R[s][a])/(max_R)\n",
    "# #         # C[s][a] = (C[s][a])/(max_C)\n",
    "\n",
    "\n",
    "# #---------- assign average reward and cost to unseen state-action pairs\n",
    "\n",
    "# # get the average of R and C\n",
    "# R_sum = 0\n",
    "# R_ct = 0\n",
    "# C_sum = 0\n",
    "# C_ct = 0\n",
    "# for (s,a) in count_s_a:\n",
    "#     R_sum += R[s][a]\n",
    "#     R_ct += 1\n",
    "#     C_sum += C[s][a]\n",
    "#     C_ct += 1\n",
    "\n",
    "# print('R_sum =', R_sum, 'R_ct =', R_ct)\n",
    "# R_avg = R_sum/R_ct\n",
    "# print('R_avg =', R_avg)\n",
    "\n",
    "# print('C_sum =', C_sum, 'C_ct =', C_ct)\n",
    "# C_avg = C_sum/C_ct\n",
    "# print('C_avg =', C_avg)\n",
    "\n",
    "# # assign the average to unseen state-action pairs\n",
    "# for s in range(N_STATES):\n",
    "#     for a in range(N_ACTIONS):\n",
    "#         if (s,a) not in count_s_a:\n",
    "#             R[s][a] = R_avg\n",
    "#             C[s][a] = C_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # assign uniform probability to unseen state-action-state triples\n",
    "# for s in range(N_STATES):\n",
    "#     for a in range(N_ACTIONS):\n",
    "#         if (s,a) not in count_s_a:\n",
    "#             for s_ in range(N_STATES):\n",
    "#                 P[s][a][s_] = 1/N_STATES\n",
    "\n",
    "# # check the sparsity of P\n",
    "\n",
    "# def check_sparsity_P(P):\n",
    "#     count_nonzero_P = 0\n",
    "#     for s in range(N_STATES):\n",
    "#         for a in range(N_ACTIONS):\n",
    "#             for s_ in range(N_STATES):\n",
    "#                 if P[s][a][s_] != 0:\n",
    "#                     count_nonzero_P += 1\n",
    "#     print(\"Percentage of non-zero elements in P:\", count_nonzero_P*100/(N_STATES*N_ACTIONS*N_STATES))\n",
    "\n",
    "# check_sparsity_P(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # assign uniform probability to all state-action-state triples\n",
    "# for s in range(N_STATES):\n",
    "#     for a in range(N_ACTIONS):\n",
    "#         for s_ in range(N_STATES):\n",
    "#             P[s][a][s_] = 1/(N_STATES)\n",
    "\n",
    "# check_sparsity_P(P)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Init states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_frequency(df, col_name):\n",
    "    df = df[col_name]\n",
    "    df = df.value_counts()\n",
    "    print(df)\n",
    "    print()\n",
    "\n",
    "    # return the first index in the series\n",
    "    return df.index[0]\n",
    "    \n",
    "# get the rows when the visit=='BLR' in df\n",
    "df_blr = df[df['Visit']=='BLR']\n",
    "INIT_STATES_LIST = df_blr['state_code'].unique() # we will sample uniformly from this list\n",
    "print('len(INIT_STATES_LIST) =', len(INIT_STATES_LIST))\n",
    "\n",
    "print('df_blr.shape =', df_blr.shape)\n",
    "most_freq_blr_state = check_frequency(df_blr, 'state_code')\n",
    "print('most_freq_blr_state =', most_freq_blr_state)\n",
    "INIT_STATE_INDEX = state_code_to_index[most_freq_blr_state]\n",
    "print('INIT_STATE_INDEX =', INIT_STATE_INDEX)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute solution.pkl and baseline.pkl files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model settings and parameters to a pickle file\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump([NUMBER_SIMULATIONS, NUMBER_EPISODES, P, R, C, INIT_STATE_INDEX, INIT_STATES_LIST, state_code_to_index,\n",
    "                CONSTRAINT, C_b, N_STATES, N_ACTIONS, actions_per_state, EPISODE_LENGTH, delta], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['UtilityMethods'])\n",
    "from UtilityMethods import utils\n",
    "\n",
    "util_methods_1 = utils(EPS, delta, M, P, R, C, INIT_STATE_INDEX, EPISODE_LENGTH, N_STATES, N_ACTIONS, actions_per_state, CONSTRAINT, C_b)\n",
    "\n",
    "# constrained MDP, solve the optimal policy using LP\n",
    "opt_policy_con, opt_value_LP_con, opt_cost_LP_con, opt_q_con = util_methods_1.compute_opt_LP_Constrained(0) \n",
    "\n",
    "# unconstrained = standard MDP, not used in DOPE\n",
    "# opt_policy_uncon, opt_value_LP_uncon, opt_cost_LP_uncon, opt_q_uncon = util_methods_1.compute_opt_LP_Unconstrained(0) \n",
    "\n",
    "with open('solution.pkl', 'wb') as f:\n",
    "    pickle.dump([opt_policy_con, opt_value_LP_con, opt_cost_LP_con, opt_q_con], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to deal with the sparsity of the P R C such that the above optimal solution is valid. For R amd C, assign the average value to unseen state-action pairs. For P, ???"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the baseline policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline policy\n",
    "\n",
    "util_methods_1 = utils(EPS, delta, M, P, R, C, INIT_STATE_INDEX, EPISODE_LENGTH, N_STATES, N_ACTIONS, actions_per_state, C_b, C_b)\n",
    "policy_b, value_b, cost_b, q_b = util_methods_1.compute_opt_LP_Constrained(0)\n",
    "\n",
    "with open('base.pkl', 'wb') as f:\n",
    "    pickle.dump([policy_b, value_b, cost_b, q_b], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"opt_value_LP_con[0, 0] =\",opt_value_LP_con[0, 0])\n",
    "print(\"value_b[0, 0] =\",value_b[0, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode calculated baseline policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the policy_b [s, h, a]\n",
    "\n",
    "for s in range(N_STATES):\n",
    "    for h in range(EPISODE_LENGTH):\n",
    "        for a in range(N_ACTIONS):\n",
    "            if policy_b[s, h, a] != 0:\n",
    "                print('policy_b[', s, ',', h, ',', a, '] =', policy_b[s, h, a], ', action_code =', actions[a])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check state code frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the frequency counts of hba1c_discrete in the dataset\n",
    "\n",
    "# 'sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete','BMI_discrete'\n",
    "check_frequency(df, 'sbp_discrete')\n",
    "check_frequency(df, 'hba1c_discrete')\n",
    "check_frequency(df, 'TC_discrete')\n",
    "check_frequency(df, 'hdl_discrete')\n",
    "check_frequency(df, 'BMI_discrete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency counts above show that:\n",
    "1. we can merge the sbp_discrete 3 with 2. \n",
    "2. hba1c_discrete: merge nearby 2 levels into 1, e.g. 0,1 --> 0, 1,2 --> 1\n",
    "3. TC_discrete: merge 3 with 2\n",
    "4. hdl_discrete: merge 3 with 2\n",
    "5. remove BMI_discrete since most are in 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP_med frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sbp_feedback range in the df when prescribinng ACE, \n",
    "df_ace = df[df['ACE']==1]\n",
    "print('df_ace.shape =', df_ace.shape)\n",
    "print(min(df_ace['sbp_feedback']))\n",
    "print(max(df_ace['sbp_feedback']))\n",
    "\n",
    "# plot the distribution of sbp_feedback\n",
    "plt.hist(df_ace['sbp_feedback'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sbp_feedback range in the df when prescribing ACE\n",
    "df_ace_only = df[df['action_code']=='00000']\n",
    "print('df_ace_only.shape =', df_ace_only.shape)\n",
    "print(min(df_ace_only['sbp_feedback']))\n",
    "print(max(df_ace_only['sbp_feedback']))\n",
    "\n",
    "# plot the distribution of sbp_feedback\n",
    "plt.hist(df_ace_only['sbp_feedback'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each possible combination of actions 00000 - 11111 (total 32 combinations), check the corresponding range of sbp_feedback, and plot the distribution\n",
    "# for i in range(32):\n",
    "#     action = str(bin(i))[2:].zfill(5)\n",
    "#     print(i, 'action =', action)\n",
    "#     df_action = df[df['action_code']==action]\n",
    "#     print('df_action.shape =', df_action.shape)\n",
    "#     print(min(df_action['sbp_feedback']))\n",
    "#     print(max(df_action['sbp_feedback']))\n",
    "#     plt.hist(df_action['sbp_feedback'], bins=20)\n",
    "#     plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the state-action sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop though each row of df, bu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlation between state features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_features = ['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_discrete = df['sbp_discrete']\n",
    "hba1c_discrete = df['hba1c_discrete']\n",
    "TC_discrete = df['TC_discrete']\n",
    "hdl_discrete = df['hdl_discrete']\n",
    "\n",
    "# plot the correlation between every 2 features in state_features\n",
    "import seaborn as sns\n",
    "sns.pairplot(df[['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete']], height=2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(df[['sbp','hba1c','TC','hdl']], height=2, markers='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 4x4 subplots, for every 2 features in state_features, plot the scatter plot\n",
    "state_fea = ['sbp','hba1c','TC','hdl']\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12,12))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # set the transparency to be 0.1\n",
    "        axes[i,j].scatter(df[state_fea[i]], df[state_fea[j]], alpha=0.01)\n",
    "        axes[i,j].set_xlabel(state_fea[i])\n",
    "        axes[i,j].set_ylabel(state_fea[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the correlation between every 2 features in state_features\n",
    "df[['sbp_discrete','hba1c_discrete','TC_discrete','hdl_discrete']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sbp','hba1c','TC','hdl']].corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the transition distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the 5 features, plot the scatter plot between the feature and the its corresponding feedback\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16,4))\n",
    "for i in range(4):\n",
    "    x_name = state_features[i]\n",
    "    y_name = x_name.split('_')[0] + '_feedback_discrete'\n",
    "    axes[i].scatter(df[x_name], df[y_name], alpha=0.01)\n",
    "    axes[i].set_xlabel(x_name)\n",
    "    axes[i].set_ylabel(y_name)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparsity comes from the transition of states. Not from the features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 3D distribution point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 3D scatter plot between sbp, hba1c, and TC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot( projection='3d')\n",
    "# ax.scatter(df['sbp'], df['hba1c'], df['TC'], alpha=0.01)\n",
    "ax.plot3D(df['sbp'], df['hba1c'], df['TC'], 'o', alpha=0.01)\n",
    "ax.set_xlabel('sbp')\n",
    "ax.set_ylabel('hba1c')\n",
    "ax.set_zlabel('TC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c86494cdbaab790faf1630f8596bee794fd9c939f53713dc51278a7ffca15d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
