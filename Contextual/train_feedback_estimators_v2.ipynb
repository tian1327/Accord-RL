{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train feedback estimators using Logistic and Linear Regression\n",
    "\n",
    "This script trains the following feedback estimators on the ACCORD_BPClass_v2.csv dataset\n",
    "\n",
    "* CVDRiskEstr: logistic regression, obtain accuracy arounnd 0.88\n",
    "* SBPEstr: linear regression, poor fitting, R^2 = 0.03\n",
    "* A1CEstr: linear regression, poor fitting, R^2 = 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 23:58:26.126217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../../data/ACCORD_BPClass_v2_merged.csv' # _merged means sbp_discrete levels are merged\n",
    "\n",
    "context_fea = ['baseline_age', 'female', 'race_whiteother', #'race_black', \n",
    "                'edu_baseline',\n",
    "                'cvd_hx_baseline', \n",
    "                'baseline_BMI', \n",
    "                # 'baseline_BMI_discrete',\n",
    "                'cigarett_baseline',\n",
    "                ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize the baseline_BMI\n",
    "\n",
    "fn = DATA\n",
    "df = pd.read_csv(fn)\n",
    "\n",
    "baseline_BMI_discrete = []\n",
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i]\n",
    "    BMI = row['baseline_BMI']      \n",
    "\n",
    "    if BMI < 18.5:\n",
    "        baseline_BMI_discrete.append(0)\n",
    "    elif BMI < 25:\n",
    "        baseline_BMI_discrete.append(1)\n",
    "    elif BMI < 30:\n",
    "        baseline_BMI_discrete.append(2)\n",
    "    else:\n",
    "        baseline_BMI_discrete.append(3)\n",
    "\n",
    "df['baseline_BMI_discrete'] = baseline_BMI_discrete\n",
    "\n",
    "# save to csv\n",
    "# fn_out = fn.replace('.csv', '_contextual.csv')\n",
    "fn_out = fn\n",
    "df.to_csv(fn_out, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVDRisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fea_cols =  ['baseline_age', 'female', 'race_whiteother', 'edu_baseline', 'cvd_hx_baseline', 'baseline_BMI_discrete', 'cigarett_baseline', 'sbp_discrete_merged', 'Diur', 'ACE', 'Beta-blocker', 'CCB']\n",
      "acc =  0.8256418663018779\n",
      "MSE =  0.1641520307058241\n",
      "MAE =  0.315682863349527\n",
      "RMSE =  0.40515679767939733\n",
      "R2 =  -8.507924848563299\n"
     ]
    }
   ],
   "source": [
    "def train_CVDRisk_estimator(fn, flag):\n",
    "\n",
    "    # flag = 'BP' or 'BG' or 'BPBG'\n",
    "    \n",
    "    # get the features and labels\n",
    "    df = pd.read_csv(fn)\n",
    "    # print(df.info())\n",
    "    \n",
    "    if flag == 'BP':\n",
    "        # state_cols = ['sbp_discrete_merged', 'BMI_discrete'] # state vector\n",
    "        state_cols = ['sbp_discrete_merged'] # state vector\n",
    "\n",
    "        medclass_cols =['Diur', 'ACE', 'Beta-blocker', 'CCB'] # pick top 4 most frequently used BP med classes\n",
    "                        \n",
    "    elif flag == 'BG':\n",
    "        medclass_cols = ['BMI', 'sbp', 'hba1c', 'TC', 'hdl', \n",
    "                        'bgclass_none', ]\n",
    "    elif flag == 'BPBG':\n",
    "        medclass_cols = ['BMI', 'sbp', 'hba1c', 'TC', 'hdl', \n",
    "                        'bpclass_none', 'Diur', 'ACE', 'Beta-blocker', 'CCB', \n",
    "                        'ARB', 'Alpha-Beta-blocker', 'Alpha-blocker', 'Sympath', 'Vasod',\n",
    "                        'bgclass_none', ]\n",
    "    else:\n",
    "        print('Error: flag must be BP, BG or BPBG')\n",
    "        exit()\n",
    "\n",
    "    fea_cols = context_fea + state_cols + medclass_cols\n",
    "\n",
    "    print('fea_cols = ', fea_cols)\n",
    "\n",
    "    X = df[fea_cols].values \n",
    "    y = df['CVDRisk_feedback_binary'].values # here we use 0.2 as the threshold to make the binarized class balance, as only 3% data has CVDRisk_feedback >= 0.5\n",
    "\n",
    "    # print('X.shape = ', X.shape)\n",
    "    # print('y.shape = ', y.shape)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "    # standardize the data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Train a logistic regression model to predict the risk of CVD\n",
    "    lr = LogisticRegression(max_iter=400).fit(X_train, y_train)\n",
    "    probs = lr.predict_proba(X_test)[:,1]\n",
    "    # print('probs = ', probs)\n",
    "    threshold = 0.2\n",
    "    y_pred = (probs >= threshold).astype(int)\n",
    "    # print('y_pred = ', y_pred)\n",
    "    # print('y_test = ', y_test)\n",
    "\n",
    "    # get the accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('test acc = ', acc)\n",
    "\n",
    "    y_test_numeric = df['CVDRisk_feedback'].values\n",
    "    # get the MSE between y_text_numeric and probs\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_test_numeric, probs)\n",
    "    print('test mse = ', mse)\n",
    "\n",
    "    # train_score = lr.score(X_train, y_train)\n",
    "    # test_score =  lr.score(X_test, y_test)\n",
    "    # print('train_score = ', train_score)\n",
    "    # print('test_score = ', test_score)\n",
    "    \"\"\"\n",
    "\n",
    "    # retrain the model on the whole dataset\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler_all = StandardScaler()\n",
    "    X = scaler_all.fit_transform(X)\n",
    "    estimator_all = LogisticRegression(max_iter=400).fit(X, y)\n",
    "    probs = estimator_all.predict_proba(X)[:,1]\n",
    "    # print('probs = ', probs)\n",
    "    threshold = 0.2\n",
    "    y_pred = (probs >= threshold).astype(int)\n",
    "    # print('y_pred = ', y_pred)\n",
    "    # print('y_test = ', y_test)\n",
    "\n",
    "    # get the accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    print('acc = ', acc)\n",
    "\n",
    "    y_numeric = df['CVDRisk_feedback'].values\n",
    "    # get the MSE, MAE, RMSE, r2\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    mse = mean_squared_error(y_numeric, probs)\n",
    "    mae = mean_absolute_error(y_numeric, probs)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_numeric, probs)\n",
    "    print('MSE = ', mse)\n",
    "    print('MAE = ', mae)\n",
    "    print('RMSE = ', rmse)\n",
    "    print('R2 = ', r2)\n",
    "\n",
    "    return (estimator_all, scaler_all, fea_cols)\n",
    "\n",
    "CVDRisk_estimator_BP, CVDRisk_scaler_BP, CVDRisk_fea_BP = train_CVDRisk_estimator(DATA, 'BP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (176906, 12)\n",
      "y.shape =  (176906,)\n",
      "train_score =  0.7914448950585644\n",
      "test_score =  0.7917677348536329\n",
      "train_score using all data =  0.7915120237782078\n"
     ]
    }
   ],
   "source": [
    "# train a linear regression model for CVD risk\n",
    "def train_CVDRisk_estimator_linear(fn):\n",
    "    # get the features and labels\n",
    "    df = pd.read_csv(fn)\n",
    "    # print(df.info())\n",
    "    # stop\n",
    "\n",
    "    medclass_cols =['Diur', 'ACE', 'Beta-blocker', 'CCB'] # pick top 4 most frequently used BP med classes\n",
    "\n",
    "    state_cols = ['sbp_discrete_merged'] # state vector\n",
    "    fea_cols = context_fea + state_cols + medclass_cols\n",
    " \n",
    "    X = df[fea_cols].values \n",
    "    y = df['CVDRisk_feedback'].values\n",
    "\n",
    "    # use  -log(1/y-1) to transform the y to a linear scale\n",
    "    y = -np.log(1/y-1)  \n",
    "\n",
    "    print('X.shape = ', X.shape)\n",
    "    print('y.shape = ', y.shape)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "    # Train a linear regression model to predict the risk of CVD\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    train_score = lr.score(X_train, y_train)\n",
    "    test_score =  lr.score(X_test, y_test)\n",
    "    print('train_score = ', train_score)\n",
    "    print('test_score = ', test_score)\n",
    "\n",
    "    # retrain the model on the whole dataset\n",
    "    estimator_all = LinearRegression().fit(X, y)\n",
    "    train_score_all = estimator_all.score(X, y)\n",
    "    print('train_score using all data = ', train_score_all)\n",
    "\n",
    "    return estimator_all        \n",
    "\n",
    "estimator = train_CVDRisk_estimator_linear(DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.053\n",
      "Model:                            OLS   Adj. R-squared:                  0.052\n",
      "Method:                 Least Squares   F-statistic:                     100.7\n",
      "Date:                Mon, 17 Apr 2023   Prob (F-statistic):               0.00\n",
      "Time:                        22:59:42   Log-Likelihood:            -7.2665e+05\n",
      "No. Observations:              176906   AIC:                         1.453e+06\n",
      "Df Residuals:                  176807   BIC:                         1.454e+06\n",
      "Df Model:                          98                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        109.2334      6.599     16.554      0.000      96.300     122.167\n",
      "x1             0.1768      0.116      1.522      0.128      -0.051       0.405\n",
      "x2            -7.3864      0.659    -11.209      0.000      -8.678      -6.095\n",
      "x3            -1.6177      0.712     -2.272      0.023      -3.013      -0.222\n",
      "x4            -1.5196      0.604     -2.516      0.012      -2.704      -0.336\n",
      "x5             0.2279      0.174      1.313      0.189      -0.112       0.568\n",
      "x6            -0.0605      0.193     -0.314      0.754      -0.438       0.317\n",
      "x7             2.7936      0.587      4.757      0.000       1.643       3.944\n",
      "x8            -0.0314      0.014     -2.264      0.024      -0.059      -0.004\n",
      "x9             0.0127      0.048      0.262      0.793      -0.082       0.107\n",
      "x10           -1.1675      0.755     -1.546      0.122      -2.647       0.312\n",
      "x11           -2.0767      0.718     -2.892      0.004      -3.484      -0.669\n",
      "x12            0.1761      0.786      0.224      0.823      -1.365       1.717\n",
      "x13            0.0130      0.858      0.015      0.988      -1.669       1.695\n",
      "x14            0.0017      0.001      2.522      0.012       0.000       0.003\n",
      "x15            0.2314      0.012     18.671      0.000       0.207       0.256\n",
      "x16           -0.0168      0.014     -1.186      0.236      -0.045       0.011\n",
      "x17            0.0392      0.006      7.075      0.000       0.028       0.050\n",
      "x18           -0.0080      0.003     -3.117      0.002      -0.013      -0.003\n",
      "x19            0.0018      0.002      0.755      0.450      -0.003       0.007\n",
      "x20           -0.0289      0.005     -5.383      0.000      -0.039      -0.018\n",
      "x21            0.0004      0.000      3.369      0.001       0.000       0.001\n",
      "x22           -0.0013      0.000     -2.796      0.005      -0.002      -0.000\n",
      "x23           -0.0021      0.014     -0.147      0.883      -0.030       0.026\n",
      "x24           -0.0049      0.014     -0.356      0.722      -0.032       0.022\n",
      "x25            0.0369      0.015      2.426      0.015       0.007       0.067\n",
      "x26           -0.0222      0.016     -1.349      0.177      -0.054       0.010\n",
      "x27           -7.3864      0.659    -11.209      0.000      -8.678      -6.095\n",
      "x28           -1.0867      0.191     -5.700      0.000      -1.460      -0.713\n",
      "x29           -0.1988      0.079     -2.509      0.012      -0.354      -0.044\n",
      "x30           -0.0355      0.034     -1.055      0.291      -0.101       0.030\n",
      "x31            0.1062      0.032      3.297      0.001       0.043       0.169\n",
      "x32            0.2568      0.075      3.409      0.001       0.109       0.404\n",
      "x33            0.0051      0.002      2.802      0.005       0.002       0.009\n",
      "x34           -0.0744      0.007    -10.870      0.000      -0.088      -0.061\n",
      "x35           -0.3109      0.208     -1.491      0.136      -0.719       0.098\n",
      "x36           -0.3163      0.196     -1.613      0.107      -0.701       0.068\n",
      "x37            1.2393      0.220      5.645      0.000       0.809       1.670\n",
      "x38           -0.0020      0.229     -0.009      0.993      -0.450       0.446\n",
      "x39           -1.6177      0.712     -2.272      0.023      -3.013      -0.222\n",
      "x40            0.0523      0.087      0.599      0.549      -0.119       0.223\n",
      "x41            0.0666      0.037      1.782      0.075      -0.007       0.140\n",
      "x42           -0.1189      0.035     -3.381      0.001      -0.188      -0.050\n",
      "x43            0.5335      0.080      6.644      0.000       0.376       0.691\n",
      "x44           -0.0093      0.002     -4.377      0.000      -0.013      -0.005\n",
      "x45            0.0224      0.007      3.183      0.001       0.009       0.036\n",
      "x46            0.5886      0.240      2.449      0.014       0.118       1.060\n",
      "x47           -0.0373      0.225     -0.165      0.869      -0.479       0.404\n",
      "x48           -1.2040      0.246     -4.895      0.000      -1.686      -0.722\n",
      "x49           -0.2691      0.251     -1.070      0.284      -0.762       0.224\n",
      "x50           -0.0221      0.037     -0.595      0.552      -0.095       0.051\n",
      "x51            0.0270      0.016      1.661      0.097      -0.005       0.059\n",
      "x52           -0.0047      0.015     -0.306      0.759      -0.035       0.025\n",
      "x53           -0.1663      0.034     -4.900      0.000      -0.233      -0.100\n",
      "x54           -0.0012      0.001     -1.449      0.147      -0.003       0.000\n",
      "x55           -0.0070      0.003     -2.323      0.020      -0.013      -0.001\n",
      "x56           -0.2976      0.094     -3.154      0.002      -0.483      -0.113\n",
      "x57           -0.0698      0.089     -0.785      0.432      -0.244       0.105\n",
      "x58            0.2138      0.099      2.159      0.031       0.020       0.408\n",
      "x59            0.2359      0.104      2.259      0.024       0.031       0.441\n",
      "x60           1.7e-07    3.7e-08      4.590      0.000    9.74e-08    2.43e-07\n",
      "x61         2.276e-05   1.22e-05      1.859      0.063   -1.23e-06    4.67e-05\n",
      "x62        -4.627e-06   3.56e-06     -1.300      0.194   -1.16e-05    2.35e-06\n",
      "x63        -1.516e-07   2.34e-07     -0.648      0.517    -6.1e-07    3.07e-07\n",
      "x64         1.216e-05   5.67e-06      2.146      0.032    1.06e-06    2.33e-05\n",
      "x65          5.43e-06   1.43e-05      0.380      0.704   -2.26e-05    3.35e-05\n",
      "x66          4.36e-05   3.49e-05      1.251      0.211   -2.47e-05       0.000\n",
      "x67        -1.559e-05   2.51e-05     -0.621      0.535   -6.48e-05    3.36e-05\n",
      "x68            0.1254      0.041      3.063      0.002       0.045       0.206\n",
      "x69            0.0041      0.001      4.816      0.000       0.002       0.006\n",
      "x70           -0.0052      0.006     -0.865      0.387      -0.017       0.007\n",
      "x71            0.0004      0.000      2.793      0.005       0.000       0.001\n",
      "x72           -0.0040      0.001     -7.683      0.000      -0.005      -0.003\n",
      "x73            0.0062      0.017      0.369      0.712      -0.027       0.039\n",
      "x74            0.0423      0.016      2.618      0.009       0.011       0.074\n",
      "x75           -0.0252      0.018     -1.440      0.150      -0.060       0.009\n",
      "x76           -0.0765      0.039     -1.943      0.052      -0.154       0.001\n",
      "x77           -0.0830      0.019     -4.464      0.000      -0.119      -0.047\n",
      "x78            0.0066      0.001      8.821      0.000       0.005       0.008\n",
      "x79            0.0090      0.003      3.245      0.001       0.004       0.014\n",
      "x80            0.0445      0.087      0.514      0.608      -0.125       0.214\n",
      "x81            0.0935      0.082      1.136      0.256      -0.068       0.255\n",
      "x82           -0.2646      0.091     -2.920      0.003      -0.442      -0.087\n",
      "x83           -0.1752      0.096     -1.832      0.067      -0.363       0.012\n",
      "x84           -0.0001   1.06e-05     -9.906      0.000      -0.000   -8.39e-05\n",
      "x85            0.0002    6.9e-05      2.868      0.004    6.27e-05       0.000\n",
      "x86           -0.0076      0.002     -3.414      0.001      -0.012      -0.003\n",
      "x87           -0.0051      0.002     -2.478      0.013      -0.009      -0.001\n",
      "x88            0.0038      0.002      1.669      0.095      -0.001       0.008\n",
      "x89            0.0197      0.002      8.170      0.000       0.015       0.024\n",
      "x90            0.0011      0.000      7.604      0.000       0.001       0.001\n",
      "x91           -0.0008      0.008     -0.101      0.919      -0.016       0.015\n",
      "x92            0.0330      0.007      4.444      0.000       0.018       0.047\n",
      "x93           -0.0074      0.008     -0.880      0.379      -0.024       0.009\n",
      "x94           -0.0311      0.009     -3.632      0.000      -0.048      -0.014\n",
      "x95           -1.1675      0.755     -1.546      0.122      -2.647       0.312\n",
      "x96            0.9421      0.208      4.532      0.000       0.535       1.349\n",
      "x97           -0.8276      0.239     -3.458      0.001      -1.297      -0.358\n",
      "x98           -0.6733      0.269     -2.500      0.012      -1.201      -0.145\n",
      "x99           -2.0767      0.718     -2.892      0.004      -3.484      -0.669\n",
      "x100           0.9544      0.208      4.599      0.000       0.548       1.361\n",
      "x101          -0.9562      0.221     -4.319      0.000      -1.390      -0.522\n",
      "x102           0.1761      0.786      0.224      0.823      -1.365       1.717\n",
      "x103           0.1443      0.213      0.676      0.499      -0.274       0.562\n",
      "x104           0.0130      0.858      0.015      0.988      -1.669       1.695\n",
      "==============================================================================\n",
      "Omnibus:                     8668.268   Durbin-Watson:                   0.504\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12711.644\n",
      "Skew:                           0.451   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.955   Cond. No.                     1.00e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large,  1e+16. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "X.shape =  (176906, 105)\n",
      "y.shape =  (176906,)\n",
      "train_score =  0.053347223392992804\n",
      "test_score =  0.049559389761584915\n",
      "train_score using all data =  0.0528616738186275\n"
     ]
    }
   ],
   "source": [
    "# train a linear regression model for SBP feedback\n",
    "def train_SBP_estimator(fn):\n",
    "    # get the features and labels\n",
    "    df = pd.read_csv(fn)\n",
    "    # print(df.info())\n",
    "    # stop\n",
    "\n",
    "    medclass_cols =['Diur', 'ACE', 'Beta-blocker', 'CCB'] # pick top 4 most frequently used BP med classes\n",
    "\n",
    "    # state_cols = ['BMI_discrete'] # state vector\n",
    "    state_cols = ['BMI', 'hba1c', 'TC', 'hdl'] # state vector\n",
    "    fea_cols = context_fea + state_cols + medclass_cols\n",
    "    # fea_cols = context_fea + medclass_cols\n",
    "\n",
    "    # fea_cols = ['BMI'] # try to predict SBP from BMI only\n",
    "\n",
    "    X = df[fea_cols].values \n",
    "    y = df['sbp_feedback'].values\n",
    "\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X = poly.fit_transform(X)\n",
    "\n",
    "    # check for p values\n",
    "    import statsmodels.api as sm\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "    print('X.shape = ', X.shape)\n",
    "    print('y.shape = ', y.shape)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "    # Train a linear regression model to predict the risk of CVD\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    train_score = lr.score(X_train, y_train)\n",
    "    test_score =  lr.score(X_test, y_test)\n",
    "    print('train_score = ', train_score)\n",
    "    print('test_score = ', test_score)\n",
    "\n",
    "    # retrain the model on the whole dataset\n",
    "    estimator_all = LinearRegression().fit(X, y)\n",
    "    train_score_all = estimator_all.score(X, y)\n",
    "    print('train_score using all data = ', train_score_all)\n",
    "\n",
    "    return estimator_all        \n",
    "\n",
    "SBP_feedback_estimator = train_SBP_estimator(DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (176906, 12)\n",
      "y.shape =  (176906,)\n",
      "train_score =  0.06409643687454869\n",
      "test_score =  0.06762149278475882\n",
      "train_score using all data =  0.06481888991998697\n"
     ]
    }
   ],
   "source": [
    "# train a linear regression model for A1C feedback\n",
    "def train_A1C_estimator(fn):\n",
    "    # get the features and labels\n",
    "    df = pd.read_csv(fn)\n",
    "    state_cols = ['sbp_discrete'] # state vector\n",
    "    medclass_cols =['Diur', 'ACE', 'Beta-blocker', 'CCB'] # pick top 4 most frequently used BP med classes\n",
    "\n",
    "    fea_cols = context_fea + state_cols + medclass_cols\n",
    "    # fea_cols.remove('race_black')\n",
    "    X = df[fea_cols].values \n",
    "    y = df['hba1c_feedback'].values\n",
    "\n",
    "    print('X.shape = ', X.shape)\n",
    "    print('y.shape = ', y.shape)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "    # Train a linear regression model to predict the risk of CVD\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    train_score = lr.score(X_train, y_train)\n",
    "    test_score =  lr.score(X_test, y_test)\n",
    "    print('train_score = ', train_score)\n",
    "    print('test_score = ', test_score)\n",
    "\n",
    "    # retrain the model on the whole dataset\n",
    "    estimator = LinearRegression().fit(X, y)\n",
    "    train_score2 = estimator.score(X, y)\n",
    "    print('train_score using all data = ', train_score2)\n",
    "\n",
    "    return estimator        \n",
    "\n",
    "SBP_estimator = train_A1C_estimator(DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Estimators using ANN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a class which build a ANN model for SBP feedback, using tensorflow framwork\n",
    "   \n",
    "class ANN:\n",
    "    def __init__(self, input_shape, output_shape, hidden_layers, output_activation='linear'):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.hidden_layers = hidden_layers        \n",
    "        \n",
    "        # Define the model architecture\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "        for i in range(len(hidden_layers)):\n",
    "            # self.model.add(tf.keras.layers.Dense(hidden_layers[i], activation='relu'))\n",
    "            self.model.add(tf.keras.layers.Dense(hidden_layers[i], activation='linear'))\n",
    "        self.model.add(tf.keras.layers.Dense(output_shape, activation=output_activation))\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val, epochs=10, batch_size=16):\n",
    "        # Compile the model with appropriate loss function and optimizer\n",
    "        self.model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "        # self.model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        # Train the model\n",
    "        self.model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        # Evaluate the model on the test set\n",
    "        return self.model.evaluate(x, y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # Use the model to make predictions\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVDRisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (176906, 12)\n",
      "y.shape =  (176906,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 20:52:03.328981: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5529/5529 [==============================] - 10s 2ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 2/20\n",
      "5529/5529 [==============================] - 9s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 3/20\n",
      "5529/5529 [==============================] - 11s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 4/20\n",
      "5529/5529 [==============================] - 9s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 5/20\n",
      "5529/5529 [==============================] - 11s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 6/20\n",
      "5529/5529 [==============================] - 11s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 7/20\n",
      "5529/5529 [==============================] - 15s 3ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 8/20\n",
      "5529/5529 [==============================] - 13s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 9/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 10/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 11/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 12/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 13/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 14/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 15/20\n",
      "5529/5529 [==============================] - 11s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 16/20\n",
      "5529/5529 [==============================] - 11s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 17/20\n",
      "5529/5529 [==============================] - 13s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 18/20\n",
      "5529/5529 [==============================] - 14s 3ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 19/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 20/20\n",
      "5529/5529 [==============================] - 12s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# train a ANN model for CVDRisk \n",
    "def train_CVDRisk_estimator_ANN(fn, flag, train_onwhole=False):\n",
    "    # flag = 'BP' or 'BG' or 'BPBG'\n",
    "    \n",
    "    # get the features and labels\n",
    "    df = pd.read_csv(fn)\n",
    "\n",
    "    if flag == 'BP':\n",
    "        state_cols = ['sbp_discrete_merged'] # state vector\n",
    "\n",
    "        medclass_cols =['Diur', 'ACE', 'Beta-blocker', 'CCB'] # pick top 4 most frequently used BP med classes\n",
    "\n",
    "    elif flag == 'BG':\n",
    "        medclass_cols = ['BMI', 'sbp', 'hba1c', 'TC', 'hdl', \n",
    "                        'bgclass_none', ]\n",
    "    elif flag == 'BPBG':\n",
    "        medclass_cols = ['BMI', 'sbp', 'hba1c', 'TC', 'hdl', \n",
    "                        'bpclass_none', 'Diur', 'ACE', 'Beta-blocker', 'CCB', \n",
    "                        'ARB', 'Alpha-Beta-blocker', 'Alpha-blocker', 'Sympath', 'Vasod',\n",
    "                        'bgclass_none', ]\n",
    "    else:\n",
    "        print('Error: flag must be BP, BG or BPBG')\n",
    "        exit()\n",
    "\n",
    "    fea_cols = context_fea + state_cols + medclass_cols\n",
    "    X = df[fea_cols].values \n",
    "    y = df['CVDRisk_feedback'].values\n",
    "    print('X.shape = ', X.shape)\n",
    "    print('y.shape = ', y.shape)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=100)\n",
    "\n",
    "    # model = ANN(X.shape[1], 1, [16, 8], 'sigmoid')\n",
    "    model = ANN(X.shape[1], 1, [16, 8], 'linear')\n",
    "    if not train_onwhole: # to explore hyperparameters\n",
    "        model.train(X_train, y_train, X_val, y_val, epochs=20, batch_size=32)\n",
    "        test_score = model.evaluate(X_test, y_test)\n",
    "        print('test_score = ', test_score)\n",
    "        return (None, fea_cols)\n",
    "\n",
    "    else: # retrain the model on the whole dataset\n",
    "        model.train(X, y, X, y, epochs=20, batch_size=32)    \n",
    "        return (model, fea_cols)\n",
    "\n",
    "# none, CVDRisk_fea = train_CVDRisk_estimator_ANN('../../../Codes/Accord/data/ACCORD_BPClass_v2.csv', 'BP')    \n",
    "CVDRisk_estimator_ANN_BP, CVDRisk_fea_BP = train_CVDRisk_estimator_ANN(DATA, 'BP', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (176906, 11)\n",
      "y.shape =  (176906,)\n",
      "Epoch 1/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 6478259.0000 - mse: 6478259.0000 - val_loss: 478504.0625 - val_mse: 478504.0625\n",
      "Epoch 2/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 1308443.2500 - mse: 1308443.2500 - val_loss: 2971903.7500 - val_mse: 2971903.7500\n",
      "Epoch 3/15\n",
      "11057/11057 [==============================] - 18s 2ms/step - loss: 1219309.5000 - mse: 1219309.5000 - val_loss: 213577.6406 - val_mse: 213577.6406\n",
      "Epoch 4/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 566021.6250 - mse: 566021.6250 - val_loss: 775707.1875 - val_mse: 775707.1875\n",
      "Epoch 5/15\n",
      "11057/11057 [==============================] - 18s 2ms/step - loss: 337095.7188 - mse: 337095.7188 - val_loss: 566042.5625 - val_mse: 566042.5625\n",
      "Epoch 6/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 255014.3594 - mse: 255014.3594 - val_loss: 127627.1562 - val_mse: 127627.1562\n",
      "Epoch 7/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 114044.1562 - mse: 114044.1562 - val_loss: 7484.4053 - val_mse: 7484.4053\n",
      "Epoch 8/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 62981.4297 - mse: 62981.4297 - val_loss: 60876.4648 - val_mse: 60876.4648\n",
      "Epoch 9/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 21096.3398 - mse: 21096.3398 - val_loss: 45244.7773 - val_mse: 45244.7773\n",
      "Epoch 10/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 12267.7012 - mse: 12267.7012 - val_loss: 3223.7354 - val_mse: 3223.7354\n",
      "Epoch 11/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 3179.8557 - mse: 3179.8557 - val_loss: 2651.2178 - val_mse: 2651.2178\n",
      "Epoch 12/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 2450.4153 - mse: 2450.4153 - val_loss: 3075.1978 - val_mse: 3075.1978\n",
      "Epoch 13/15\n",
      "11057/11057 [==============================] - 19s 2ms/step - loss: 2304.9114 - mse: 2304.9114 - val_loss: 522.2042 - val_mse: 522.2042\n",
      "Epoch 14/15\n",
      "11057/11057 [==============================] - 20s 2ms/step - loss: 2084.5552 - mse: 2084.5552 - val_loss: 330.6629 - val_mse: 330.6629\n",
      "Epoch 15/15\n",
      "11053/11057 [============================>.] - ETA: 0s - loss: 1207.9719 - mse: 1207.9719"
     ]
    }
   ],
   "source": [
    "# train SBP estimator using ANN model\n",
    "def train_SBP_estimator_ANN(fn, train_onwhole=False):\n",
    "    # get the features and labels\n",
    "    df = pd.read_csv(fn)\n",
    "\n",
    "    medclass_cols =['Diur', 'ACE', 'Beta-blocker', 'CCB']\n",
    "\n",
    "    fea_cols = context_fea + medclass_cols\n",
    "    X = df[fea_cols].values \n",
    "    y = df['sbp_feedback'].values\n",
    "\n",
    "    print('X.shape = ', X.shape)\n",
    "    print('y.shape = ', y.shape)\n",
    "    \n",
    "    # Split the data into training, validation and testing sets\n",
    "    X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=100)\n",
    "\n",
    "    model = ANN(X.shape[1], 1, [16, 8])\n",
    "    if not train_onwhole: # to explore hyperparameters\n",
    "        model.train(X_train, y_train, X_val, y_val, epochs=20, batch_size=16)\n",
    "        test_score = model.evaluate(X_test, y_test)\n",
    "        print('test_score = ', test_score)\n",
    "        return (None, fea_cols)\n",
    "\n",
    "    else: # retrain the model on the whole dataset\n",
    "        model.train(X, y, X, y, epochs=50, batch_size=16)    \n",
    "        return (model, fea_cols)\n",
    "\n",
    "# none, SBP_fea = train_SBP_estimator_ANN('../../../Codes/Accord/data/ACCORD_BPClass_v2.csv')\n",
    "SBP_estimator_ANN, SBP_fea = train_SBP_estimator_ANN(DATA, True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (290467, 17)\n",
      "y.shape =  (290467,)\n",
      "Epoch 1/15\n",
      "9078/9078 [==============================] - 18s 2ms/step - loss: 323339.7812 - val_loss: 16.1397\n",
      "Epoch 2/15\n",
      "9078/9078 [==============================] - 19s 2ms/step - loss: 25794.3047 - val_loss: 920.3678\n",
      "Epoch 3/15\n",
      "9078/9078 [==============================] - 17s 2ms/step - loss: 16736.1738 - val_loss: 5715.7778\n",
      "Epoch 4/15\n",
      "9078/9078 [==============================] - 20s 2ms/step - loss: 14569.7510 - val_loss: 156323.9062\n",
      "Epoch 5/15\n",
      "9078/9078 [==============================] - 25s 3ms/step - loss: 15216.2100 - val_loss: 5436.5928\n",
      "Epoch 6/15\n",
      "9078/9078 [==============================] - 22s 2ms/step - loss: 5136.6772 - val_loss: 1187.3887\n",
      "Epoch 7/15\n",
      "9078/9078 [==============================] - 23s 3ms/step - loss: 1994.5747 - val_loss: 123.3015\n",
      "Epoch 8/15\n",
      "9078/9078 [==============================] - 24s 3ms/step - loss: 5.3624 - val_loss: 1.0676\n",
      "Epoch 9/15\n",
      "9078/9078 [==============================] - 21s 2ms/step - loss: 1.0831 - val_loss: 1.0642\n",
      "Epoch 10/15\n",
      "9078/9078 [==============================] - 19s 2ms/step - loss: 47.7258 - val_loss: 1.0516\n",
      "Epoch 11/15\n",
      "9078/9078 [==============================] - 18s 2ms/step - loss: 1.0664 - val_loss: 1.0554\n",
      "Epoch 12/15\n",
      "9078/9078 [==============================] - 20s 2ms/step - loss: 1.0603 - val_loss: 1.0531\n",
      "Epoch 13/15\n",
      "9078/9078 [==============================] - 15s 2ms/step - loss: 1.0567 - val_loss: 1.0634\n",
      "Epoch 14/15\n",
      "9078/9078 [==============================] - 16s 2ms/step - loss: 1.0939 - val_loss: 1.0377\n",
      "Epoch 15/15\n",
      "9078/9078 [==============================] - 15s 2ms/step - loss: 1.0479 - val_loss: 1.0419\n"
     ]
    }
   ],
   "source": [
    "# train a ANN model for A1C feedback\n",
    "def train_A1C_estimator_ANN(fn, train_onwhole=False):\n",
    "    # get the features and labels\n",
    "    df = pd.read_csv(fn)\n",
    "\n",
    "    medclass_cols = ['BMI', 'sbp', 'TC', 'hdl',   \n",
    "                    'bgclass_none', 'Bingu', 'Thiaz', 'Sulfon', 'Meglit', \n",
    "                    'Alpha-gluc']\n",
    "\n",
    "    fea_cols = context_fea + medclass_cols\n",
    "    X = df[fea_cols].values \n",
    "    y = df['hba1c'].values\n",
    "\n",
    "    print('X.shape = ', X.shape)\n",
    "    print('y.shape = ', y.shape)\n",
    "    \n",
    "    # Split the data into training, validation and testing sets\n",
    "    X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=100)\n",
    "\n",
    "    model = ANN(X.shape[1], 1, [16, 8])\n",
    "    if not train_onwhole: # to explore hyperparameters\n",
    "        model.train(X_train, y_train, X_val, y_val, epochs=20, batch_size=32)\n",
    "        test_score = model.evaluate(X_test, y_test)\n",
    "        print('test_score = ', test_score)\n",
    "        return (None, fea_cols)\n",
    "    else:\n",
    "        model.train(X, y, X, y, epochs=15, batch_size=32)    \n",
    "        return (model, fea_cols)       \n",
    "\n",
    "# none, A1C_fea = train_A1C_estimator_ANN('../../../Codes/Accord/data/ACCORD_BGClass_v2.csv')\n",
    "A1C_estimator_ANN, A1C_fea = train_A1C_estimator_ANN('../../../Codes/Accord/data/ACCORD_BGClass_v2.csv', True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model for RL feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ef1c0d68-e16a-48f8-8607-ae7c517c88cc/assets\n",
      "INFO:tensorflow:Assets written to: ram://9afb876a-7a58-40e2-b0f0-0b64595f98d0/assets\n",
      "INFO:tensorflow:Assets written to: ram://20326107-bf74-4531-a314-ed37f7657990/assets\n"
     ]
    }
   ],
   "source": [
    "estimators = {'CVDRisk-BP': CVDRisk_estimator_ANN_BP, 'SBP': SBP_estimator_ANN, 'A1C': A1C_estimator_ANN}\n",
    "feature_cols = {'CVDRisk-BP': CVDRisk_fea_BP, 'SBP': SBP_fea, 'A1C': A1C_fea}\n",
    "\n",
    "# save the estimators and feature columns\n",
    "with open('estimators.pkl', 'wb') as f:\n",
    "    pickle.dump(estimators, f)\n",
    "\n",
    "with open('feature_cols.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
